{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongwoonalee/jongwoonalee.github.io/blob/main/bladdder_flexattention_0531_final_%EB%B3%B5%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhoWaUeoFvDU"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ê¸°ë³¸ ì„¤ì •\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgxTZATiFvDX",
        "outputId": "1bfe49bf-dd17-4c92-b4f6-5a6093ab2146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\n",
            "ğŸš€ 1ê°œì˜ GPU ë°œê²¬!\n",
            "   GPU 0: NVIDIA GeForce RTX 4060 (8.0GB)\n",
            "âœ… ì£¼ ë””ë°”ì´ìŠ¤: cuda:0\n",
            "PyTorch ë²„ì „: 2.7.0+cu118\n",
            "CUDA ì‚¬ìš© ê°€ëŠ¥: True\n",
            "âœ… ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ 42ë¡œ ê³ ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "ğŸ” [ì´ˆê¸° ìƒíƒœ] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "\n",
            "================================================================================\n",
            "Part 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ì™„ë£Œ!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ì´ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš” - í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ import í•©ë‹ˆë‹¤\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from skimage.filters import threshold_otsu\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")\n",
        "\n",
        "# GPU ì„¤ì • ë° í™•ì¸ - RTX 6000 Ada x2 ìµœì í™”\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"ğŸš€ {num_gpus}ê°œì˜ GPU ë°œê²¬!\")\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "        print(f\"   GPU {i}: {gpu_name} ({memory_gb:.1f}GB)\")\n",
        "\n",
        "    # CUDA ìµœì í™” ì„¤ì •\n",
        "    torch.backends.cudnn.benchmark = True  # ë™ì¼í•œ ì…ë ¥ í¬ê¸°ì— ëŒ€í•´ ìµœì í™”\n",
        "    torch.cuda.empty_cache()               # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "\n",
        "    print(f\"âœ… ì£¼ ë””ë°”ì´ìŠ¤: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"âš ï¸  GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
        "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
        "\n",
        "# ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    Args:\n",
        "        seed (int): ê³ ì •í•  ì‹œë“œ ê°’ (ê¸°ë³¸ê°’: 42)\n",
        "    \"\"\"\n",
        "    random.seed(seed)              # Python ê¸°ë³¸ random\n",
        "    np.random.seed(seed)           # NumPy random\n",
        "    torch.manual_seed(seed)        # PyTorch CPU random\n",
        "    torch.cuda.manual_seed(seed)   # PyTorch GPU random (í˜„ì¬ ë””ë°”ì´ìŠ¤)\n",
        "    torch.cuda.manual_seed_all(seed)  # PyTorch ëª¨ë“  GPU random\n",
        "\n",
        "    # ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì • (ì†ë„ê°€ ì•½ê°„ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì‹œë“œ ì„¤ì •\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    print(f\"âœ… ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ {seed}ë¡œ ê³ ì •í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ì‹œë“œ ê³ ì • ì‹¤í–‰\n",
        "set_seed(42)\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜\n",
        "def log_gpu_memory(step_name=\"\"):\n",
        "    \"\"\"\n",
        "    í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "    Args:\n",
        "        step_name (str): í˜„ì¬ ë‹¨ê³„ ì´ë¦„ (ë¡œê·¸ êµ¬ë¶„ìš©)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3  # GB ë‹¨ìœ„\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3    # GB ë‹¨ìœ„\n",
        "        max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
        "\n",
        "        print(f\"ğŸ” [{step_name}] GPU ë©”ëª¨ë¦¬ - \"\n",
        "              f\"ì‚¬ìš©ì¤‘: {allocated:.2f}GB, \"\n",
        "              f\"ì˜ˆì•½ë¨: {reserved:.2f}GB, \"\n",
        "              f\"ìµœëŒ€ì‚¬ìš©: {max_allocated:.2f}GB\")\n",
        "    else:\n",
        "        print(f\"ğŸ” [{step_name}] CPU ëª¨ë“œ ì‹¤í–‰ ì¤‘\")\n",
        "\n",
        "# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"ì´ˆê¸° ìƒíƒœ\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nGd-YVrFvDZ"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 2: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVFkHLUMFvDZ",
        "outputId": "82b59fac-5937-4d8c-9e80-a3425d3cc9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 2 ì™„ë£Œ: ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\n",
            "ë‹¤ìŒìœ¼ë¡œ Part 3ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ë‘ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ë°ì´í„° ì²˜ë¦¬ì— í•„ìš”í•œ ëª¨ë“  í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
        "\n",
        "def extract_identifier(filename):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ëª…ì—ì„œ í™˜ì IDë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        filename (str): ì´ë¯¸ì§€ íŒŒì¼ëª… (ì˜ˆ: \"S123-456.jpg\")\n",
        "\n",
        "    Returns:\n",
        "        str or None: ì¶”ì¶œëœ í™˜ì ID (ì˜ˆ: \"S123000456\")\n",
        "        str: íŒŒì¼ í™•ì¥ì\n",
        "\n",
        "    Example:\n",
        "        extract_identifier(\"S123-456.jpg\") â†’ (\"S123000456\", \".jpg\")\n",
        "    \"\"\"\n",
        "    # íŒŒì¼ëª…ê³¼ í™•ì¥ì ë¶„ë¦¬\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # ëŒ€ê´„í˜¸ê°€ ìˆìœ¼ë©´ ì œê±° (ì˜ˆ: \"[comment]\" ë¶€ë¶„)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # íŒ¨í„´ 1: Sìˆ«ì-ìˆ«ì í˜•íƒœ (ì˜ˆ: S123-456)\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)      # \"123\"\n",
        "        patch = m1.group(2)      # \"456\"\n",
        "\n",
        "        # íŒ¨ì¹˜ ë²ˆí˜¸ë¥¼ 6ìë¦¬ë¡œ íŒ¨ë”© (ì•ì— 0 ì¶”ê°€)\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch    # 456 â†’ 000456\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch     # 1456 â†’ 001456\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch      # 12456 â†’ 012456\n",
        "        else:\n",
        "            patch_padded = patch            # ì´ë¯¸ 6ìë¦¬ë©´ ê·¸ëŒ€ë¡œ\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # íŒ¨í„´ 2: Sìˆ«ì, í˜•íƒœ (ì˜ˆ: S123,)\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # íŒ¨í„´ 3: S + 6-8ìë¦¬ ìˆ«ì (ì˜ˆ: S12345678)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜\n",
        "    return None, ext\n",
        "\n",
        "def convert_file_id_to_excel_format(file_id):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ IDë¥¼ Excelì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜\n",
        "\n",
        "    Args:\n",
        "        file_id (str): íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ ID\n",
        "\n",
        "    Returns:\n",
        "        str or None: Excel í˜•íƒœë¡œ ë³€í™˜ëœ ID\n",
        "\n",
        "    Example:\n",
        "        convert_file_id_to_excel_format(\"S123-456\") â†’ \"S123000456\"\n",
        "    \"\"\"\n",
        "    if file_id is None:\n",
        "        return None\n",
        "\n",
        "    file_id = str(file_id).strip()\n",
        "\n",
        "    # \"-\"ê°€ í¬í•¨ëœ ê²½ìš° (ì˜ˆ: S123-456)\n",
        "    if \"-\" in file_id:\n",
        "        parts = file_id.split(\"-\")\n",
        "        if len(parts) == 2 and parts[1].isdigit():\n",
        "            patch = parts[1]\n",
        "\n",
        "            # íŒ¨ì¹˜ ë²ˆí˜¸ë¥¼ 6ìë¦¬ë¡œ íŒ¨ë”©\n",
        "            if len(patch) == 3:\n",
        "                padded_number = \"000\" + patch\n",
        "            elif len(patch) == 4:\n",
        "                padded_number = \"00\" + patch\n",
        "            elif len(patch) == 5:\n",
        "                padded_number = \"0\" + patch\n",
        "            else:\n",
        "                padded_number = patch\n",
        "\n",
        "            return f\"{parts[0]}{padded_number}\"\n",
        "\n",
        "    # ì´ë¯¸ Së¡œ ì‹œì‘í•˜ëŠ” ê¸´ í˜•íƒœë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
        "    elif len(file_id) > 3 and file_id.startswith(\"S\"):\n",
        "        return file_id\n",
        "\n",
        "    return None\n",
        "\n",
        "# ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ í•¨ìˆ˜ (ì—¬ê¸°ì„œëŠ” í•¨ìˆ˜ë§Œ ì •ì˜, ì‹¤ì œ ë¡œë”©ì€ ë‹¤ìŒ ì…€ì—ì„œ)\n",
        "def load_and_match_data(zip_path, excel_path, base_dir=None):\n",
        "    \"\"\"\n",
        "    ZIP íŒŒì¼ê³¼ Excel íŒŒì¼ì„ ë§¤ì¹­í•˜ì—¬ í™˜ìë³„ ë°ì´í„°ë¥¼ êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” ZIP íŒŒì¼ ê²½ë¡œ\n",
        "        excel_path (str): ë¼ë²¨ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” Excel íŒŒì¼ ê²½ë¡œ\n",
        "        base_dir (str, optional): ZIP ì••ì¶• í•´ì œí•  ë””ë ‰í† ë¦¬\n",
        "\n",
        "    Returns:\n",
        "        dict: í™˜ìë³„ë¡œ êµ¬ì„±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
        "        {\n",
        "            \"patient_id\": {\n",
        "                \"images\": [ì´ë¯¸ì§€íŒŒì¼ê²½ë¡œë“¤],\n",
        "                \"t_label\": T-stage ë¼ë²¨,\n",
        "                \"recur_label\": ì¬ë°œ ë¼ë²¨,\n",
        "                \"grade\": ë“±ê¸‰ ì •ë³´,\n",
        "                ... ê¸°íƒ€ ì •ë³´\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ ì‹œì‘...\")\n",
        "\n",
        "    # Excel íŒŒì¼ ì½ê¸°\n",
        "    print(\"ğŸ“Š Excel íŒŒì¼ ì½ëŠ” ì¤‘...\")\n",
        "    try:\n",
        "        df = pd.read_excel(excel_path)\n",
        "        print(f\"   âœ… Excel íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰\")\n",
        "        print(f\"   ğŸ“‹ ì»¬ëŸ¼ë“¤: {list(df.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # T-stageì™€ ì¬ë°œ ë¼ë²¨ ìƒì„±\n",
        "    print(\"ğŸ·ï¸  ë¼ë²¨ ë³€í™˜ ì¤‘...\")\n",
        "\n",
        "        # T-stage ë¼ë²¨: 1 â†’ 0 (ì €ìœ„í—˜), 2 â†’ 1 (ê³ ìœ„í—˜)\n",
        "    second_column = df.columns[1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ (Subtype)\n",
        "    df['t_label'] = df[second_column].apply(\n",
        "        lambda x: 0 if str(x) == '1' else 1\n",
        "    )\n",
        "    t_counts = df['t_label'].value_counts()\n",
        "    print(f\"   ğŸ“ˆ T-stage ë¶„í¬: ì €ìœ„í—˜(0): {t_counts.get(0, 0)}ê°œ, ê³ ìœ„í—˜(1): {t_counts.get(1, 0)}ê°œ\")\n",
        "\n",
        "    # ì¬ë°œ ë¼ë²¨: No â†’ 0, Yes â†’ 1\n",
        "    #if 'Recurrence' in df.columns:\n",
        "        #df['recur_label'] = df['Recurrence'].apply(\n",
        "           # lambda x: 0 if str(x).lower() == 'no' else 1\n",
        "        #)\n",
        "       # recur_counts = df['recur_label'].value_counts()\n",
        "      #  print(f\"   ğŸ”„ ì¬ë°œ ë¶„í¬: ì—†ìŒ(0): {recur_counts.get(0, 0)}ê°œ, ìˆìŒ(1): {recur_counts.get(1, 0)}ê°œ\")\n",
        "\n",
        "    # ZIP íŒŒì¼ ì²˜ë¦¬\n",
        "    if base_dir is None:\n",
        "        base_dir = zip_path.replace('.zip', '')\n",
        "\n",
        "    print(f\"ğŸ“¦ ZIP íŒŒì¼ ì²˜ë¦¬ ì¤‘: {zip_path}\")\n",
        "\n",
        "    # ZIP íŒŒì¼ì´ ì´ë¯¸ ì••ì¶• í•´ì œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(\"   ğŸ”„ ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(os.path.dirname(base_dir))\n",
        "        print(\"   âœ… ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì™„ë£Œ\")\n",
        "    else:\n",
        "        print(\"   âœ… ì´ë¯¸ ì••ì¶• í•´ì œëœ í´ë” ë°œê²¬\")\n",
        "\n",
        "    # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°\n",
        "    print(\"ğŸ” ì´ë¯¸ì§€ íŒŒì¼ë“¤ íƒìƒ‰ ì¤‘...\")\n",
        "    image_files = []\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                full_path = os.path.join(root, file)\n",
        "                image_files.append(full_path)\n",
        "\n",
        "    print(f\"   ğŸ“· ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬\")\n",
        "\n",
        "    # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ ë° ë§¤ì¹­\n",
        "    print(\"ğŸ”— í™˜ì ID ë§¤ì¹­ ì¤‘...\")\n",
        "    patient_data = {}\n",
        "    matched_count = 0\n",
        "    unmatched_files = []\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬\"):\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ\n",
        "        file_id, _ = extract_identifier(filename)\n",
        "        if file_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excel í˜•íƒœë¡œ ë³€í™˜\n",
        "        excel_id = convert_file_id_to_excel_format(file_id)\n",
        "        if excel_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excelì—ì„œ í•´ë‹¹ í™˜ì ì°¾ê¸°\n",
        "        patient_row = df[df.iloc[:, 0].astype(str).str.contains(excel_id, na=False)]\n",
        "\n",
        "        if len(patient_row) > 0:\n",
        "            patient_info = patient_row.iloc[0]\n",
        "            patient_id = str(patient_info.iloc[0])\n",
        "\n",
        "            # í™˜ì ë°ì´í„° ì´ˆê¸°í™” (ì²˜ìŒ ë°œê²¬ëœ ê²½ìš°)\n",
        "            if patient_id not in patient_data:\n",
        "                patient_data[patient_id] = {\n",
        "                    'images': [],\n",
        "                    't_label': patient_info.get('t_label', 0),\n",
        "                    'recur_label': patient_info.get('recur_label', 0),\n",
        "                    'grade': patient_info.get('Grade', 'Unknown'),\n",
        "                    't_stage': patient_info.get('T-stage', 'Unknown'),\n",
        "                    'recurrence': patient_info.get('Recurrence', 'Unknown')\n",
        "                }\n",
        "\n",
        "            # ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€\n",
        "            patient_data[patient_id]['images'].append(img_path)\n",
        "            matched_count += 1\n",
        "        else:\n",
        "            unmatched_files.append(filename)\n",
        "\n",
        "    print(f\"   âœ… ë§¤ì¹­ ì™„ë£Œ: {matched_count}ê°œ íŒŒì¼ ë§¤ì¹­\")\n",
        "    print(f\"   âš ï¸  ë§¤ì¹­ ì‹¤íŒ¨: {len(unmatched_files)}ê°œ íŒŒì¼\")\n",
        "    print(f\"   ğŸ‘¥ ì´ í™˜ì ìˆ˜: {len(patient_data)}ëª…\")\n",
        "\n",
        "    # í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜ í†µê³„\n",
        "    image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "    if image_counts:\n",
        "        print(f\"   ğŸ“Š í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜ - í‰ê· : {np.mean(image_counts):.1f}ê°œ, \"\n",
        "              f\"ìµœì†Œ: {min(image_counts)}ê°œ, ìµœëŒ€: {max(image_counts)}ê°œ\")\n",
        "\n",
        "    # ë§¤ì¹­ë˜ì§€ ì•Šì€ íŒŒì¼ ì¼ë¶€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)\n",
        "    if unmatched_files:\n",
        "        print(f\"   ğŸ“ ë§¤ì¹­ ì‹¤íŒ¨ íŒŒì¼ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):\")\n",
        "        for file in unmatched_files[:5]:\n",
        "            print(f\"      - {file}\")\n",
        "\n",
        "    print(\"âœ… ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ ì™„ë£Œ!\")\n",
        "    return patient_data\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 2 ì™„ë£Œ: ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒìœ¼ë¡œ Part 3ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSJh7ioCFvDa"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 3: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwFDkxV3FvDa",
        "outputId": "6982101e-6687-4586-a550-62916e5f6168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 3 ì™„ë£Œ: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\n",
            "ì´ì œ 1024x1024 ì´ë¯¸ì§€ë¥¼ 16ê°œì˜ 3-stream íŒ¨ì¹˜ë¡œ ë¶„í• í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ì„¸ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - FlexAttentionì˜ í•µì‹¬ì¸ ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
        "\n",
        "def split_megapatch_to_patches(megapatch_path, grid_size=4):\n",
        "    \"\"\"\n",
        "    ğŸ”ª STEP 1: 1024x1024 ë©”ê°€íŒ¨ì¹˜ë¥¼ 4x4=16ê°œì˜ 256x256 íŒ¨ì¹˜ë¡œ ë¶„í• \n",
        "\n",
        "    FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - í° ì´ë¯¸ì§€ë¥¼ ì‘ì€ íŒ¨ì¹˜ë“¤ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬\n",
        "    - ê° íŒ¨ì¹˜ëŠ” ë™ì¼í•œ í¬ê¸°ë¡œ ì •ê·œí™”\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 ë©”ê°€íŒ¨ì¹˜ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "        grid_size (int): ê·¸ë¦¬ë“œ í¬ê¸° (4x4 = 16ê°œ íŒ¨ì¹˜, 3x3 = 9ê°œ íŒ¨ì¹˜ ë“±)\n",
        "\n",
        "    Returns:\n",
        "        list: 16ê°œì˜ 256x256 íŒ¨ì¹˜ë“¤ (numpy arrays)\n",
        "        list: ê° íŒ¨ì¹˜ì˜ ìœ„ì¹˜ ì •ë³´ [(i, j), ...]\n",
        "\n",
        "    Example:\n",
        "        patches, positions = split_megapatch_to_patches(\"image.jpg\", 4)\n",
        "        # patches[0]: ì¢Œìƒë‹¨ íŒ¨ì¹˜, patches[15]: ìš°í•˜ë‹¨ íŒ¨ì¹˜\n",
        "        # positions[0]: (0, 0), positions[15]: (3, 3)\n",
        "    \"\"\"\n",
        "    # 1024x1024 ë©”ê°€íŒ¨ì¹˜ ì½ê¸°\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"âŒ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {megapatch_path}\")\n",
        "\n",
        "    # BGR â†’ RGB ë³€í™˜ (OpenCVëŠ” BGR, ìš°ë¦¬ëŠ” RGB ì‚¬ìš©)\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "    h, w = megapatch.shape[:2]\n",
        "\n",
        "    # ê° íŒ¨ì¹˜ í¬ê¸° ê³„ì‚°: 1024/4 = 256\n",
        "    patch_size = h // grid_size  # 256x256\n",
        "\n",
        "    patches = []      # ë¶„í• ëœ íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    positions = []    # ê° íŒ¨ì¹˜ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    # 4x4 ê·¸ë¦¬ë“œë¡œ ë¶„í•  (ì™¼ìª½ ìœ„ë¶€í„° ì˜¤ë¥¸ìª½ ì•„ë˜ë¡œ)\n",
        "    for i in range(grid_size):        # ì„¸ë¡œ ë°©í–¥ (í–‰)\n",
        "        for j in range(grid_size):    # ê°€ë¡œ ë°©í–¥ (ì—´)\n",
        "            # íŒ¨ì¹˜ì˜ ì‹œì‘ì ê³¼ ëì  ê³„ì‚°\n",
        "            y_start = i * patch_size      # ì„¸ë¡œ ì‹œì‘ ìœ„ì¹˜\n",
        "            x_start = j * patch_size      # ê°€ë¡œ ì‹œì‘ ìœ„ì¹˜\n",
        "            y_end = y_start + patch_size  # ì„¸ë¡œ ë ìœ„ì¹˜\n",
        "            x_end = x_start + patch_size  # ê°€ë¡œ ë ìœ„ì¹˜\n",
        "\n",
        "            # 256x256 íŒ¨ì¹˜ ì¶”ì¶œ\n",
        "            patch = megapatch[y_start:y_end, x_start:x_end]\n",
        "            patches.append(patch)\n",
        "            positions.append((i, j))  # (í–‰, ì—´) ìœ„ì¹˜ ì €ì¥\n",
        "\n",
        "    return patches, positions\n",
        "\n",
        "def create_three_streams_from_patch(patch_256, megapatch_1024):\n",
        "    \"\"\"\n",
        "    ğŸ¯ STEP 2: ê° 256x256 íŒ¨ì¹˜ë¡œë¶€í„° 3-stream ìƒì„±\n",
        "\n",
        "    FlexAttentionì˜ 3-stream êµ¬ì¡°:\n",
        "    1. LR (Low Resolution): ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ 64x64 ì €í•´ìƒë„\n",
        "    2. HR (High Resolution): ì„¸ë°€í•œ ë¶„ì„ì„ ìœ„í•œ 256x256 ê³ í•´ìƒë„\n",
        "    3. Global: ì „ì²´ ë§¥ë½ì„ ìœ„í•œ 64x64 ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸\n",
        "\n",
        "    Args:\n",
        "        patch_256 (numpy.ndarray): 256x256 íŒ¨ì¹˜ (numpy array)\n",
        "        megapatch_1024 (numpy.ndarray): ì „ì²´ 1024x1024 ë©”ê°€íŒ¨ì¹˜ (Global ìƒì„±ìš©)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr': 64x64 LR íŒ¨ì¹˜,\n",
        "            'hr': 256x256 HR íŒ¨ì¹˜ (ì›ë³¸),\n",
        "            'global': 64x64 Global ì»¨í…ìŠ¤íŠ¸\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 1. LR ìŠ¤íŠ¸ë¦¼: 256x256 â†’ 64x64 ë‹¤ìš´ìƒ˜í”Œë§\n",
        "    # INTER_AREA: ì¶•ì†Œì‹œ í’ˆì§ˆì´ ì¢‹ì€ ë³´ê°„ë²•\n",
        "    lr_patch =  patch_256.copy()  # 256x256 ê·¸ëŒ€ë¡œ\n",
        "\n",
        "    # 2. HR ìŠ¤íŠ¸ë¦¼: 256x256 ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "    # ì„¸ë°€í•œ íŠ¹ì§•ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ì›ë³¸ í•´ìƒë„ ìœ ì§€\n",
        "    hr_patch = patch_256.copy()\n",
        "\n",
        "    # 3. Global ìŠ¤íŠ¸ë¦¼: ì „ì²´ 1024x1024 â†’ 64x64 (ë§¤ìš° ì‘ì€ overview)\n",
        "    # ì „ì²´ì ì¸ êµ¬ì¡°ì™€ ë§¥ë½ ì •ë³´ë¥¼ ì œê³µ\n",
        "    global_context = cv2.resize(megapatch_1024, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return {\n",
        "        'lr': lr_patch,         # 64x64 LR (ë¹ ë¥¸ ì²˜ë¦¬ìš©)\n",
        "        'hr': hr_patch,         # 256x256 HR (ì„¸ë°€í•œ ë¶„ì„ìš©)\n",
        "        'global': global_context # 64x64 Global (ë§¥ë½ ì •ë³´ìš©)\n",
        "    }\n",
        "\n",
        "def process_megapatch_complete(megapatch_path, patches_per_megapatch=16):\n",
        "    \"\"\"\n",
        "    ğŸš€ STEP 3: ë©”ê°€íŒ¨ì¹˜ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "    ì „ì²´ ê³¼ì •:\n",
        "    1024x1024 ë©”ê°€íŒ¨ì¹˜ â†’ 16ê°œ íŒ¨ì¹˜ë¡œ ë¶„í•  â†’ ê°ê° 3-stream ìƒì„±\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        patches_per_megapatch (int): ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ê°œìˆ˜ (16 or 8 ë“±)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr_patches': 16ê°œì˜ 64x64 LR íŒ¨ì¹˜ë“¤,\n",
        "            'hr_patches': 16ê°œì˜ 256x256 HR íŒ¨ì¹˜ë“¤,\n",
        "            'global_tokens': 16ê°œì˜ 64x64 Global í† í°ë“¤ (ëª¨ë‘ ë™ì¼),\n",
        "            'positions': íŒ¨ì¹˜ ìœ„ì¹˜ ì •ë³´ [(i,j), ...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    # ì›ë³¸ ë©”ê°€íŒ¨ì¹˜ ì½ê¸°\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"âŒ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {megapatch_path}\")\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # patches_per_megapatchì— ë”°ë¼ grid_size ê²°ì •\n",
        "    if patches_per_megapatch == 16:\n",
        "        grid_size = 4    # 4x4 = 16\n",
        "    elif patches_per_megapatch == 9:\n",
        "        grid_size = 3    # 3x3 = 9\n",
        "    elif patches_per_megapatch == 8:\n",
        "        # 8ê°œëŠ” íŠ¹ë³„ ì²˜ë¦¬: 4x4ì—ì„œ 8ê°œë§Œ ì„ íƒ\n",
        "        grid_size = 4\n",
        "        use_subset = True\n",
        "    else:\n",
        "        grid_size = int(math.sqrt(patches_per_megapatch))\n",
        "        use_subset = False\n",
        "\n",
        "    # STEP 1: 1024x1024 â†’ ì—¬ëŸ¬ê°œ 256x256 íŒ¨ì¹˜ë¡œ ë¶„í• \n",
        "    patches_256, positions = split_megapatch_to_patches(megapatch_path, grid_size)\n",
        "\n",
        "    # 8ê°œë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°: ì²´ìŠ¤íŒ íŒ¨í„´ìœ¼ë¡œ ì„ íƒ (ê· ë“± ë¶„í¬)\n",
        "    if patches_per_megapatch == 8 and len(patches_256) == 16:\n",
        "        # ì²´ìŠ¤íŒ íŒ¨í„´: (0,0), (0,2), (1,1), (1,3), (2,0), (2,2), (3,1), (3,3)\n",
        "        selected_indices = []\n",
        "        for i, (row, col) in enumerate(positions):\n",
        "            if (row + col) % 2 == 0:  # ì²´ìŠ¤íŒ íŒ¨í„´\n",
        "                selected_indices.append(i)\n",
        "\n",
        "        # 8ê°œë§Œ ì„ íƒ\n",
        "        selected_indices = selected_indices[:patches_per_megapatch]\n",
        "        patches_256 = [patches_256[i] for i in selected_indices]\n",
        "        positions = [positions[i] for i in selected_indices]\n",
        "\n",
        "    # STEP 2: ê° íŒ¨ì¹˜ë³„ë¡œ 3-stream ìƒì„±\n",
        "    lr_patches = []       # LR íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    hr_patches = []       # HR íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    global_tokens = []    # Global í† í°ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    for patch_256 in patches_256:\n",
        "        # ê° íŒ¨ì¹˜ì— ëŒ€í•´ 3-stream ìƒì„±\n",
        "        streams = create_three_streams_from_patch(patch_256, megapatch)\n",
        "\n",
        "        lr_patches.append(streams['lr'])        # 64x64 LR\n",
        "        hr_patches.append(streams['hr'])        # 256x256 HR\n",
        "        global_tokens.append(streams['global']) # 64x64 Global\n",
        "\n",
        "        # ì°¸ê³ : global_tokensëŠ” ëª¨ë‘ ë™ì¼í•œ ì „ì²´ ì´ë¯¸ì§€ì˜ ì¶•ì†Œë³¸ì…ë‹ˆë‹¤\n",
        "\n",
        "    return {\n",
        "        'lr_patches': lr_patches,     # patches_per_megapatchê°œ Ã— 64x64\n",
        "        'hr_patches': hr_patches,     # patches_per_megapatchê°œ Ã— 256x256\n",
        "        'global_tokens': global_tokens, # patches_per_megapatchê°œ Ã— 64x64 (ëª¨ë‘ ë™ì¼)\n",
        "        'positions': positions        # patches_per_megapatchê°œ ìœ„ì¹˜ ì •ë³´\n",
        "    }\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™” í•¨ìˆ˜\n",
        "def visualize_patch_splitting(megapatch_path, save_path=None):\n",
        "    \"\"\"\n",
        "    ğŸ“Š ë©”ê°€íŒ¨ì¹˜ ë¶„í•  ê³¼ì •ì„ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ (ë””ë²„ê¹… ë° í™•ì¸ìš©)\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): ì‹œê°í™”í•  ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        save_path (str, optional): ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬\n",
        "        processed = process_megapatch_complete(megapatch_path)\n",
        "\n",
        "        # ì‹œê°í™” ì„¤ì •\n",
        "        fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
        "        fig.suptitle(f'ë©”ê°€íŒ¨ì¹˜ ë¶„í•  ê²°ê³¼: {os.path.basename(megapatch_path)}', fontsize=16)\n",
        "\n",
        "        # ì›ë³¸ ë©”ê°€íŒ¨ì¹˜ í‘œì‹œ\n",
        "        megapatch = cv2.imread(megapatch_path)\n",
        "        megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "        axes[0, 0].imshow(megapatch)\n",
        "        axes[0, 0].set_title('ì›ë³¸ ë©”ê°€íŒ¨ì¹˜\\n(1024x1024)', fontsize=10)\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # ì²˜ìŒ 5ê°œ íŒ¨ì¹˜ì˜ 3-stream í‘œì‹œ\n",
        "        for i in range(min(5, len(processed['lr_patches']))):\n",
        "            row = i // 5 + 1\n",
        "            col_start = (i % 5) + 1\n",
        "\n",
        "            # LR íŒ¨ì¹˜ (64x64)\n",
        "            axes[0, col_start].imshow(processed['lr_patches'][i])\n",
        "            axes[0, col_start].set_title(f'LR {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[0, col_start].axis('off')\n",
        "\n",
        "            # HR íŒ¨ì¹˜ (256x256)\n",
        "            axes[1, col_start].imshow(processed['hr_patches'][i])\n",
        "            axes[1, col_start].set_title(f'HR {i+1}\\n(256x256)', fontsize=8)\n",
        "            axes[1, col_start].axis('off')\n",
        "\n",
        "            # Global í† í° (64x64)\n",
        "            axes[2, col_start].imshow(processed['global_tokens'][i])\n",
        "            axes[2, col_start].set_title(f'Global {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[2, col_start].axis('off')\n",
        "\n",
        "        # ë¹ˆ subplotë“¤ ìˆ¨ê¸°ê¸°\n",
        "        for i in range(4):\n",
        "            for j in range(6):\n",
        "                if i > 2 or (i == 0 and j == 0) or (i > 0 and j == 0):\n",
        "                    continue\n",
        "                if not axes[i, j].has_data():\n",
        "                    axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"âœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # í†µê³„ ì •ë³´ ì¶œë ¥\n",
        "        print(f\"ğŸ“Š ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ ê²°ê³¼:\")\n",
        "        print(f\"   - LR íŒ¨ì¹˜ ê°œìˆ˜: {len(processed['lr_patches'])}ê°œ (ê° 64x64)\")\n",
        "        print(f\"   - HR íŒ¨ì¹˜ ê°œìˆ˜: {len(processed['hr_patches'])}ê°œ (ê° 256x256)\")\n",
        "        print(f\"   - Global í† í° ê°œìˆ˜: {len(processed['global_tokens'])}ê°œ (ê° 64x64)\")\n",
        "        print(f\"   - ìœ„ì¹˜ ì •ë³´: {processed['positions'][:5]}... (ì²˜ìŒ 5ê°œ)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 3 ì™„ë£Œ: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ 1024x1024 ì´ë¯¸ì§€ë¥¼ 16ê°œì˜ 3-stream íŒ¨ì¹˜ë¡œ ë¶„í• í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUw1pN87FvDb"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 4: Feature Extractorì™€ HR Selection\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M3AzkZBFvDb",
        "outputId": "3f7db9bb-4815-4bc7-ac57-dea6836e98a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 4 ì™„ë£Œ: Feature Extractorì™€ HR Selector ì •ì˜ ì™„ë£Œ!\n",
            "ResNet18 vs MobileNet vs EfficientNet ì¤‘ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ë„¤ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ResNet ê¸°ë°˜ feature extractorì™€ ë…¼ë¬¸ì˜ threshold ë°©ì‹ HR selectionì„ êµ¬í˜„í•©ë‹ˆë‹¤\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ”¬ ResNet18 ê¸°ë°˜ Feature Extractor\n",
        "\n",
        "    ì—­í• :\n",
        "    - 64x64 ì´ë¯¸ì§€ìš© (LR, Global streams)\n",
        "    - 256x256 ì´ë¯¸ì§€ìš© (HR stream)\n",
        "    - ì´ë¯¸ì§€ë¥¼ ê³ ì • í¬ê¸° feature vectorë¡œ ë³€í™˜\n",
        "\n",
        "    ì„ íƒì§€:\n",
        "    - ResNet18: ì•ˆì •ì ì´ê³  ê²€ì¦ëœ ì„±ëŠ¥ (ì¶”ì²œ)\n",
        "    - MobileNetV3: ë” ë¹ ë¥´ì§€ë§Œ ì„±ëŠ¥ ì•½ê°„ ë‚®ìŒ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, model_type='resnet18', pretrained=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): ì¶œë ¥ feature ì°¨ì› (256 or 384)\n",
        "            model_type (str): ì‚¬ìš©í•  ë°±ë³¸ ëª¨ë¸ ('resnet18', 'mobilenet', 'efficientnet')\n",
        "            pretrained (bool): ImageNet ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€\n",
        "        \"\"\"\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.model_type = model_type\n",
        "\n",
        "        # ë°±ë³¸ ëª¨ë¸ ì„ íƒ ë° ì„¤ì •\n",
        "        if model_type == 'resnet18':\n",
        "            # ResNet18: ì•ˆì •ì ì´ê³  ë„ë¦¬ ì‚¬ìš©ë¨ (11M parameters)\n",
        "            resnet = models.resnet18(pretrained=pretrained)\n",
        "            self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # avgpool, fc ì œê±°\n",
        "            backbone_out_dim = 512\n",
        "\n",
        "        elif model_type == 'mobilenet':\n",
        "            # MobileNetV3-Small: ë¹ ë¥´ê³  ê²½ëŸ‰ (2.5M parameters)\n",
        "            from torchvision.models import mobilenet_v3_small\n",
        "            mobilenet = mobilenet_v3_small(pretrained=pretrained)\n",
        "            self.backbone = mobilenet.features\n",
        "            backbone_out_dim = 576\n",
        "\n",
        "        elif model_type == 'efficientnet':\n",
        "            # EfficientNet-B0: íš¨ìœ¨ì ì´ê³  ì„±ëŠ¥ ì¢‹ìŒ (5.3M parameters)\n",
        "            from torchvision.models import efficientnet_b0\n",
        "            efficientnet = efficientnet_b0(pretrained=pretrained)\n",
        "            self.backbone = efficientnet.features\n",
        "            backbone_out_dim = 1280\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}\")\n",
        "\n",
        "        # Global Average Pooling: spatial dimensionsë¥¼ 1x1ë¡œ ì¶•ì†Œ\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Feature projection: backbone output â†’ ì›í•˜ëŠ” feature dimension\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(backbone_out_dim, feature_dim),\n",
        "            nn.LayerNorm(feature_dim),  # Layer Normalizationìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1)             # 10% ë“œë¡­ì•„ì›ƒìœ¼ë¡œ overfitting ë°©ì§€\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… {model_type.upper()} Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "        print(f\"   - ë°±ë³¸ ì¶œë ¥ ì°¨ì›: {backbone_out_dim}\")\n",
        "        print(f\"   - ìµœì¢… feature ì°¨ì›: {feature_dim}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ feature vectorsë¡œ ë³€í™˜\n",
        "\n",
        "        Args:\n",
        "            x: [batch_size, 3, H, W] - RGB ì´ë¯¸ì§€ ë°°ì¹˜\n",
        "               H, WëŠ” 64 (LR, Global) ë˜ëŠ” 256 (HR)\n",
        "\n",
        "        Returns:\n",
        "            [batch_size, feature_dim] - ì¶”ì¶œëœ feature vectors\n",
        "        \"\"\"\n",
        "        # 1. ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ feature map ì¶”ì¶œ\n",
        "        features = self.backbone(x)      # [B, C, H', W'] - ì˜ˆ: [B, 512, H'/32, W'/32]\n",
        "\n",
        "        # 2. Global Average Poolingìœ¼ë¡œ spatial dimensions ì¶•ì†Œ\n",
        "        pooled = self.avgpool(features)  # [B, C, 1, 1]\n",
        "\n",
        "        # 3. Flatten: [B, C, 1, 1] â†’ [B, C]\n",
        "        flattened = pooled.view(pooled.size(0), -1)  # [B, backbone_out_dim]\n",
        "\n",
        "        # 4. Projectionì„ í†µí•´ ì›í•˜ëŠ” ì°¨ì›ìœ¼ë¡œ ë³€í™˜\n",
        "        projected = self.projection(flattened)       # [B, feature_dim]\n",
        "\n",
        "        return projected\n",
        "\n",
        "\n",
        "class ThresholdBasedHRSelector(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ ë…¼ë¬¸ì˜ ì •í™•í•œ ë°©ì‹: Threshold ê¸°ë°˜ HR Feature Selection\n",
        "\n",
        "    FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - LR attention scoresì—ì„œ thresholdë¥¼ ê³„ì‚°\n",
        "    - Threshold ì´ìƒì¸ íŒ¨ì¹˜ë“¤ë§Œ HRë¡œ ì„ íƒ\n",
        "    - ì•½ 10% ì •ë„ê°€ ì„ íƒë˜ë„ë¡ ë™ì  ì¡°ì •\n",
        "    - Top-K ê³ ì • ì„ íƒì´ ì•„ë‹Œ ì‹¤ì œ ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target_selection_ratio=0.1, min_patches=1, max_patches=4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            target_selection_ratio (float): ëª©í‘œ ì„ íƒ ë¹„ìœ¨ (0.1 = ì•½ 10%)\n",
        "            min_patches (int): ìµœì†Œ ì„ íƒ íŒ¨ì¹˜ ê°œìˆ˜ (ë„ˆë¬´ ì ìœ¼ë©´ ê°•ì œ ì„ íƒ)\n",
        "            max_patches (int): ìµœëŒ€ ì„ íƒ íŒ¨ì¹˜ ê°œìˆ˜ (ë„ˆë¬´ ë§ìœ¼ë©´ ì œí•œ)\n",
        "        \"\"\"\n",
        "        super(ThresholdBasedHRSelector, self).__init__()\n",
        "        self.target_selection_ratio = target_selection_ratio\n",
        "        self.min_patches = min_patches\n",
        "        self.max_patches = max_patches\n",
        "\n",
        "        print(f\"âœ… Threshold ê¸°ë°˜ HR Selector ì´ˆê¸°í™”\")\n",
        "        print(f\"   - ëª©í‘œ ì„ íƒ ë¹„ìœ¨: {target_selection_ratio*100:.1f}%\")\n",
        "        print(f\"   - ì„ íƒ ë²”ìœ„: {min_patches}~{max_patches}ê°œ\")\n",
        "\n",
        "    def forward(self, lr_attention_scores, hr_features):\n",
        "        \"\"\"\n",
        "        Threshold ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”í•œ HR featuresë§Œ ì„ íƒ\n",
        "\n",
        "        Args:\n",
        "            lr_attention_scores: [batch_size, 16] - LR patchesì˜ attention scores\n",
        "            hr_features: [batch_size, 16, feature_dim] - HR patch features\n",
        "\n",
        "        Returns:\n",
        "            selected_hr_features: [batch_size, max_patches, feature_dim] - ì„ íƒëœ HR features\n",
        "            selection_masks: [batch_size, 16] - binary selection mask (ì‹œê°í™”ìš©)\n",
        "            thresholds: [batch_size] - ì‚¬ìš©ëœ threshold ê°’ë“¤ (ë¶„ì„ìš©)\n",
        "        \"\"\"\n",
        "        batch_size, num_patches, feature_dim = hr_features.shape\n",
        "\n",
        "        selected_hr_features = []  # ì„ íƒëœ HR featuresë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        selection_masks = []       # ì„ íƒ ë§ˆìŠ¤í¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        thresholds = []           # ì‚¬ìš©ëœ thresholdë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "        # ë°°ì¹˜ì˜ ê° ìƒ˜í”Œì— ëŒ€í•´ ê°œë³„ ì²˜ë¦¬\n",
        "        for b in range(batch_size):\n",
        "            att_scores = lr_attention_scores[b]  # [16] - ì´ ìƒ˜í”Œì˜ attention scores\n",
        "\n",
        "            # Step 1: Adaptive threshold ê³„ì‚°\n",
        "            threshold = self._compute_adaptive_threshold(att_scores)\n",
        "\n",
        "            # Step 2: Threshold ì ìš©í•˜ì—¬ íŒ¨ì¹˜ ì„ íƒ\n",
        "            mask = att_scores > threshold\n",
        "            selected_indices = torch.where(mask)[0]  # threshold ì´ìƒì¸ íŒ¨ì¹˜ë“¤ì˜ ì¸ë±ìŠ¤\n",
        "\n",
        "            num_selected = len(selected_indices)\n",
        "\n",
        "            # Step 3: ì„ íƒëœ íŒ¨ì¹˜ ìˆ˜ ê²€ì¦ ë° ì¡°ì •\n",
        "            if num_selected < self.min_patches:\n",
        "                # ë„ˆë¬´ ì ê²Œ ì„ íƒëœ ê²½ìš°: ê°•ì œë¡œ ìµœì†Œ ê°œìˆ˜ë§Œí¼ ì„ íƒ\n",
        "                _, top_indices = torch.topk(att_scores, self.min_patches)\n",
        "                selected_indices = top_indices\n",
        "                threshold = att_scores[top_indices[-1]]  # ìƒˆë¡œìš´ threshold\n",
        "\n",
        "            elif num_selected > self.max_patches:\n",
        "                # ë„ˆë¬´ ë§ì´ ì„ íƒëœ ê²½ìš°: ìƒìœ„ max_patchesê°œë§Œ ì„ íƒ\n",
        "                selected_scores = att_scores[selected_indices]\n",
        "                _, top_within_selected = torch.topk(selected_scores, self.max_patches)\n",
        "                selected_indices = selected_indices[top_within_selected]\n",
        "                threshold = att_scores[selected_indices[-1]]  # ìƒˆë¡œìš´ threshold\n",
        "\n",
        "            # Step 4: ì„ íƒëœ HR features ì¶”ì¶œ\n",
        "            selected_features = hr_features[b, selected_indices]  # [num_selected, feature_dim]\n",
        "\n",
        "            # Step 5: ê³ ì • í¬ê¸°ë¡œ íŒ¨ë”© (ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´)\n",
        "            if len(selected_indices) < self.max_patches:\n",
        "                padding_size = self.max_patches - len(selected_indices)\n",
        "                padding = torch.zeros(padding_size, feature_dim, device=hr_features.device)\n",
        "                selected_features = torch.cat([selected_features, padding], dim=0)\n",
        "\n",
        "            selected_hr_features.append(selected_features)\n",
        "\n",
        "            # Step 6: Binary mask ìƒì„± (ì‹œê°í™” ë° ë¶„ì„ìš©)\n",
        "            binary_mask = torch.zeros_like(att_scores)\n",
        "            if len(selected_indices) > 0:\n",
        "                binary_mask[selected_indices] = 1.0\n",
        "            selection_masks.append(binary_mask)\n",
        "\n",
        "            thresholds.append(threshold)\n",
        "\n",
        "        # ë¦¬ìŠ¤íŠ¸ë“¤ì„ í…ì„œë¡œ ë³€í™˜\n",
        "        selected_hr_features = torch.stack(selected_hr_features)  # [B, max_patches, feature_dim]\n",
        "        selection_masks = torch.stack(selection_masks)            # [B, 16]\n",
        "        thresholds = torch.stack(thresholds)                      # [B]\n",
        "\n",
        "        return selected_hr_features, selection_masks, thresholds\n",
        "\n",
        "    def _compute_adaptive_threshold(self, attention_scores):\n",
        "        \"\"\"\n",
        "        ì ì‘ì  threshold ê³„ì‚° - ì—¬ëŸ¬ ë°©ë²• ì¤‘ ê°€ì¥ ì ì ˆí•œ ê²ƒ ì„ íƒ\n",
        "\n",
        "        Args:\n",
        "            attention_scores: [16] - í•˜ë‚˜ì˜ ìƒ˜í”Œì— ëŒ€í•œ attention scores\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: ê³„ì‚°ëœ threshold ê°’\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Method 1: Otsu threshold (ì´ì§„í™”ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìµœì  ë¶„í• ì )\n",
        "            # ê°€ì¥ ì¢‹ì€ ë°©ë²•ì´ì§€ë§Œ sklearn í•„ìš”\n",
        "            scores_np = attention_scores.detach().cpu().numpy()\n",
        "            threshold_val = threshold_otsu(scores_np)\n",
        "            return torch.tensor(threshold_val, device=attention_scores.device)\n",
        "\n",
        "        except:\n",
        "            # Method 2: Percentile-based threshold (Fallback)\n",
        "            # ìƒìœ„ target_selection_ratio*2 ì •ë„ê°€ ì„ íƒë˜ë„ë¡\n",
        "            percentile = 1.0 - (self.target_selection_ratio * 2)  # 80th percentile for 10% target\n",
        "            threshold_val = torch.quantile(attention_scores, percentile)\n",
        "            return threshold_val\n",
        "\n",
        "    def get_selection_statistics(self, selection_masks):\n",
        "        \"\"\"\n",
        "        ì„ íƒ í†µê³„ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§ìš©)\n",
        "\n",
        "        Args:\n",
        "            selection_masks: [batch_size, 16] - binary selection masks\n",
        "\n",
        "        Returns:\n",
        "            dict: ì„ íƒ í†µê³„ ì •ë³´\n",
        "        \"\"\"\n",
        "        num_selected_per_sample = selection_masks.sum(dim=1)  # [batch_size]\n",
        "\n",
        "        stats = {\n",
        "            'mean_selected': num_selected_per_sample.float().mean().item(),\n",
        "            'min_selected': num_selected_per_sample.min().item(),\n",
        "            'max_selected': num_selected_per_sample.max().item(),\n",
        "            'selection_ratio': (num_selected_per_sample.float() / selection_masks.shape[1]).mean().item(),\n",
        "            'std_selected': num_selected_per_sample.float().std().item()\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "\n",
        "# Feature Extractor ì„±ëŠ¥ ë¹„êµ í•¨ìˆ˜\n",
        "def compare_feature_extractors():\n",
        "    \"\"\"\n",
        "    ğŸ”¬ ë‹¤ì–‘í•œ Feature Extractorë“¤ì˜ ì„±ëŠ¥ê³¼ ì†ë„ ë¹„êµ\n",
        "    ì‹¤ì œ ì„ íƒì— ë„ì›€ì„ ì£¼ëŠ” ë²¤ì¹˜ë§ˆí¬\n",
        "    \"\"\"\n",
        "    print(\"ğŸ”¬ Feature Extractor ì„±ëŠ¥ ë¹„êµ\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ ë°ì´í„°\n",
        "    dummy_lr = torch.randn(4, 3, 64, 64)    # LR íŒ¨ì¹˜ë“¤\n",
        "    dummy_hr = torch.randn(4, 3, 256, 256)  # HR íŒ¨ì¹˜ë“¤\n",
        "\n",
        "    extractors = {\n",
        "        'ResNet18': ResNetFeatureExtractor(feature_dim=256, model_type='resnet18'),\n",
        "        'MobileNetV3': ResNetFeatureExtractor(feature_dim=256, model_type='mobilenet'),\n",
        "        'EfficientNet-B0': ResNetFeatureExtractor(feature_dim=256, model_type='efficientnet')\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, extractor in extractors.items():\n",
        "        print(f\"\\nğŸ“Š {name} í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
        "\n",
        "        # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
        "        total_params = sum(p.numel() for p in extractor.parameters())\n",
        "        trainable_params = sum(p.numel() for p in extractor.parameters() if p.requires_grad)\n",
        "\n",
        "        # ì†ë„ ì¸¡ì • (LR íŒ¨ì¹˜)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10ë²ˆ ë°˜ë³µ ì¸¡ì •\n",
        "                _ = extractor(dummy_lr)\n",
        "        lr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        # ì†ë„ ì¸¡ì • (HR íŒ¨ì¹˜)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10ë²ˆ ë°˜ë³µ ì¸¡ì •\n",
        "                _ = extractor(dummy_hr)\n",
        "        hr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        results[name] = {\n",
        "            'total_params': total_params,\n",
        "            'trainable_params': trainable_params,\n",
        "            'lr_time_ms': lr_time * 1000,\n",
        "            'hr_time_ms': hr_time * 1000\n",
        "        }\n",
        "\n",
        "        print(f\"   íŒŒë¼ë¯¸í„° ìˆ˜: {total_params/1e6:.1f}M\")\n",
        "        print(f\"   LR ì²˜ë¦¬ ì†ë„: {lr_time*1000:.1f}ms\")\n",
        "        print(f\"   HR ì²˜ë¦¬ ì†ë„: {hr_time*1000:.1f}ms\")\n",
        "\n",
        "    # ì¶”ì²œ ì¶œë ¥\n",
        "    print(f\"\\nğŸ¯ ì¶”ì²œ:\")\n",
        "    print(f\"   - ì•ˆì •ì„± ìš°ì„ : ResNet18 (ê²€ì¦ëœ ì„±ëŠ¥)\")\n",
        "    print(f\"   - ì†ë„ ìš°ì„ : MobileNetV3 (ê°€ì¥ ë¹ ë¦„)\")\n",
        "    print(f\"   - ë°¸ëŸ°ìŠ¤: EfficientNet-B0 (ì„±ëŠ¥-ì†ë„ ì ˆì¶©)\")\n",
        "    print(f\"   - 2ì¼ ì•ˆì— ì™„ì£¼: ResNet18 ë˜ëŠ” MobileNetV3\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ì‚¬ìš©ë²• ì˜ˆì‹œ\n",
        "def example_usage():\n",
        "    \"\"\"Feature Extractorì™€ HR Selector ì‚¬ìš© ì˜ˆì‹œ\"\"\"\n",
        "    print(\"ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:\")\n",
        "\n",
        "    # Feature Extractor ìƒì„±\n",
        "    feature_extractor = ResNetFeatureExtractor(\n",
        "        feature_dim=256,\n",
        "        model_type='resnet18',  # 'resnet18', 'mobilenet', 'efficientnet' ì¤‘ ì„ íƒ\n",
        "        pretrained=True\n",
        "    )\n",
        "\n",
        "    # HR Selector ìƒì„±\n",
        "    hr_selector = ThresholdBasedHRSelector(\n",
        "        target_selection_ratio=0.1,  # 10% ì„ íƒ ëª©í‘œ\n",
        "        min_patches=1,               # ìµœì†Œ 1ê°œ\n",
        "        max_patches=4                # ìµœëŒ€ 4ê°œ\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 4 ì™„ë£Œ: Feature Extractorì™€ HR Selector ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ResNet18 vs MobileNet vs EfficientNet ì¤‘ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqHc2tdeFvDc"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 5: ì‹¤ì œ ë°ì´í„° ë¡œë”© (ë¡œì»¬ ê²½ë¡œ)\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya5dXvOiFvDc",
        "outputId": "83f30392-100e-4bac-feb1-9544f1430efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ  ë¡œì»¬ í™˜ê²½ ì„¤ì • ì™„ë£Œ!\n",
            "ğŸ” ì¤‘ì²© í´ë”ì—ì„œ ë°œê²¬: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\n",
            "\n",
            "ğŸ” í´ë” í™•ì¸:\n",
            "   C_TIL: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\\C_TIL\n",
            "   P_TIL: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\\P_TIL\n",
            "   C_TIL ì´ë¯¸ì§€: 4261ê°œ\n",
            "   P_TIL ì´ë¯¸ì§€: 4446ê°œ\n",
            "\n",
            "ğŸ“‹ ìƒ˜í”Œ íŒŒì¼ëª…:\n",
            "   ._S15-11819,B [d=2.01814,x=18599,y=148794,w=2067,h=2066].png â†’ None\n",
            "   ._S15-16941 [d=2.01814,x=24799,y=169459,w=2067,h=2067].png â†’ None\n",
            "   ._S15-16941 [d=2.01814,x=26866,y=169459,w=2066,h=2067].png â†’ None\n",
            "\n",
            "âœ… Excel íŒŒì¼ ë¡œë“œ: 100ê°œ í–‰\n",
            "ğŸ“‹ ì»¬ëŸ¼: ['Number', 'T', 'Subtype', 'Recur']\n",
            "\n",
            "ğŸ“Š ìƒ˜í”Œ Excel ë°ì´í„°:\n",
            "   S15000922: Subtype=sarc, T=2, Recur=1\n",
            "   S15003203: Subtype=sarc, T=1, Recur=0\n",
            "   S15003380: Subtype=0, T=2, Recur=1\n",
            "   S15004965: Subtype=0, T=1, Recur=0\n",
            "   S15007775: Subtype=0, T=1, Recur=1\n",
            "\n",
            "ğŸ·ï¸ ë¼ë²¨ ë¶„í¬ í™•ì¸:\n",
            "   Subtype ë¶„í¬: {0: np.int64(81), 'sarc': np.int64(7), 'micropapillary': np.int64(4), 'SQ': np.int64(3), 'plasmacytoid': np.int64(2), 'sarcomatoid': np.int64(1), 'giant': np.int64(1), 'small': np.int64(1)}\n",
            "ğŸ“ˆ ìˆ˜ì •ëœ T-stage ë¶„í¬: ì €ìœ„í—˜(0): 100ê°œ, ê³ ìœ„í—˜(1): 0ê°œ\n",
            "\n",
            "ğŸš€ í–¥ìƒëœ ë§¤ì¹­ ì‹œì‘...\n",
            "ğŸ” [ë§¤ì¹­ ì „] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "ğŸ“Š Excel ID ìˆ˜: 100\n",
            "ğŸ“‹ Excel ID ìƒ˜í”Œ: ['S17003467', 'S21008159', 'S20005232', 'S22026444', 'S18000751']\n",
            "\n",
            "ğŸ“ C_TIL: 4261ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C_TIL ë§¤ì¹­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4261/4261 [00:00<00:00, 12970.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   C_TIL ë§¤ì¹­: 2194ê°œ\n",
            "\n",
            "ğŸ“ P_TIL: 4446ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "P_TIL ë§¤ì¹­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4446/4446 [00:00<00:00, 14182.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   P_TIL ë§¤ì¹­: 2193ê°œ\n",
            "\n",
            "âœ… ì „ì²´ ë§¤ì¹­ ê²°ê³¼: 8707ê°œ ì´ë¯¸ì§€ ì¤‘ 4387ê°œ ë§¤ì¹­\n",
            "\n",
            "ğŸ‘¥ í™˜ìë³„ ë°ì´í„°:\n",
            "   ì´ í™˜ì: 100ëª…\n",
            "   ì´ ì´ë¯¸ì§€: 4387ê°œ\n",
            "   í™˜ìë³„ í‰ê·  ì´ë¯¸ì§€: 43.9ê°œ\n",
            "   T-stage ë¶„í¬: ì €ìœ„í—˜(0)=64ëª…, ê³ ìœ„í—˜(1)=36ëª…\n",
            "\n",
            "ğŸ‘¤ ìƒ˜í”Œ í™˜ì (S15011819):\n",
            "   ì´ë¯¸ì§€ ìˆ˜: 94ê°œ\n",
            "   T-stage: T2\n",
            "   ì¬ë°œ: Yes\n",
            "\n",
            "âœ… ì„±ê³µ! 100ëª…ì˜ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n",
            "ğŸ”¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 20ëª…ìœ¼ë¡œ ì œí•œ\n",
            "ğŸ’¾ ë°ì´í„° ì €ì¥: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\\cache\\patient_data.pkl\n",
            "ğŸ” [ë§¤ì¹­ í›„] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "\n",
            "================================================================================\n",
            "Part 5 ì™„ë£Œ: í–¥ìƒëœ ë°ì´í„° ë¡œë”©!\n",
            "ìµœì¢… í™˜ì ìˆ˜: 20ëª…\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 5: ì™„ì „ ìˆ˜ì •ëœ ë°ì´í„° ë¡œë”©\n",
        "# ========================================================================\n",
        "\n",
        "import re\n",
        "from tqdm import tqdm  # notebook ëŒ€ì‹  ì¼ë°˜ tqdm ì‚¬ìš©\n",
        "\n",
        "\n",
        "# ğŸ  ë¡œì»¬ ê²½ë¡œ ì„¤ì •\n",
        "zip_path = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710.zip\"\n",
        "excel_path = r\"C:\\Users\\ehdwk\\Downloads\\MIL_TURB_240918_Modified.xlsx\"\n",
        "base_dir = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\"\n",
        "\n",
        "# ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "checkpoint_dir = os.path.join(work_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(work_dir, \"logs\")\n",
        "cache_dir = os.path.join(work_dir, \"cache\")\n",
        "result_dir = os.path.join(work_dir, \"results\")\n",
        "\n",
        "for directory in [work_dir, checkpoint_dir, log_dir, cache_dir, result_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ  ë¡œì»¬ í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n",
        "\n",
        "# ğŸ” ì‹¤ì œ ë°ì´í„° í´ë” ì°¾ê¸°\n",
        "def find_data_folders(base_dir):\n",
        "    \"\"\"ì¤‘ì²©ëœ í´ë” êµ¬ì¡°ì—ì„œ ì‹¤ì œ C_TIL, P_TIL í´ë” ì°¾ê¸°\"\"\"\n",
        "\n",
        "    # 1ì°¨: ì§ì ‘ í™•ì¸\n",
        "    c_til_dir = os.path.join(base_dir, \"C_TIL\")\n",
        "    p_til_dir = os.path.join(base_dir, \"P_TIL\")\n",
        "\n",
        "    if os.path.exists(c_til_dir) and os.path.exists(p_til_dir):\n",
        "        return c_til_dir, p_til_dir\n",
        "\n",
        "    # 2ì°¨: í•˜ìœ„ í´ë”ì—ì„œ ì°¾ê¸°\n",
        "    for item in os.listdir(base_dir):\n",
        "        item_path = os.path.join(base_dir, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            nested_c_til = os.path.join(item_path, \"C_TIL\")\n",
        "            nested_p_til = os.path.join(item_path, \"P_TIL\")\n",
        "\n",
        "            if os.path.exists(nested_c_til) and os.path.exists(nested_p_til):\n",
        "                print(f\"ğŸ” ì¤‘ì²© í´ë”ì—ì„œ ë°œê²¬: {item_path}\")\n",
        "                return nested_c_til, nested_p_til\n",
        "\n",
        "    return None, None\n",
        "\n",
        "# ğŸ”§ ë³µì¡í•œ íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ\n",
        "def extract_patient_id_advanced(filename):\n",
        "    \"\"\"\n",
        "    ì‹¤ì œ ì‘ë™í–ˆë˜ ë¡œì§ + ìˆ¨ê¹€íŒŒì¼ í•„í„°\n",
        "    \"\"\"\n",
        "    # ìˆ¨ê¹€íŒŒì¼ ì œê±°\n",
        "    if filename.startswith('._'):\n",
        "        return None\n",
        "\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # ëŒ€ê´„í˜¸ ì• ë¶€ë¶„ë§Œ ì‚¬ìš© (ì¢Œí‘œ ì •ë³´ ì œê±°)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # íŒ¨í„´ 1: S15-3380 í˜•ì‹\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)  # ì˜ˆ: \"15\"\n",
        "        patch = m1.group(2)  # ì˜ˆ: \"3380\"\n",
        "\n",
        "        # íŒ¨ì¹˜ ë²ˆí˜¸ ê¸¸ì´ì— ë”°ë¼ íŒ¨ë”© ì¶”ê°€\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch\n",
        "        else:\n",
        "            patch_padded = patch\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # íŒ¨í„´ 2: S16022792,1A í˜•ì‹\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\"\n",
        "\n",
        "    # íŒ¨í„´ 3: S16021286 í˜•ì‹ (ì´ë¯¸ ì™„ì„±ëœ í˜•ì‹)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# ì‹¤ì œ ë°ì´í„° í´ë” ì°¾ê¸°\n",
        "c_til_dir, p_til_dir = find_data_folders(base_dir)\n",
        "\n",
        "print(f\"\\nğŸ” í´ë” í™•ì¸:\")\n",
        "print(f\"   C_TIL: {c_til_dir}\")\n",
        "print(f\"   P_TIL: {p_til_dir}\")\n",
        "\n",
        "if c_til_dir and p_til_dir:\n",
        "    c_images = [f for f in os.listdir(c_til_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    p_images = [f for f in os.listdir(p_til_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"   C_TIL ì´ë¯¸ì§€: {len(c_images)}ê°œ\")\n",
        "    print(f\"   P_TIL ì´ë¯¸ì§€: {len(p_images)}ê°œ\")\n",
        "\n",
        "    # ìƒ˜í”Œ íŒŒì¼ëª… í™•ì¸\n",
        "    print(f\"\\nğŸ“‹ ìƒ˜í”Œ íŒŒì¼ëª…:\")\n",
        "    for i, filename in enumerate(c_images[:3]):\n",
        "        extracted_id = extract_patient_id_advanced(filename)\n",
        "        print(f\"   {filename} â†’ {extracted_id}\")\n",
        "\n",
        "# Excel íŒŒì¼ ë¡œë“œ ë° ë¼ë²¨ í™•ì¸\n",
        "try:\n",
        "    labels_df = pd.read_excel(excel_path)\n",
        "    print(f\"\\nâœ… Excel íŒŒì¼ ë¡œë“œ: {len(labels_df)}ê°œ í–‰\")\n",
        "    print(f\"ğŸ“‹ ì»¬ëŸ¼: {list(labels_df.columns)}\")\n",
        "\n",
        "    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
        "    print(f\"\\nğŸ“Š ìƒ˜í”Œ Excel ë°ì´í„°:\")\n",
        "    for i in range(min(5, len(labels_df))):\n",
        "        row = labels_df.iloc[i]\n",
        "        print(f\"   {row['Number']}: Subtype={row.get('Subtype', 'N/A')}, T={row.get('T', 'N/A')}, Recur={row.get('Recur', 'N/A')}\")\n",
        "\n",
        "    # Subtype ë¶„í¬ í™•ì¸ (ìˆ˜ì •ëœ ë¡œì§)\n",
        "    print(f\"\\nğŸ·ï¸ ë¼ë²¨ ë¶„í¬ í™•ì¸:\")\n",
        "    if 'Subtype' in labels_df.columns:\n",
        "        subtype_counts = labels_df['Subtype'].value_counts()\n",
        "        print(f\"   Subtype ë¶„í¬: {dict(subtype_counts)}\")\n",
        "\n",
        "        # ì˜¬ë°”ë¥¸ ë¼ë²¨ ë³€í™˜: Subtype 1â†’0, Subtype 2â†’1\n",
        "        t_labels_corrected = []\n",
        "        for _, row in labels_df.iterrows():\n",
        "            subtype = row['Subtype']\n",
        "            if subtype == 1:\n",
        "                t_label = 0  # ì €ìœ„í—˜\n",
        "            elif subtype == 2:\n",
        "                t_label = 1  # ê³ ìœ„í—˜\n",
        "            else:\n",
        "                t_label = 0  # ê¸°ë³¸ê°’\n",
        "            t_labels_corrected.append(t_label)\n",
        "\n",
        "        print(f\"ğŸ“ˆ ìˆ˜ì •ëœ T-stage ë¶„í¬: ì €ìœ„í—˜(0): {t_labels_corrected.count(0)}ê°œ, ê³ ìœ„í—˜(1): {t_labels_corrected.count(1)}ê°œ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Excel íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
        "    labels_df = None\n",
        "\n",
        "# í–¥ìƒëœ ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­\n",
        "def match_images_with_labels_v2(c_til_dir, p_til_dir, labels_df):\n",
        "    \"\"\"í–¥ìƒëœ ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­\"\"\"\n",
        "\n",
        "    if not c_til_dir or not p_til_dir or labels_df is None:\n",
        "        print(\"âŒ í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return []\n",
        "\n",
        "    # Excel IDë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì§‘í•© ìƒì„±\n",
        "    excel_ids = set(str(id_val) for id_val in labels_df['Number'].values)\n",
        "    print(f\"ğŸ“Š Excel ID ìˆ˜: {len(excel_ids)}\")\n",
        "    print(f\"ğŸ“‹ Excel ID ìƒ˜í”Œ: {list(excel_ids)[:5]}\")\n",
        "\n",
        "    matched_samples = []\n",
        "    total_images = 0\n",
        "    matched_images = 0\n",
        "\n",
        "    # ë‘ í´ë” ëª¨ë‘ ì²˜ë¦¬\n",
        "    for folder_name, data_dir in [(\"C_TIL\", c_til_dir), (\"P_TIL\", p_til_dir)]:\n",
        "        if not os.path.exists(data_dir):\n",
        "            continue\n",
        "\n",
        "        image_files = [f for f in os.listdir(data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        total_images += len(image_files)\n",
        "        print(f\"\\nğŸ“ {folder_name}: {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬\")\n",
        "\n",
        "        folder_matched = 0\n",
        "\n",
        "        for filename in tqdm(image_files, desc=f\"{folder_name} ë§¤ì¹­\"):\n",
        "            # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ\n",
        "            patient_id = extract_patient_id_advanced(filename)\n",
        "\n",
        "            if patient_id and patient_id in excel_ids:\n",
        "                # Excelì—ì„œ í•´ë‹¹ í™˜ì ì •ë³´ ì°¾ê¸°\n",
        "                patient_row = labels_df[labels_df['Number'] == patient_id]\n",
        "\n",
        "                if not patient_row.empty:\n",
        "                    row = patient_row.iloc[0]\n",
        "\n",
        "                    # T ì»¬ëŸ¼ë§Œ ì‚¬ìš© (ê°„ë‹¨!)\n",
        "                    t_value = row.get('T', 1)\n",
        "                    t_label = 0 if t_value == 1 else 1  # T=1â†’0(ì €ìœ„í—˜), T=2â†’1(ê³ ìœ„í—˜)\n",
        "\n",
        "                    # ì¬ë°œ ë¼ë²¨\n",
        "                    recur = row.get('Recur', None)\n",
        "                    recur_label = int(recur) if pd.notna(recur) else None\n",
        "\n",
        "                    matched_samples.append({\n",
        "                        'patient_id': patient_id,\n",
        "                        'image_path': os.path.join(data_dir, filename),\n",
        "                        't_label': t_label,\n",
        "                        'recur_label': recur_label,\n",
        "                        'subtype': t_value,  # T ê°’ ì €ì¥\n",
        "                        'folder': folder_name\n",
        "                    })\n",
        "\n",
        "                    matched_images += 1\n",
        "                    folder_matched += 1\n",
        "\n",
        "        print(f\"   {folder_name} ë§¤ì¹­: {folder_matched}ê°œ\")\n",
        "\n",
        "    print(f\"\\nâœ… ì „ì²´ ë§¤ì¹­ ê²°ê³¼: {total_images}ê°œ ì´ë¯¸ì§€ ì¤‘ {matched_images}ê°œ ë§¤ì¹­\")\n",
        "    return matched_samples\n",
        "\n",
        "# í™˜ìë³„ ê·¸ë£¹í™” (ê°œì„ ë¨)\n",
        "def group_by_patient_v2(matched_samples):\n",
        "    \"\"\"í™˜ìë³„ ë°ì´í„° ê·¸ë£¹í™” (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
        "\n",
        "    patient_data = {}\n",
        "\n",
        "    for sample in matched_samples:\n",
        "        patient_id = sample['patient_id']\n",
        "\n",
        "        if patient_id not in patient_data:\n",
        "            patient_data[patient_id] = {\n",
        "                't_label': sample['t_label'],\n",
        "                'recur_label': sample['recur_label'],\n",
        "                'images': [],\n",
        "                't_stage': f\"T{sample['subtype']}\",  # T1 ë˜ëŠ” T2\n",
        "                'recurrence': 'No' if sample['recur_label'] == 0 else 'Yes' if sample['recur_label'] == 1 else 'Unknown'\n",
        "            }\n",
        "\n",
        "        patient_data[patient_id]['images'].append(sample['image_path'])\n",
        "\n",
        "    # í†µê³„\n",
        "    if patient_data:\n",
        "        image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "        t_distribution = [info['t_label'] for info in patient_data.values()]\n",
        "\n",
        "        print(f\"\\nğŸ‘¥ í™˜ìë³„ ë°ì´í„°:\")\n",
        "        print(f\"   ì´ í™˜ì: {len(patient_data)}ëª…\")\n",
        "        print(f\"   ì´ ì´ë¯¸ì§€: {sum(image_counts)}ê°œ\")\n",
        "        print(f\"   í™˜ìë³„ í‰ê·  ì´ë¯¸ì§€: {np.mean(image_counts):.1f}ê°œ\")\n",
        "        print(f\"   T-stage ë¶„í¬: ì €ìœ„í—˜(0)={t_distribution.count(0)}ëª…, ê³ ìœ„í—˜(1)={t_distribution.count(1)}ëª…\")\n",
        "\n",
        "        # ìƒ˜í”Œ í™˜ì ì •ë³´\n",
        "        sample_id = list(patient_data.keys())[0]\n",
        "        sample_info = patient_data[sample_id]\n",
        "        print(f\"\\nğŸ‘¤ ìƒ˜í”Œ í™˜ì ({sample_id}):\")\n",
        "        print(f\"   ì´ë¯¸ì§€ ìˆ˜: {len(sample_info['images'])}ê°œ\")\n",
        "        print(f\"   T-stage: {sample_info['t_stage']}\")\n",
        "        print(f\"   ì¬ë°œ: {sample_info['recurrence']}\")\n",
        "\n",
        "    return patient_data\n",
        "\n",
        "# ì‹¤í–‰\n",
        "print(f\"\\nğŸš€ í–¥ìƒëœ ë§¤ì¹­ ì‹œì‘...\")\n",
        "log_gpu_memory(\"ë§¤ì¹­ ì „\")\n",
        "\n",
        "try:\n",
        "    all_samples = match_images_with_labels_v2(c_til_dir, p_til_dir, labels_df)\n",
        "    patient_data = group_by_patient_v2(all_samples)\n",
        "\n",
        "    if patient_data and len(patient_data) > 0:\n",
        "        print(f\"\\nâœ… ì„±ê³µ! {len(patient_data)}ëª…ì˜ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
        "\n",
        "        # 20ëª…ìœ¼ë¡œ ì œí•œ (í…ŒìŠ¤íŠ¸)\n",
        "        if len(patient_data) > 20:\n",
        "            limited_ids = list(patient_data.keys())[:20]\n",
        "            patient_data = {pid: patient_data[pid] for pid in limited_ids}\n",
        "            print(f\"ğŸ”¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ {len(patient_data)}ëª…ìœ¼ë¡œ ì œí•œ\")\n",
        "\n",
        "        # ì €ì¥\n",
        "        data_save_path = os.path.join(cache_dir, \"patient_data.pkl\")\n",
        "        with open(data_save_path, 'wb') as f:\n",
        "            pickle.dump(patient_data, f)\n",
        "        print(f\"ğŸ’¾ ë°ì´í„° ì €ì¥: {data_save_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ í™˜ì ë°ì´í„° ìƒì„± ì‹¤íŒ¨ - ë§¤ì¹­ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤\")\n",
        "        patient_data = {}\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    patient_data = {}\n",
        "\n",
        "log_gpu_memory(\"ë§¤ì¹­ í›„\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 5 ì™„ë£Œ: í–¥ìƒëœ ë°ì´í„° ë¡œë”©!\")\n",
        "print(f\"ìµœì¢… í™˜ì ìˆ˜: {len(patient_data) if patient_data else 0}ëª…\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozWjJnVTFvDd"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 6: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention\n",
        "# ========================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y3qGrfSFvDd",
        "outputId": "7bfc8244-514d-47e3-80b8-e76f4b53a9e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\\checkpoints\n",
            "âœ… Flash Attention í™œì„±í™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)\n",
            "âœ… CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\n",
            "âœ… GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
            "\n",
            "================================================================================\n",
            "Part 6 ì™„ë£Œ: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention ì¤€ë¹„ ì™„ë£Œ!\n",
            "ì´ì œ í›ˆë ¨ ì¤‘ë‹¨ë˜ì–´ë„ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class CheckpointManager:\n",
        "    \"\"\"\n",
        "    ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
        "\n",
        "    ê¸°ëŠ¥:\n",
        "    - ë§¤ epochë§ˆë‹¤ ëª¨ë¸ ìƒíƒœ ìë™ ì €ì¥\n",
        "    - í›ˆë ¨ ì¤‘ë‹¨ì‹œ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥\n",
        "    - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ì¥\n",
        "    - í›ˆë ¨ ë¡œê·¸ ë° í†µê³„ ì €ì¥\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir, max_keep=5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            checkpoint_dir (str): ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "            max_keep (int): ìµœëŒ€ ë³´ê´€í•  ì²´í¬í¬ì¸íŠ¸ ê°œìˆ˜ (ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ)\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.max_keep = max_keep\n",
        "        self.best_score = 0.0\n",
        "        self.training_log = []\n",
        "\n",
        "        # ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        print(f\"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”: {checkpoint_dir}\")\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, fold,\n",
        "                       train_loss, val_metrics=None, is_best=False):\n",
        "        \"\"\"\n",
        "        ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë§¤ epochë§ˆë‹¤ í˜¸ì¶œ)\n",
        "\n",
        "        Args:\n",
        "            model: í›ˆë ¨ ì¤‘ì¸ ëª¨ë¸\n",
        "            optimizer: ì˜µí‹°ë§ˆì´ì €\n",
        "            scheduler: ìŠ¤ì¼€ì¤„ëŸ¬\n",
        "            epoch: í˜„ì¬ epoch\n",
        "            fold: í˜„ì¬ fold ë²ˆí˜¸\n",
        "            train_loss: í›ˆë ¨ loss\n",
        "            val_metrics: ê²€ì¦ ë©”íŠ¸ë¦­ë“¤ (dict)\n",
        "            is_best: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì¸ì§€ ì—¬ë¶€\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ì •ë³´\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.module.state_dict() if hasattr(model, 'module') else model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp,\n",
        "            'best_score': self.best_score\n",
        "        }\n",
        "\n",
        "        # ì •ê·œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
        "        checkpoint_path = os.path.join(\n",
        "            self.checkpoint_dir,\n",
        "            f\"checkpoint_fold{fold}_epoch{epoch:03d}_{timestamp}.pt\"\n",
        "        )\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "        # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ë¡œ ë§í¬ (ì¬ì‹œì‘ ì‹œ ì‚¬ìš©)\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ì¥\n",
        "        if is_best:\n",
        "            best_path = os.path.join(self.checkpoint_dir, f\"best_model_fold{fold}.pt\")\n",
        "            torch.save(checkpoint, best_path)\n",
        "            self.best_score = val_metrics.get('f1', 0.0) if val_metrics else 0.0\n",
        "            print(f\"ğŸ† ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥! F1: {self.best_score:.4f}\")\n",
        "\n",
        "        # í›ˆë ¨ ë¡œê·¸ ì—…ë°ì´íŠ¸\n",
        "        log_entry = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "        self.training_log.append(log_entry)\n",
        "\n",
        "        # ë¡œê·¸ íŒŒì¼ ì €ì¥\n",
        "        log_path = os.path.join(self.checkpoint_dir, f\"training_log_fold{fold}.json\")\n",
        "        with open(log_path, 'w') as f:\n",
        "            json.dump(self.training_log, f, indent=2)\n",
        "\n",
        "        print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold {fold}, Epoch {epoch}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬\n",
        "        self._cleanup_old_checkpoints(fold)\n",
        "\n",
        "    def _cleanup_old_checkpoints(self, fold):\n",
        "        \"\"\"ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì •ë¦¬\"\"\"\n",
        "        import glob\n",
        "\n",
        "        # í•´ë‹¹ foldì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì°¾ê¸°\n",
        "        pattern = os.path.join(self.checkpoint_dir, f\"checkpoint_fold{fold}_*.pt\")\n",
        "        checkpoints = glob.glob(pattern)\n",
        "\n",
        "        # ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
        "        checkpoints.sort(key=os.path.getctime)\n",
        "\n",
        "        # max_keep ê°œìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ\n",
        "        while len(checkpoints) > self.max_keep:\n",
        "            old_checkpoint = checkpoints.pop(0)\n",
        "            try:\n",
        "                os.remove(old_checkpoint)\n",
        "                print(f\"ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: {os.path.basename(old_checkpoint)}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    def load_latest_checkpoint(self, fold):\n",
        "        \"\"\"\n",
        "        ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë¡œë”© (ì¬ì‹œì‘ ì‹œ ì‚¬ìš©)\n",
        "\n",
        "        Args:\n",
        "            fold: ë¡œë”©í•  fold ë²ˆí˜¸\n",
        "\n",
        "        Returns:\n",
        "            dict or None: ì²´í¬í¬ì¸íŠ¸ ë°ì´í„°, ì—†ìœ¼ë©´ None\n",
        "        \"\"\"\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "\n",
        "        if os.path.exists(latest_path):\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            print(f\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: Fold {fold}, Epoch {checkpoint['epoch']}\")\n",
        "            return checkpoint\n",
        "        else:\n",
        "            print(f\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ: Fold {fold} (ì²˜ìŒë¶€í„° ì‹œì‘)\")\n",
        "            return None\n",
        "\n",
        "\n",
        "class HierarchicalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬: Hierarchical Self-Attention\n",
        "\n",
        "    í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - ì¼ë°˜ Self-Attention: O(nÂ²) - ëª¨ë“  í† í°ì´ ëª¨ë“  í† í°ê³¼ ìƒí˜¸ì‘ìš©\n",
        "    - Hierarchical: O(nÃ—M) - ì„ íƒëœ HR í† í°ë§Œ ìƒí˜¸ì‘ìš© (M << n)\n",
        "    - ê³„ì‚°ëŸ‰ ëŒ€í­ ê°ì†Œí•˜ë©´ì„œ ì„±ëŠ¥ ìœ ì§€!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_heads=4, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): feature ì°¨ì› (256 ì¶”ì²œ, 384ëŠ” ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)\n",
        "            num_heads (int): attention head ê°œìˆ˜ (4 ì¶”ì²œ, 6ì€ ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)\n",
        "            dropout (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
        "        \"\"\"\n",
        "        super(HierarchicalSelfAttention, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = feature_dim // num_heads\n",
        "\n",
        "        # feature_dimì´ num_headsë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ëŠ”ì§€ í™•ì¸\n",
        "        assert feature_dim % num_heads == 0, f\"feature_dim({feature_dim})ì´ num_heads({num_heads})ë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤!\"\n",
        "\n",
        "        # ğŸ”µ ì¼ë°˜ hidden statesìš© projections (LR + Global + CLS tokens)\n",
        "        self.q_proj = nn.Linear(feature_dim, feature_dim)  # Query projection\n",
        "        self.k_proj = nn.Linear(feature_dim, feature_dim)  # Key projection\n",
        "        self.v_proj = nn.Linear(feature_dim, feature_dim)  # Value projection\n",
        "\n",
        "        # ğŸ”´ HR features ì „ìš© projections (ë…¼ë¬¸ì˜ W'_K, W'_V)\n",
        "        # ì¤‘ìš”: HR featuresëŠ” ë³„ë„ì˜ projectionì„ ì‚¬ìš©!\n",
        "        self.k_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_K for HR\n",
        "        self.v_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_V for HR\n",
        "\n",
        "        # ì¶œë ¥ projection\n",
        "        self.out_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = math.sqrt(self.head_dim)  # attention scaling factor\n",
        "\n",
        "        print(f\"âœ… Hierarchical Self-Attention ì´ˆê¸°í™”\")\n",
        "        print(f\"   - Feature dim: {feature_dim}, Heads: {num_heads}, Head dim: {self.head_dim}\")\n",
        "\n",
        "    def forward(self, hidden_states, selected_hr_features):\n",
        "        \"\"\"\n",
        "        Hierarchical Self-Attention ê³„ì‚° (ë…¼ë¬¸ì˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜)\n",
        "\n",
        "        Args:\n",
        "            hidden_states: [batch_size, N, feature_dim]\n",
        "                          N = LR tokens + Global tokens + CLS token\n",
        "            selected_hr_features: [batch_size, M, feature_dim]\n",
        "                                M = ì„ íƒëœ HR tokens (ë³´í†µ 1~4ê°œ)\n",
        "\n",
        "        Returns:\n",
        "            output: [batch_size, N, feature_dim] - ì—…ë°ì´íŠ¸ëœ hidden states\n",
        "            attention_map: [batch_size, N-1] - CLS tokenì˜ attention (ë‹¤ìŒ layerìš©)\n",
        "        \"\"\"\n",
        "        batch_size, N, _ = hidden_states.shape          # N: LR + Global + CLS ê°œìˆ˜\n",
        "        _, M, _ = selected_hr_features.shape            # M: ì„ íƒëœ HR ê°œìˆ˜\n",
        "\n",
        "        # ğŸ”µ Step 1: ì¼ë°˜ hidden statesì— ëŒ€í•œ Q, K, V ê³„ì‚°\n",
        "        Q = self.q_proj(hidden_states)      # [B, N, D] - Query (ì–´ë””ì— ì§‘ì¤‘í• ì§€?)\n",
        "        K_h = self.k_proj(hidden_states)    # [B, N, D] - Key (ë‚˜ëŠ” ì´ëŸ° ì •ë³´ì•¼)\n",
        "        V_h = self.v_proj(hidden_states)    # [B, N, D] - Value (ì‹¤ì œ ì „ë‹¬í•  ì •ë³´)\n",
        "\n",
        "        # ğŸ”´ Step 2: HR featuresì— ëŒ€í•œ ë³„ë„ K, V ê³„ì‚° (ë…¼ë¬¸ì˜ í•µì‹¬!)\n",
        "        K_hr = self.k_proj_hr(selected_hr_features)  # [B, M, D] - HRìš© Key\n",
        "        V_hr = self.v_proj_hr(selected_hr_features)  # [B, M, D] - HRìš© Value\n",
        "\n",
        "        # ğŸ”— Step 3: Keyì™€ Valueë¥¼ ì—°ê²° [ì¼ë°˜ tokens + HR tokens]\n",
        "        K_all = torch.cat([K_h, K_hr], dim=1)  # [B, N+M, D] - ëª¨ë“  Keys\n",
        "        V_all = torch.cat([V_h, V_hr], dim=1)  # [B, N+M, D] - ëª¨ë“  Values\n",
        "\n",
        "        # ğŸ§  Step 4: Multi-head attentionì„ ìœ„í•œ reshape\n",
        "        # [B, seq_len, D] â†’ [B, num_heads, seq_len, head_dim]\n",
        "        Q = Q.view(batch_size, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K_all = K_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V_all = V_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # âš¡ Step 5: Attention ê³„ì‚° - ì—¬ê¸°ì„œ ê³„ì‚°ëŸ‰ O(NÃ—(N+M))\n",
        "        # ì¼ë°˜ Self-Attentionì´ë¼ë©´ O((N+M)Â²)ì´ì§€ë§Œ,\n",
        "        # QueryëŠ” Nê°œë¿ì´ë¯€ë¡œ O(NÃ—(N+M)) = O(NÂ²+NM)\n",
        "        scores = torch.matmul(Q, K_all.transpose(-2, -1)) / self.scale  # [B, H, N, N+M]\n",
        "        attention_weights = F.softmax(scores, dim=-1)                   # attention í™•ë¥ \n",
        "        attention_weights = self.dropout(attention_weights)             # ë“œë¡­ì•„ì›ƒ ì ìš©\n",
        "\n",
        "        # ğŸ¯ Step 6: Attention ì ìš©í•˜ì—¬ ì •ë³´ ì§‘ì•½\n",
        "        attended = torch.matmul(attention_weights, V_all)  # [B, H, N, head_dim]\n",
        "\n",
        "        # ğŸ”„ Step 7: Multi-head ê²°ê³¼ í•©ì¹˜ê¸°\n",
        "        attended = attended.transpose(1, 2).contiguous()  # [B, N, H, head_dim]\n",
        "        attended = attended.view(batch_size, N, self.feature_dim)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“¤ Step 8: ìµœì¢… ì¶œë ¥ projection\n",
        "        output = self.out_proj(attended)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“Š Step 9: ë‹¤ìŒ layerìš© attention map ì¶”ì¶œ\n",
        "        # CLS token (ë§ˆì§€ë§‰ í† í°)ì´ LR tokensì— ì£¼ëŠ” attention\n",
        "        cls_attention = attention_weights[:, :, -1, :N-1]  # [B, H, N-1] - CLS â†’ LR\n",
        "        attention_map = cls_attention.mean(dim=1)          # [B, N-1] - head í‰ê· \n",
        "\n",
        "        return output, attention_map\n",
        "\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í•¨ìˆ˜ë“¤\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ì„¤ì •\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ attention ì‚¬ìš© (PyTorch 2.0+)\n",
        "        try:\n",
        "            torch.backends.cuda.enable_flash_sdp(True)\n",
        "            print(\"âœ… Flash Attention í™œì„±í™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)\")\n",
        "        except:\n",
        "            print(\"âš ï¸  Flash Attention ë¯¸ì§€ì› (PyTorch ë²„ì „ í™•ì¸)\")\n",
        "\n",
        "        # CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "        print(\"âœ… CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"âœ… GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
        "\n",
        "def log_model_info(model):\n",
        "    \"\"\"ëª¨ë¸ ì •ë³´ ë¡œê¹…\"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"ğŸ” ëª¨ë¸ ì •ë³´:\")\n",
        "    print(f\"   - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ ({total_params/1e6:.1f}M)\")\n",
        "    print(f\"   - í›ˆë ¨ ê°€ëŠ¥: {trainable_params:,}ê°œ ({trainable_params/1e6:.1f}M)\")\n",
        "    print(f\"   - ëª¨ë¸ í¬ê¸°: {total_params * 4 / 1024**2:.1f}MB (float32 ê¸°ì¤€)\")\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    max_keep=3  # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ ë³´ê´€ (ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½)\n",
        ")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰\n",
        "optimize_memory_usage()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 6 ì™„ë£Œ: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ í›ˆë ¨ ì¤‘ë‹¨ë˜ì–´ë„ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1p4fmUNFvDe"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 7: ì™„ì „í•œ MIL ëª¨ë¸ê³¼ Dataset\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ì¼ê³± ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì™„ì „í•œ FlexAttention MIL ëª¨ë¸ê³¼ Datasetì„ êµ¬í˜„í•©ë‹ˆë‹¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKnx_vVnFvDe",
        "outputId": "969e7632-01ad-45ae-9698-5fac53430370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 7 ì™„ë£Œ: Feature Dimension í†µì¼ëœ FlexAttention MIL ëª¨ë¸!\n",
            "ëª¨ë“  Feature Extractorê°€ 256 ì°¨ì›ìœ¼ë¡œ í†µì¼ë˜ì–´ í…ì„œ í¬ê¸° ì˜¤ë¥˜ê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class FlexAttentionPatientMIL(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ ì™„ì „í•œ FlexAttention Multiple Instance Learning ëª¨ë¸\n",
        "\n",
        "    ì „ì²´ êµ¬ì¡°:\n",
        "    1. í™˜ìë³„ ì—¬ëŸ¬ ë©”ê°€íŒ¨ì¹˜ â†’ ê°ê° 8ê°œ íŒ¨ì¹˜ â†’ 3-stream features\n",
        "    2. LR + Global tokens â†’ Standard Self-Attention layers\n",
        "    3. LR attention â†’ HR selection â†’ FlexAttention layers\n",
        "    4. CLS token â†’ Patient-level classification (ì•” ë‹¨ê³„/ì¬ë°œ ì˜ˆì¸¡)\n",
        "\n",
        "    ê³„ì‚°ëŸ‰ ìµœì í™”:\n",
        "    - ë©”ê°€íŒ¨ì¹˜ë‹¹ 16ê°œ â†’ 8ê°œ íŒ¨ì¹˜ë¡œ ê°ì†Œ (50% ì ˆì•½)\n",
        "    - Feature dim 384 â†’ 256ë¡œ ê°ì†Œ (33% ì ˆì•½)\n",
        "    - FA layers 2ê°œ â†’ 1ê°œë¡œ ê°ì†Œ (50% ì ˆì•½)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_classes=2, num_heads=4,\n",
        "                 num_sa_layers=1, num_fa_layers=1, dropout=0.1,\n",
        "                 extractor_type='resnet18'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): Feature ì°¨ì› (256 ì¶”ì²œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "            num_classes (int): ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜ (2: binary classification)\n",
        "            num_heads (int): Attention head ìˆ˜ (4 ì¶”ì²œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "            num_sa_layers (int): Standard Self-Attention layer ìˆ˜\n",
        "            num_fa_layers (int): FlexAttention layer ìˆ˜\n",
        "            dropout (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
        "            extractor_type (str): Feature extractor íƒ€ì… ('resnet18', 'mobilenet')\n",
        "        \"\"\"\n",
        "        super(FlexAttentionPatientMIL, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_sa_layers = num_sa_layers\n",
        "        self.num_fa_layers = num_fa_layers\n",
        "\n",
        "        print(f\"ğŸ—ï¸  FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
        "        print(f\"   - Feature dim: {feature_dim}\")\n",
        "        print(f\"   - Attention heads: {num_heads}\")\n",
        "        print(f\"   - SA layers: {num_sa_layers}, FA layers: {num_fa_layers}\")\n",
        "        print(f\"   - Extractor: {extractor_type}\")\n",
        "\n",
        "        # ğŸ”¬ Feature extractors (3ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ í•´ìƒë„ìš©) - ëª¨ë‘ 256 ì°¨ì›ìœ¼ë¡œ í†µì¼!\n",
        "        if extractor_type == 'resnet18':\n",
        "            self.lr_extractor = ResNetFeatureExtractor(feature_dim=feature_dim)    # 256ìœ¼ë¡œ í†µì¼\n",
        "            self.global_extractor = ResNetFeatureExtractor(feature_dim=feature_dim) # 256ìœ¼ë¡œ í†µì¼\n",
        "            self.hr_extractor = ResNetFeatureExtractor(feature_dim=feature_dim)    # 256ìœ¼ë¡œ í†µì¼\n",
        "        elif extractor_type == 'mobilenet':\n",
        "            self.lr_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "            self.global_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "            self.hr_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "        else:\n",
        "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” extractor_type: {extractor_type}\")\n",
        "\n",
        "        # ğŸ¯ CLS token (í™˜ì ë ˆë²¨ ë¶„ë¥˜ë¥¼ ìœ„í•œ íŠ¹ë³„í•œ í† í°)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, feature_dim))\n",
        "\n",
        "        # ğŸ“ Positional encoding (í† í° ìœ„ì¹˜ ì •ë³´)\n",
        "        # ìµœëŒ€ í† í° ìˆ˜: í™˜ìë‹¹ 20ë©”ê°€íŒ¨ì¹˜ Ã— 8íŒ¨ì¹˜ = 160 LR + 20 Global + 1 CLS = 181\n",
        "        max_tokens = 200  # ì—¬ìœ ìˆê²Œ ì„¤ì •\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, max_tokens, feature_dim))\n",
        "\n",
        "        # ğŸ§  Standard Self-Attention layers (LR + Global + CLSë§Œ ì‚¬ìš©)\n",
        "        self.sa_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=feature_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=feature_dim * 4,  # FFN hidden dim\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True  # Pre-LN for better training stability\n",
        "            ) for _ in range(num_sa_layers)\n",
        "        ])\n",
        "\n",
        "        # ğŸ¯ FlexAttention components\n",
        "        self.hr_selectors = nn.ModuleList([\n",
        "            ThresholdBasedHRSelector(\n",
        "                target_selection_ratio=0.1,  # 10% ì„ íƒ\n",
        "                min_patches=1,\n",
        "                max_patches=4\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.hierarchical_attentions = nn.ModuleList([\n",
        "            HierarchicalSelfAttention(feature_dim, num_heads, dropout)\n",
        "            for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # FlexAttention layerìš© FFNê³¼ LayerNorm\n",
        "        self.fa_ffns = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(feature_dim, feature_dim * 4),\n",
        "                nn.GELU(),  # ReLUë³´ë‹¤ ë” ë¶€ë“œëŸ¬ìš´ í™œì„±í™” í•¨ìˆ˜\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(feature_dim * 4, feature_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.fa_layer_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(feature_dim) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # ğŸ¥ ìµœì¢… ë¶„ë¥˜ê¸° (í™˜ì ë ˆë²¨ ì˜ˆì¸¡)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feature_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
        "        self._initialize_weights()\n",
        "\n",
        "        print(f\"âœ… FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ë” ì•ˆì •ì ì¸ í›ˆë ¨ì„ ìœ„í•´)\"\"\"\n",
        "        # CLS token ì´ˆê¸°í™”\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "\n",
        "        # Positional encoding ì´ˆê¸°í™”\n",
        "        nn.init.trunc_normal_(self.pos_encoding, std=0.02)\n",
        "\n",
        "        # Linear layer ì´ˆê¸°í™”\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.trunc_normal_(module.weight, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def forward(self, lr_features, global_features, hr_features):\n",
        "        \"\"\"\n",
        "        FlexAttention MIL Forward Pass\n",
        "\n",
        "        Args:\n",
        "            lr_features: [batch_size, total_lr_patches, feature_dim] - ëª¨ë“  LR features\n",
        "            global_features: [batch_size, num_megapatches, feature_dim] - Global features\n",
        "            hr_features: [batch_size, total_hr_patches, feature_dim] - ëª¨ë“  HR features\n",
        "\n",
        "        Returns:\n",
        "            logits: [batch_size, num_classes] - í™˜ì ë ˆë²¨ ì˜ˆì¸¡\n",
        "            attention_maps: List[Tensor] - attention maps (ì‹œê°í™”ìš©)\n",
        "            selection_stats: Dict - HR selection í†µê³„ (ë¶„ì„ìš©)\n",
        "        \"\"\"\n",
        "        batch_size = lr_features.shape[0]\n",
        "\n",
        "        # ğŸ“Š ì…ë ¥ ë°ì´í„° í¬ê¸° í™•ì¸ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
        "        max_lr_tokens = min(lr_features.shape[1], 128)    # ìµœëŒ€ 128ê°œ LR tokens\n",
        "        max_global_tokens = min(global_features.shape[1], 16)  # ìµœëŒ€ 16ê°œ Global tokens\n",
        "        max_hr_tokens = min(hr_features.shape[1], 128)    # ìµœëŒ€ 128ê°œ HR tokens\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ í† í°ë§Œ ì‚¬ìš©\n",
        "        lr_subset = lr_features[:, :max_lr_tokens]        # [B, â‰¤128, D]\n",
        "        global_subset = global_features[:, :max_global_tokens]  # [B, â‰¤16, D]\n",
        "        hr_subset = hr_features[:, :max_hr_tokens]        # [B, â‰¤128, D] (ë‚˜ì¤‘ì— ì¼ë¶€ë§Œ ì„ íƒë¨)\n",
        "\n",
        "        # ğŸ”§ Feature dimension ì²´í¬ ë° í†µì¼ (ìˆ˜ì •ëœ ë¶€ë¶„!)\n",
        "        assert lr_subset.shape[2] == self.feature_dim, f\"LR features dim mismatch: {lr_subset.shape[2]} vs {self.feature_dim}\"\n",
        "        assert global_subset.shape[2] == self.feature_dim, f\"Global features dim mismatch: {global_subset.shape[2]} vs {self.feature_dim}\"\n",
        "        assert hr_subset.shape[2] == self.feature_dim, f\"HR features dim mismatch: {hr_subset.shape[2]} vs {self.feature_dim}\"\n",
        "\n",
        "        # ğŸ¯ Step 1: Token sequence êµ¬ì„± [LR + Global + CLS]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # [B, 1, D]\n",
        "\n",
        "        # ì´ˆê¸° hidden states: LR tokens + Global tokens + CLS token (ëª¨ë‘ ê°™ì€ ì°¨ì›!)\n",
        "        hidden_states = torch.cat([lr_subset, global_subset, cls_tokens], dim=1)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“ Positional encoding ì¶”ê°€\n",
        "        seq_len = hidden_states.shape[1]\n",
        "        if seq_len <= self.pos_encoding.shape[1]:\n",
        "            hidden_states = hidden_states + self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        attention_maps = []  # attention mapë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        selection_stats = {'total_selected': [], 'selection_ratios': []}\n",
        "\n",
        "        # ğŸ§  Step 2: Standard Self-Attention layers (Algorithm 1, lines 8-12)\n",
        "        for i in range(self.num_sa_layers):\n",
        "            hidden_states = self.sa_layers[i](hidden_states)\n",
        "\n",
        "        # ğŸ¯ Step 3: FlexAttention layers (Algorithm 1, lines 14-19)\n",
        "        for i in range(self.num_fa_layers):\n",
        "            # Step 3a: LR attention ê¸°ë°˜ HR selection\n",
        "            if i == 0:\n",
        "                # ì²« ë²ˆì§¸ layer: uniform attention (ëª¨ë“  LR í† í°ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜)\n",
        "                num_lr_tokens = lr_subset.shape[1]\n",
        "                lr_attention_map = torch.ones(batch_size, num_lr_tokens, device=lr_features.device)\n",
        "                lr_attention_map = lr_attention_map / lr_attention_map.sum(dim=1, keepdim=True)\n",
        "            else:\n",
        "                # ì´ì „ layerì˜ attention ì‚¬ìš©\n",
        "                lr_attention_map = attention_maps[-1][:, :lr_subset.shape[1]]  # LR ë¶€ë¶„ë§Œ\n",
        "\n",
        "            # HR featuresë¥¼ LRê³¼ ëŒ€ì‘ë˜ë„ë¡ í¬ê¸° ë§ì¶¤\n",
        "            hr_corresponding_size = min(hr_subset.shape[1], lr_subset.shape[1])\n",
        "            hr_for_selection = hr_subset[:, :hr_corresponding_size]\n",
        "            lr_attention_for_selection = lr_attention_map[:, :hr_corresponding_size]\n",
        "\n",
        "            # Step 3b: ì¤‘ìš”í•œ HR features ì„ íƒ (ë…¼ë¬¸ì˜ í•µì‹¬!)\n",
        "            selected_hr_features, selection_masks, thresholds = self.hr_selectors[i](\n",
        "                lr_attention_for_selection, hr_for_selection\n",
        "            )\n",
        "\n",
        "            # ì„ íƒ í†µê³„ ìˆ˜ì§‘\n",
        "            stats = self.hr_selectors[i].get_selection_statistics(selection_masks)\n",
        "            selection_stats['total_selected'].append(stats['mean_selected'])\n",
        "            selection_stats['selection_ratios'].append(stats['selection_ratio'])\n",
        "\n",
        "            # Step 3c: Hierarchical Self-Attention (Algorithm 1, line 16)\n",
        "            attended_output, new_attention_map = self.hierarchical_attentions[i](\n",
        "                hidden_states, selected_hr_features\n",
        "            )\n",
        "\n",
        "            # Step 3d: Residual connection + Layer normalization\n",
        "            hidden_states = self.fa_layer_norms[i](hidden_states + attended_output)\n",
        "\n",
        "            # Step 3e: FFN + residual connection (Algorithm 1, line 18)\n",
        "            ffn_output = self.fa_ffns[i](hidden_states)\n",
        "            hidden_states = hidden_states + ffn_output\n",
        "\n",
        "            attention_maps.append(new_attention_map)\n",
        "\n",
        "        # ğŸ¥ Step 4: í™˜ì ë ˆë²¨ ë¶„ë¥˜ (Algorithm 1, line 20)\n",
        "        cls_output = hidden_states[:, -1]  # CLS tokenì˜ ìµœì¢… representation\n",
        "        logits = self.classifier(cls_output)  # [B, num_classes]\n",
        "\n",
        "        return logits, attention_maps, selection_stats\n",
        "\n",
        "\n",
        "# ë‚˜ë¨¸ì§€ DynamicFlexAttentionDatasetì€ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "class DynamicFlexAttentionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ğŸ—‚ï¸  FlexAttentionìš© ë™ì  í™˜ì Dataset\n",
        "\n",
        "    íŠ¹ì§•:\n",
        "    - í™˜ìë³„ë¡œ ë‹¤ë¥¸ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ì²˜ë¦¬\n",
        "    - ë©”ê°€íŒ¨ì¹˜ë‹¹ 8ê°œ íŒ¨ì¹˜ë¡œ ê°ì†Œ (ì†ë„ í–¥ìƒ)\n",
        "    - ìºì‹±ìœ¼ë¡œ ë°˜ë³µ ë¡œë”© ë°©ì§€\n",
        "    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patient_data, target_type='t_label',\n",
        "                 patches_per_megapatch=8, cache_dir=None,\n",
        "                 max_megapatches=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patient_data (dict): í™˜ìë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
        "            target_type (str): ë¼ë²¨ íƒ€ì… ('t_label', 'recur_label')\n",
        "            patches_per_megapatch (int): ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ê°œìˆ˜ (8 ì¶”ì²œ)\n",
        "            cache_dir (str): ìºì‹œ ë””ë ‰í† ë¦¬ (ì²˜ë¦¬ëœ features ì €ì¥)\n",
        "            max_megapatches (int): í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜ ìˆ˜ (Noneì´ë©´ ìë™ ê²°ì •)\n",
        "        \"\"\"\n",
        "        self.patient_data = patient_data\n",
        "        self.patient_ids = list(patient_data.keys())\n",
        "        self.target_type = target_type\n",
        "        self.patches_per_megapatch = patches_per_megapatch\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        if cache_dir:\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "        # í™˜ìë³„ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„ì„ ë° ìµœì  max_megapatches ê²°ì •\n",
        "        self._analyze_megapatch_distribution()\n",
        "        if max_megapatches is None:\n",
        "            self.max_megapatches = self._determine_optimal_max_megapatches()\n",
        "        else:\n",
        "            self.max_megapatches = max_megapatches\n",
        "\n",
        "        print(f\"ğŸ“Š Dataset ì´ˆê¸°í™” ì™„ë£Œ:\")\n",
        "        print(f\"   - í™˜ì ìˆ˜: {len(self.patient_ids)}ëª…\")\n",
        "        print(f\"   - ë¼ë²¨ íƒ€ì…: {target_type}\")\n",
        "        print(f\"   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: {patches_per_megapatch}ê°œ\")\n",
        "        print(f\"   - í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜: {self.max_megapatches}ê°œ\")\n",
        "\n",
        "        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ transform\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™” (ì‚¬ì „í›ˆë ¨ ëª¨ë¸ê³¼ ë§ì¶¤)\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def _analyze_megapatch_distribution(self):\n",
        "        \"\"\"í™˜ìë³„ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬ ë¶„ì„\"\"\"\n",
        "        counts = []\n",
        "        for patient_id, info in self.patient_data.items():\n",
        "            counts.append(len(info['images']))\n",
        "\n",
        "        if counts:\n",
        "            print(f\"ğŸ“ˆ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬:\")\n",
        "            print(f\"   - í‰ê· : {np.mean(counts):.1f}ê°œ\")\n",
        "            print(f\"   - ì¤‘ê°„ê°’: {np.median(counts):.1f}ê°œ\")\n",
        "            print(f\"   - 25%/75% ì§€ì : {np.percentile(counts, 25):.1f}/{np.percentile(counts, 75):.1f}ê°œ\")\n",
        "            print(f\"   - ìµœì†Œ/ìµœëŒ€: {min(counts)}/{max(counts)}ê°œ\")\n",
        "\n",
        "        self.megapatch_counts = counts\n",
        "\n",
        "    def _determine_optimal_max_megapatches(self):\n",
        "        \"\"\"ë©”ëª¨ë¦¬ì™€ ì„±ëŠ¥ì„ ê³ ë ¤í•œ ìµœì  max_megapatches ê²°ì •\"\"\"\n",
        "        if not self.megapatch_counts:\n",
        "            return 10  # ê¸°ë³¸ê°’\n",
        "\n",
        "        # 75% percentile ì‚¬ìš© (ëŒ€ë¶€ë¶„ í™˜ìë¥¼ ì»¤ë²„í•˜ë©´ì„œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "        optimal = int(np.percentile(self.megapatch_counts, 75))\n",
        "\n",
        "        # ìµœì†Œ 5ê°œ, ìµœëŒ€ 15ê°œë¡œ ì œí•œ (ë©”ëª¨ë¦¬ ê³ ë ¤)\n",
        "        optimal = max(5, min(optimal, 15))\n",
        "\n",
        "        print(f\"ğŸ¯ ìµœì  max_megapatches ê²°ì •: {optimal}ê°œ (75th percentile ê¸°ì¤€)\")\n",
        "        return optimal\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        í™˜ì ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
        "\n",
        "        Returns:\n",
        "            dict: {\n",
        "                'patient_id': í™˜ì ID,\n",
        "                'lr_patches': [total_lr, 3, 64, 64] - LR íŒ¨ì¹˜ë“¤,\n",
        "                'global_patches': [num_megapatches, 3, 64, 64] - Global íŒ¨ì¹˜ë“¤,\n",
        "                'hr_patches': [total_hr, 3, 256, 256] - HR íŒ¨ì¹˜ë“¤,\n",
        "                'label': ë¼ë²¨,\n",
        "                'num_megapatches': ì‹¤ì œ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜\n",
        "            }\n",
        "        \"\"\"\n",
        "        patient_id = self.patient_ids[idx]\n",
        "        patient_info = self.patient_data[patient_id]\n",
        "\n",
        "        # ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°\n",
        "        label = patient_info.get(self.target_type, 0)\n",
        "        if label is None:\n",
        "            label = 0\n",
        "\n",
        "        # ì´ í™˜ìì˜ ëª¨ë“  ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        megapatch_paths = patient_info['images']\n",
        "\n",
        "        # ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ì¡°ì •\n",
        "        if len(megapatch_paths) > self.max_megapatches:\n",
        "            # ë„ˆë¬´ ë§ìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§\n",
        "            megapatch_paths = random.sample(megapatch_paths, self.max_megapatches)\n",
        "        elif len(megapatch_paths) == 0:\n",
        "            # ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # ê° streamë³„ ë°ì´í„° ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë“¤\n",
        "        all_lr_features = []\n",
        "        all_global_features = []\n",
        "        all_hr_features = []\n",
        "\n",
        "        # ê° ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬\n",
        "        processed_count = 0\n",
        "        for megapatch_path in megapatch_paths:\n",
        "            try:\n",
        "                # ìºì‹± í™•ì¸\n",
        "                if self.cache_dir:\n",
        "                    cache_key = hashlib.md5(\n",
        "                        f\"{megapatch_path}_{self.patches_per_megapatch}\".encode()\n",
        "                    ).hexdigest()\n",
        "                    cache_path = os.path.join(self.cache_dir, f\"{cache_key}.pkl\")\n",
        "\n",
        "                    if os.path.exists(cache_path):\n",
        "                        with open(cache_path, 'rb') as f:\n",
        "                            processed = pickle.load(f)\n",
        "                    else:\n",
        "                        processed = process_megapatch_complete(\n",
        "                            megapatch_path, self.patches_per_megapatch\n",
        "                        )\n",
        "                        with open(cache_path, 'wb') as f:\n",
        "                            pickle.dump(processed, f)\n",
        "                else:\n",
        "                    processed = process_megapatch_complete(\n",
        "                        megapatch_path, self.patches_per_megapatch\n",
        "                    )\n",
        "\n",
        "                # ê° streamë³„ë¡œ tensor ë³€í™˜\n",
        "                for lr_patch in processed['lr_patches']:\n",
        "                    lr_pil = Image.fromarray(lr_patch)\n",
        "                    lr_tensor = self.transform(lr_pil)\n",
        "                    all_lr_features.append(lr_tensor)\n",
        "\n",
        "                # Global token (ë©”ê°€íŒ¨ì¹˜ë‹¹ 1ê°œ)\n",
        "                global_pil = Image.fromarray(processed['global_tokens'][0])\n",
        "                global_tensor = self.transform(global_pil)\n",
        "                all_global_features.append(global_tensor)\n",
        "\n",
        "                # HR patches\n",
        "                for hr_patch in processed['hr_patches']:\n",
        "                    hr_pil = Image.fromarray(hr_patch)\n",
        "                    hr_tensor = self.transform(hr_pil)\n",
        "                    all_hr_features.append(hr_tensor)\n",
        "\n",
        "                processed_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ {megapatch_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # ì²˜ë¦¬ëœ ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°\n",
        "        if processed_count == 0:\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # Tensorë¡œ ë³€í™˜\n",
        "        lr_tensor = torch.stack(all_lr_features)      # [total_lr, 3, 64, 64]\n",
        "        global_tensor = torch.stack(all_global_features)  # [num_megapatches, 3, 64, 64]\n",
        "        hr_tensor = torch.stack(all_hr_features)      # [total_hr, 3, 256, 256]\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': lr_tensor,\n",
        "            'global_patches': global_tensor,\n",
        "            'hr_patches': hr_tensor,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': processed_count\n",
        "        }\n",
        "\n",
        "    def _create_dummy_data(self, patient_id, label):\n",
        "        \"\"\"ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ê±°ë‚˜ ì²˜ë¦¬ ì‹¤íŒ¨ì‹œ ë”ë¯¸ ë°ì´í„° ìƒì„±\"\"\"\n",
        "        dummy_lr = torch.zeros(self.patches_per_megapatch, 3, 64, 64)\n",
        "        dummy_global = torch.zeros(1, 3, 64, 64)\n",
        "        dummy_hr = torch.zeros(self.patches_per_megapatch, 3, 256, 256)\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': dummy_lr,\n",
        "            'global_patches': dummy_global,\n",
        "            'hr_patches': dummy_hr,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': 1\n",
        "        }\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 7 ì™„ë£Œ: Feature Dimension í†µì¼ëœ FlexAttention MIL ëª¨ë¸!\")\n",
        "print(\"ëª¨ë“  Feature Extractorê°€ 256 ì°¨ì›ìœ¼ë¡œ í†µì¼ë˜ì–´ í…ì„œ í¬ê¸° ì˜¤ë¥˜ê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_X-jwFDFvDf"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 8: í›ˆë ¨ í•¨ìˆ˜ (ì²´í¬í¬ì¸íŠ¸ ì™„ë²½ ì§€ì›)\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ5xkOuOFvDf",
        "outputId": "233dcc8c-d366-4c7e-ef50-bed11f8e3ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 8 ì™„ì „ ìˆ˜ì • ì™„ë£Œ: ëª¨ë“  ì˜¤ë¥˜ í•´ê²°!\n",
            "ì´ì œ extract_features_fixed í•¨ìˆ˜ì™€ í•¨ê»˜ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# ì™„ì „íˆ ìˆ˜ì •ëœ Part 8: FlexAttention í›ˆë ¨ í•¨ìˆ˜\n",
        "# ========================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "\n",
        "def train_flexattention_model_with_checkpoints(\n",
        "    patient_data,\n",
        "    target_type='t_label',\n",
        "    num_folds=5,\n",
        "    num_epochs=8,\n",
        "    batch_size=1,\n",
        "    accumulation_steps=4,\n",
        "    learning_rate=3e-4,\n",
        "    extractor_type='resnet18',\n",
        "    device=device,\n",
        "    work_dir=work_dir,\n",
        "    resume_from_checkpoint=True\n",
        "):\n",
        "    \"\"\"\n",
        "    ğŸš€ ì™„ì „íˆ ìˆ˜ì •ëœ FlexAttention MIL í›ˆë ¨ í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"ğŸš€ FlexAttention MIL í›ˆë ¨ ì‹œì‘!\")\n",
        "    print(f\"   Target: {target_type}\")\n",
        "    print(f\"   Folds: {num_folds}, Epochs: {num_epochs}\")\n",
        "    print(f\"   Batch size: {batch_size} Ã— {accumulation_steps} = {batch_size * accumulation_steps}\")\n",
        "    print(f\"   Learning rate: {learning_rate}\")\n",
        "    print(f\"   Extractor: {extractor_type}\")\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "    target_dir = os.path.join(work_dir, f\"results_{target_type}\")\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
        "    checkpoint_manager = CheckpointManager(\n",
        "        checkpoint_dir=os.path.join(target_dir, \"checkpoints\"),\n",
        "        max_keep=3\n",
        "    )\n",
        "\n",
        "    # í™˜ì ë°ì´í„° ì¤€ë¹„\n",
        "    patient_ids = list(patient_data.keys())\n",
        "    patient_labels = [patient_data[pid].get(target_type, 0) for pid in patient_ids]\n",
        "    patient_labels = [0 if label is None else label for label in patient_labels]\n",
        "\n",
        "    print(f\"\\nğŸ‘¥ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:\")\n",
        "    print(f\"   ì´ í™˜ì ìˆ˜: {len(patient_ids)}ëª…\")\n",
        "    print(f\"   ë¼ë²¨ ë¶„í¬: {dict(zip(*np.unique(patient_labels, return_counts=True)))}\")\n",
        "\n",
        "    # Stratified K-Fold ì„¤ì •\n",
        "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # ì „ì²´ ê²°ê³¼ ì €ì¥\n",
        "    all_results = {\n",
        "        'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'auc': [],\n",
        "        'fold_details': []\n",
        "    }\n",
        "\n",
        "    # ê° fold ë³„ í›ˆë ¨\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(patient_ids, patient_labels)):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"ğŸ”„ Fold {fold+1}/{num_folds} ì‹œì‘\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # ë°ì´í„° ë¶„í• \n",
        "        train_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in train_idx}\n",
        "        test_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in test_idx}\n",
        "\n",
        "        print(f\"   í›ˆë ¨ í™˜ì: {len(train_patients)}ëª…\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ í™˜ì: {len(test_patients)}ëª…\")\n",
        "\n",
        "        # Dataset ìƒì„±\n",
        "        train_dataset = DynamicFlexAttentionDataset(\n",
        "            train_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=4,  # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=6         # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "        )\n",
        "\n",
        "        test_dataset = DynamicFlexAttentionDataset(\n",
        "            test_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=4,\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=6\n",
        "        )\n",
        "\n",
        "        # DataLoader ìƒì„±\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=False,\n",
        "            drop_last=False\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            pin_memory=False,\n",
        "        )\n",
        "\n",
        "        print(f\"   í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")\n",
        "\n",
        "        # ëª¨ë¸ ì´ˆê¸°í™” (ì‘ì€ í¬ê¸°ë¡œ)\n",
        "        model = FlexAttentionPatientMIL(\n",
        "            feature_dim=128,           # 256â†’128ë¡œ ì¤„ì„\n",
        "            num_classes=2,\n",
        "            num_heads=2,               # 4â†’2ë¡œ ì¤„ì„\n",
        "            num_sa_layers=1,\n",
        "            num_fa_layers=1,\n",
        "            dropout=0.1,\n",
        "            extractor_type=extractor_type\n",
        "        )\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
        "        optimizer = AdamW(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—†ìŒ (ê°„ë‹¨í•˜ê²Œ)\n",
        "        scheduler = None\n",
        "\n",
        "        # Loss function & Scaler\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scaler = GradScaler()\n",
        "\n",
        "        print(f\"âœ… ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "\n",
        "        # í›ˆë ¨ ë£¨í”„\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nğŸ”„ Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            # í›ˆë ¨ ë‹¨ê³„\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            num_batches = 0\n",
        "\n",
        "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"í›ˆë ¨ ì§„í–‰\")):\n",
        "                try:\n",
        "                    # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™\n",
        "                    lr_patches = batch['lr_patches'].to(device)\n",
        "                    global_patches = batch['global_patches'].to(device)\n",
        "                    hr_patches = batch['hr_patches'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "\n",
        "                    with autocast():\n",
        "                        # Feature extraction (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
        "                        lr_features, global_features, hr_features = extract_features_fixed(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        # Forward pass\n",
        "                        logits, attention_maps, selection_stats = model(\n",
        "                            lr_features, global_features, hr_features\n",
        "                        )\n",
        "\n",
        "                        # Loss ê³„ì‚° (ì´ ë¶€ë¶„ì´ ë¹ ì ¸ìˆì—ˆìŒ!)\n",
        "                        loss = criterion(logits, labels) / accumulation_steps\n",
        "\n",
        "                    # Backward pass\n",
        "                    scaler.scale(loss).backward()\n",
        "\n",
        "                    # Gradient accumulation\n",
        "                    if (batch_idx + 1) % accumulation_steps == 0:\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                    total_loss += loss.item() * accumulation_steps\n",
        "                    num_batches += 1\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(f\"ğŸ’¥ OOM ë°œìƒ! ë°°ì¹˜ {batch_idx} ìŠ¤í‚µ\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        continue\n",
        "                    else:\n",
        "                        print(f\"âŒ í›ˆë ¨ ì˜¤ë¥˜: {e}\")\n",
        "                        break\n",
        "\n",
        "            avg_loss = total_loss / max(num_batches, 1)\n",
        "            print(f\"   í‰ê·  Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # ê°„ë‹¨í•œ ê²€ì¦\n",
        "            model.eval()\n",
        "            test_preds = []\n",
        "            test_labels = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in test_loader:\n",
        "                    try:\n",
        "                        lr_patches = batch['lr_patches'].to(device)\n",
        "                        global_patches = batch['global_patches'].to(device)\n",
        "                        hr_patches = batch['hr_patches'].to(device)\n",
        "                        labels = batch['label'].to(device)\n",
        "\n",
        "                        lr_features, global_features, hr_features = extract_features_fixed(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        logits, _, _ = model(lr_features, global_features, hr_features)\n",
        "                        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "                        test_preds.extend(preds.cpu().tolist())\n",
        "                        test_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"âš ï¸ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "                        continue\n",
        "\n",
        "            # ì„±ëŠ¥ ê³„ì‚°\n",
        "            if test_labels and test_preds:\n",
        "                accuracy = accuracy_score(test_labels, test_preds)\n",
        "                f1 = f1_score(test_labels, test_preds, zero_division=0)\n",
        "\n",
        "                print(f\"   ê²€ì¦ ê²°ê³¼: Acc={accuracy:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
        "                checkpoint_manager.save_checkpoint(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    scheduler=scheduler,\n",
        "                    epoch=epoch,\n",
        "                    fold=fold + 1,\n",
        "                    train_loss=avg_loss,\n",
        "                    val_metrics={'accuracy': accuracy, 'f1': f1},\n",
        "                    is_best=(f1 > checkpoint_manager.best_score)\n",
        "                )\n",
        "\n",
        "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Fold ì™„ë£Œ í›„ ê²°ê³¼ ì €ì¥\n",
        "        if test_labels and test_preds:\n",
        "            fold_accuracy = accuracy_score(test_labels, test_preds)\n",
        "            fold_f1 = f1_score(test_labels, test_preds, zero_division=0)\n",
        "\n",
        "            all_results['accuracy'].append(fold_accuracy)\n",
        "            all_results['f1'].append(fold_f1)\n",
        "\n",
        "            print(f\"âœ… Fold {fold+1} ì™„ë£Œ: Acc={fold_accuracy:.3f}, F1={fold_f1:.3f}\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # ìµœì¢… ê²°ê³¼\n",
        "    if all_results['accuracy']:\n",
        "        avg_acc = np.mean(all_results['accuracy'])\n",
        "        avg_f1 = np.mean(all_results['f1'])\n",
        "\n",
        "        print(f\"\\nğŸ‰ ìµœì¢… ê²°ê³¼ ({target_type}):\")\n",
        "        print(f\"   í‰ê·  Accuracy: {avg_acc:.3f}\")\n",
        "        print(f\"   í‰ê·  F1-Score: {avg_f1:.3f}\")\n",
        "\n",
        "        return {\n",
        "            'target_type': target_type,\n",
        "            'avg_accuracy': avg_acc,\n",
        "            'avg_f1': avg_f1,\n",
        "            'accuracy': all_results['accuracy'],\n",
        "            'f1': all_results['f1']\n",
        "        }\n",
        "    else:\n",
        "        print(f\"âŒ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 8 ì™„ì „ ìˆ˜ì • ì™„ë£Œ: ëª¨ë“  ì˜¤ë¥˜ í•´ê²°!\")\n",
        "print(\"ì´ì œ extract_features_fixed í•¨ìˆ˜ì™€ í•¨ê»˜ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRyxDkraFvDf"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 9: ì‹¤ì œ í›ˆë ¨ ì‹¤í–‰\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ì•„í™‰ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NzeF7nhFvDf",
        "outputId": "54920646-912a-4825-db9d-8495dbb9d492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ FlexAttention MIL í›ˆë ¨ ì¤€ë¹„ ì™„ë£Œ!\n",
            "================================================================================\n",
            "ğŸ’¾ ë°ì´í„°: 20ëª…ì˜ í™˜ì\n",
            "ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: cuda:0\n",
            "ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\n",
            "â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 1-2ì¼ (ìµœì í™”ëœ ì„¤ì •)\n",
            "================================================================================\n",
            "ğŸ” [í›ˆë ¨ ì‹œì‘ ì „] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "\n",
            "âš™ï¸  í›ˆë ¨ ì„¤ì •:\n",
            "   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: 8ê°œ (16â†’8, 50% ì ˆì•½)\n",
            "   - Feature dimension: 256 (384â†’256, 33% ì ˆì•½)\n",
            "   - Attention heads: 4ê°œ (6â†’4, 33% ì ˆì•½)\n",
            "   - FlexAttention layers: 1ê°œ (2â†’1, 50% ì ˆì•½)\n",
            "   - ë°°ì¹˜ í¬ê¸°: 1 (ë¬¼ë¦¬ì ) Ã— 4 (ëˆ„ì ) = 4 (íš¨ê³¼ì )\n",
            "   - Feature extractor: ResNet18 (ì•ˆì •ì„± ìš°ì„ )\n",
            "\n",
            "â“ ì„¤ì •ì´ ë§ë‹¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”!\n",
            "   T-stage ë¶„ë¥˜ì™€ ì¬ë°œ ì˜ˆì¸¡ì„ ìˆœì°¨ì ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
            "   ê° foldë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ê°€ ìë™ ì €ì¥ë©ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ“‹ í›ˆë ¨ íŒŒë¼ë¯¸í„°:\n",
            "   num_folds: 5\n",
            "   num_epochs: 8\n",
            "   batch_size: 1\n",
            "   accumulation_steps: 4\n",
            "   learning_rate: 0.0003\n",
            "   extractor_type: resnet18\n",
            "   resume_from_checkpoint: True\n",
            "\n",
            "âœ… í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: 20ëª…\n",
            "ğŸ“Š ë¼ë²¨ ë¶„í¬:\n",
            "   T-stage: {np.int64(0): np.int64(12), np.int64(1): np.int64(8)}\n",
            "   ì¬ë°œ: {np.int64(0): np.int64(7), np.int64(1): np.int64(13)}\n",
            "\n",
            "================================================================================\n",
            "Part 9 ì™„ë£Œ: í›ˆë ¨ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\n",
            "ë‹¤ìŒ ì…€ì—ì„œ ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# í›ˆë ¨ ì „ ìµœì¢… í™•ì¸ ë° ì„¤ì •\n",
        "print(\"ğŸš€ FlexAttention MIL í›ˆë ¨ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"ğŸ’¾ ë°ì´í„°: {len(patient_data) if 'patient_data' in locals() else 0}ëª…ì˜ í™˜ì\")\n",
        "print(f\"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}\")\n",
        "print(f\"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {work_dir}\")\n",
        "print(f\"â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 1-2ì¼ (ìµœì í™”ëœ ì„¤ì •)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"í›ˆë ¨ ì‹œì‘ ì „\")\n",
        "\n",
        "# í›ˆë ¨ ì„¤ì • í™•ì¸\n",
        "print(\"\\nâš™ï¸  í›ˆë ¨ ì„¤ì •:\")\n",
        "print(\"   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: 8ê°œ (16â†’8, 50% ì ˆì•½)\")\n",
        "print(\"   - Feature dimension: 256 (384â†’256, 33% ì ˆì•½)\")\n",
        "print(\"   - Attention heads: 4ê°œ (6â†’4, 33% ì ˆì•½)\")\n",
        "print(\"   - FlexAttention layers: 1ê°œ (2â†’1, 50% ì ˆì•½)\")\n",
        "print(\"   - ë°°ì¹˜ í¬ê¸°: 1 (ë¬¼ë¦¬ì ) Ã— 4 (ëˆ„ì ) = 4 (íš¨ê³¼ì )\")\n",
        "print(\"   - Feature extractor: ResNet18 (ì•ˆì •ì„± ìš°ì„ )\")\n",
        "\n",
        "# ì‚¬ìš©ì í™•ì¸\n",
        "print(f\"\\nâ“ ì„¤ì •ì´ ë§ë‹¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
        "print(f\"   T-stage ë¶„ë¥˜ì™€ ì¬ë°œ ì˜ˆì¸¡ì„ ìˆœì°¨ì ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.\")\n",
        "print(f\"   ê° foldë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ê°€ ìë™ ì €ì¥ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "# í›ˆë ¨ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "TRAINING_CONFIG = {\n",
        "    'num_folds': 5,\n",
        "    'num_epochs': 8,           # 2ì¼ ì•ˆì— ì™„ì£¼í•˜ê¸° ìœ„í•´ 12â†’10\n",
        "    'batch_size': 1,            # ë©”ëª¨ë¦¬ ì•ˆì „\n",
        "    'accumulation_steps': 4,    # íš¨ê³¼ì  ë°°ì¹˜ í¬ê¸° = 4\n",
        "    'learning_rate': 3e-4,\n",
        "    'extractor_type': 'resnet18',  # ì•ˆì •ì„± ìš°ì„ \n",
        "    'resume_from_checkpoint': True\n",
        "}\n",
        "\n",
        "print(f\"\\nğŸ“‹ í›ˆë ¨ íŒŒë¼ë¯¸í„°:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# ë°ì´í„° ì¡´ì¬ í™•ì¸\n",
        "if 'patient_data' not in locals() or not patient_data:\n",
        "    print(f\"\\nâŒ í™˜ì ë°ì´í„°ê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"   Part 5ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    print(f\"\\nâœ… í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(patient_data)}ëª…\")\n",
        "\n",
        "    # ë¼ë²¨ ë¶„í¬ ì¬í™•ì¸\n",
        "    t_labels = [info.get('t_label', 0) for info in patient_data.values()]\n",
        "    recur_labels = [info.get('recur_label', 0) for info in patient_data.values()]\n",
        "\n",
        "    print(f\"ğŸ“Š ë¼ë²¨ ë¶„í¬:\")\n",
        "    print(f\"   T-stage: {dict(zip(*np.unique(t_labels, return_counts=True)))}\")\n",
        "    print(f\"   ì¬ë°œ: {dict(zip(*np.unique(recur_labels, return_counts=True)))}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 9 ì™„ë£Œ: í›ˆë ¨ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒ ì…€ì—ì„œ ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrghSaZrFvDg"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 10: T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP44_GEvFvDg",
        "outputId": "0256667b-43b5-4428-a529-019138a4e2c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘!\n",
            "============================================================\n",
            "ğŸ“‹ T-stage ë¶„ë¥˜:\n",
            "   - í´ë˜ìŠ¤ 0: Ta, T1 (ì €ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ì—†ìŒ)\n",
            "   - í´ë˜ìŠ¤ 1: T2+ (ê³ ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ìˆìŒ)\n",
            "   - ì„ìƒì  ì¤‘ìš”ì„±: ì¹˜ë£Œ ê³„íš ë° ì˜ˆí›„ ì˜ˆì¸¡ì— í•µì‹¬\n",
            "============================================================\n",
            "ğŸ•’ í›ˆë ¨ ì‹œì‘ ì‹œê°„: 2025-05-31 14:11:12\n",
            "ğŸ” [T-stage í›ˆë ¨ ì‹œì‘] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "\n",
            "ğŸš€ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘...\n",
            "\n",
            "âŒ T-stage í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: name 'TRAINING_CONFIG' is not defined\n",
            "ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸:\n",
            "\n",
            "ğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:\n",
            "   1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: batch_sizeë¥¼ 1ë¡œ ì¤„ì´ê¸°\n",
            "   2. ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë¶€ì¡±: patches_per_megapatchë¥¼ 8â†’6ìœ¼ë¡œ ì¤„ì´ê¸°\n",
            "   3. ë°ì´í„° ë¬¸ì œ: Part 5ì—ì„œ ë°ì´í„° ë¡œë”© ë‹¤ì‹œ í™•ì¸\n",
            "   4. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: resume_from_checkpoint=True ì„¤ì •\n",
            "\n",
            "================================================================================\n",
            "Part 10 ì™„ë£Œ: T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰!\n",
            "âš ï¸  í›ˆë ¨ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ í•´ê²° ë°©ë²•ì„ ì°¸ê³ í•˜ì„¸ìš”.\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_203128\\2362231652.py\", line 28, in <module>\n",
            "    **TRAINING_CONFIG  # Part 9ì—ì„œ ì •ì˜í•œ ì„¤ì • ì‚¬ìš©\n",
            "      ^^^^^^^^^^^^^^^\n",
            "NameError: name 'TRAINING_CONFIG' is not defined\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ì—´ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - T-stage ë¶„ë¥˜ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!\n",
        "\n",
        "print(\"ğŸ¯ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘!\")\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ“‹ T-stage ë¶„ë¥˜:\")\n",
        "print(\"   - í´ë˜ìŠ¤ 0: Ta, T1 (ì €ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ì—†ìŒ)\")\n",
        "print(\"   - í´ë˜ìŠ¤ 1: T2+ (ê³ ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ìˆìŒ)\")\n",
        "print(\"   - ì„ìƒì  ì¤‘ìš”ì„±: ì¹˜ë£Œ ê³„íš ë° ì˜ˆí›„ ì˜ˆì¸¡ì— í•µì‹¬\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# í›ˆë ¨ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
        "import time\n",
        "start_time = time.time()\n",
        "start_datetime = datetime.now()\n",
        "\n",
        "print(f\"ğŸ•’ í›ˆë ¨ ì‹œì‘ ì‹œê°„: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"T-stage í›ˆë ¨ ì‹œì‘\")\n",
        "\n",
        "try:\n",
        "    # T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰\n",
        "    print(f\"\\nğŸš€ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘...\")\n",
        "\n",
        "    t_stage_results = train_flexattention_model_with_checkpoints(\n",
        "        patient_data=patient_data,\n",
        "        target_type='t_label',\n",
        "        **TRAINING_CONFIG  # Part 9ì—ì„œ ì •ì˜í•œ ì„¤ì • ì‚¬ìš©\n",
        "    )\n",
        "\n",
        "    # í›ˆë ¨ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
        "    end_time = time.time()\n",
        "    training_duration = end_time - start_time\n",
        "    hours = int(training_duration // 3600)\n",
        "    minutes = int((training_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\nğŸ‰ T-stage ë¶„ë¥˜ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "    print(f\"â±ï¸  ì†Œìš” ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„\")\n",
        "    print(f\"ğŸ“Š ìµœì¢… ì„±ëŠ¥:\")\n",
        "\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        print(f\"   í‰ê·  Accuracy: {np.mean(t_stage_results['accuracy']):.4f} Â± {np.std(t_stage_results['accuracy']):.4f}\")\n",
        "        print(f\"   í‰ê·  F1 Score: {np.mean(t_stage_results['f1']):.4f} Â± {np.std(t_stage_results['f1']):.4f}\")\n",
        "        print(f\"   í‰ê·  AUC: {np.mean(t_stage_results['auc']):.4f} Â± {np.std(t_stage_results['auc']):.4f}\")\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ fold ì°¾ê¸°\n",
        "        best_fold_idx = np.argmax(t_stage_results['f1'])\n",
        "        best_f1 = t_stage_results['f1'][best_fold_idx]\n",
        "        print(f\"   ìµœê³  ì„±ëŠ¥: Fold {best_fold_idx + 1} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    # ê²°ê³¼ ì‹œê°í™” (ê°„ë‹¨í•œ ì„±ëŠ¥ ê·¸ë˜í”„)\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            values = t_stage_results[metric]\n",
        "            plt.bar(range(1, len(values)+1), values, alpha=0.7)\n",
        "            plt.title(f'{name}')\n",
        "            plt.xlabel('Fold')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            # í‰ê· ì„  ì¶”ê°€\n",
        "            mean_val = np.mean(values)\n",
        "            plt.axhline(y=mean_val, color='red', linestyle='--', alpha=0.8)\n",
        "            plt.text(0.5, mean_val + 0.02, f'í‰ê· : {mean_val:.3f}', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # ê·¸ë˜í”„ ì €ì¥\n",
        "        plot_path = os.path.join(work_dir, \"results_t_label\", \"t_stage_performance.png\")\n",
        "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"ğŸ“ˆ ì„±ëŠ¥ ê·¸ë˜í”„ ì €ì¥: {plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    torch.cuda.empty_cache()\n",
        "    log_gpu_memory(\"T-stage í›ˆë ¨ ì™„ë£Œ\")\n",
        "\n",
        "    print(f\"\\nâœ… T-stage ë¶„ë¥˜ í›ˆë ¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {os.path.join(work_dir, 'results_t_label')}\")\n",
        "    print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸: {os.path.join(work_dir, 'results_t_label', 'checkpoints')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ T-stage í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    print(f\"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:\")\n",
        "    print(f\"   1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: batch_sizeë¥¼ 1ë¡œ ì¤„ì´ê¸°\")\n",
        "    print(f\"   2. ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë¶€ì¡±: patches_per_megapatchë¥¼ 8â†’6ìœ¼ë¡œ ì¤„ì´ê¸°\")\n",
        "    print(f\"   3. ë°ì´í„° ë¬¸ì œ: Part 5ì—ì„œ ë°ì´í„° ë¡œë”© ë‹¤ì‹œ í™•ì¸\")\n",
        "    print(f\"   4. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: resume_from_checkpoint=True ì„¤ì •\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 10 ì™„ë£Œ: T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰!\")\n",
        "if 't_stage_results' in locals():\n",
        "    print(\"âœ… í›ˆë ¨ ì„±ê³µ! ë‹¤ìŒ Partì—ì„œ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ì„ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"âš ï¸  í›ˆë ¨ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ í•´ê²° ë°©ë²•ì„ ì°¸ê³ í•˜ì„¸ìš”.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCmYihyqFvDg"
      },
      "source": [
        "# part 12 ë©”ëª¨ë¦¬ ì •ë¦¬ + ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpS00423FvDg",
        "outputId": "8c607020-f855-41b7-d50a-71fd82a1134d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ì´ˆê³ ì† í…ŒìŠ¤íŠ¸ ì„¤ì • ì¤€ë¹„!\n",
            "   ì˜ˆìƒ ì‹œê°„: 30ë¶„-1ì‹œê°„\n",
            "   2-fold Ã— 2-epoch = ì´ 4ë²ˆë§Œ í›ˆë ¨\n"
          ]
        }
      ],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# ì´ˆê³ ì† í…ŒìŠ¤íŠ¸ ì„¤ì •\n",
        "FAST_TEST_CONFIG = {\n",
        "    'num_folds': 2,              # 5â†’2 (ë¹ ë¥´ê²Œ)\n",
        "    'num_epochs': 2,             # 8â†’2 (ë¹ ë¥´ê²Œ)\n",
        "    'batch_size': 1,\n",
        "    'accumulation_steps': 2,     # 4â†’2 (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "    'learning_rate': 3e-4,\n",
        "    'extractor_type': 'resnet18',\n",
        "    'resume_from_checkpoint': False  # ì²˜ìŒë¶€í„°\n",
        "}\n",
        "\n",
        "print(\"ğŸš€ ì´ˆê³ ì† í…ŒìŠ¤íŠ¸ ì„¤ì • ì¤€ë¹„!\")\n",
        "print(f\"   ì˜ˆìƒ ì‹œê°„: 30ë¶„-1ì‹œê°„\")\n",
        "print(f\"   2-fold Ã— 2-epoch = ì´ 4ë²ˆë§Œ í›ˆë ¨\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}