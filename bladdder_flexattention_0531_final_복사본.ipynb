{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongwoonalee/jongwoonalee.github.io/blob/main/bladdder_flexattention_0531_final_%EB%B3%B5%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhoWaUeoFvDU"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 1: 라이브러리 및 기본 설정\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgxTZATiFvDX",
        "outputId": "1bfe49bf-dd17-4c92-b4f6-5a6093ab2146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 모든 라이브러리 import 완료!\n",
            "🚀 1개의 GPU 발견!\n",
            "   GPU 0: NVIDIA GeForce RTX 4060 (8.0GB)\n",
            "✅ 주 디바이스: cuda:0\n",
            "PyTorch 버전: 2.7.0+cu118\n",
            "CUDA 사용 가능: True\n",
            "✅ 모든 랜덤 시드를 42로 고정했습니다.\n",
            "🔍 [초기 상태] GPU 메모리 - 사용중: 0.00GB, 예약됨: 0.00GB, 최대사용: 0.00GB\n",
            "\n",
            "================================================================================\n",
            "Part 1 완료: 기본 설정 및 라이브러리 준비 완료!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 이 셀을 먼저 실행하세요 - 필요한 모든 라이브러리를 import 합니다\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from skimage.filters import threshold_otsu\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "print(\"✅ 모든 라이브러리 import 완료!\")\n",
        "\n",
        "# GPU 설정 및 확인 - RTX 6000 Ada x2 최적화\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"🚀 {num_gpus}개의 GPU 발견!\")\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "        print(f\"   GPU {i}: {gpu_name} ({memory_gb:.1f}GB)\")\n",
        "\n",
        "    # CUDA 최적화 설정\n",
        "    torch.backends.cudnn.benchmark = True  # 동일한 입력 크기에 대해 최적화\n",
        "    torch.cuda.empty_cache()               # GPU 메모리 정리\n",
        "\n",
        "    print(f\"✅ 주 디바이스: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"⚠️  GPU를 찾을 수 없습니다. CPU 모드로 실행됩니다.\")\n",
        "\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "\n",
        "# 재현 가능한 결과를 위한 시드 설정\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    모든 랜덤 시드를 고정하여 재현 가능한 결과를 얻습니다.\n",
        "\n",
        "    Args:\n",
        "        seed (int): 고정할 시드 값 (기본값: 42)\n",
        "    \"\"\"\n",
        "    random.seed(seed)              # Python 기본 random\n",
        "    np.random.seed(seed)           # NumPy random\n",
        "    torch.manual_seed(seed)        # PyTorch CPU random\n",
        "    torch.cuda.manual_seed(seed)   # PyTorch GPU random (현재 디바이스)\n",
        "    torch.cuda.manual_seed_all(seed)  # PyTorch 모든 GPU random\n",
        "\n",
        "    # 완전한 재현성을 위한 설정 (속도가 약간 느려질 수 있음)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # 환경 변수로도 시드 설정\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    print(f\"✅ 모든 랜덤 시드를 {seed}로 고정했습니다.\")\n",
        "\n",
        "# 시드 고정 실행\n",
        "set_seed(42)\n",
        "\n",
        "# 메모리 사용량 모니터링 함수\n",
        "def log_gpu_memory(step_name=\"\"):\n",
        "    \"\"\"\n",
        "    현재 GPU 메모리 사용량을 출력합니다.\n",
        "\n",
        "    Args:\n",
        "        step_name (str): 현재 단계 이름 (로그 구분용)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3  # GB 단위\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3    # GB 단위\n",
        "        max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
        "\n",
        "        print(f\"🔍 [{step_name}] GPU 메모리 - \"\n",
        "              f\"사용중: {allocated:.2f}GB, \"\n",
        "              f\"예약됨: {reserved:.2f}GB, \"\n",
        "              f\"최대사용: {max_allocated:.2f}GB\")\n",
        "    else:\n",
        "        print(f\"🔍 [{step_name}] CPU 모드 실행 중\")\n",
        "\n",
        "# 초기 메모리 상태 확인\n",
        "log_gpu_memory(\"초기 상태\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 1 완료: 기본 설정 및 라이브러리 준비 완료!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nGd-YVrFvDZ"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 2: 데이터 로딩 및 전처리 함수\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVFkHLUMFvDZ",
        "outputId": "82b59fac-5937-4d8c-9e80-a3425d3cc9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 2 완료: 데이터 처리 함수들 정의 완료!\n",
            "다음으로 Part 3에서 실제 데이터를 로딩합니다.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 두 번째로 실행하세요 - 데이터 처리에 필요한 모든 함수들을 정의합니다\n",
        "\n",
        "def extract_identifier(filename):\n",
        "    \"\"\"\n",
        "    파일명에서 환자 ID를 추출하는 함수\n",
        "\n",
        "    Args:\n",
        "        filename (str): 이미지 파일명 (예: \"S123-456.jpg\")\n",
        "\n",
        "    Returns:\n",
        "        str or None: 추출된 환자 ID (예: \"S123000456\")\n",
        "        str: 파일 확장자\n",
        "\n",
        "    Example:\n",
        "        extract_identifier(\"S123-456.jpg\") → (\"S123000456\", \".jpg\")\n",
        "    \"\"\"\n",
        "    # 파일명과 확장자 분리\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # 대괄호가 있으면 제거 (예: \"[comment]\" 부분)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # 패턴 1: S숫자-숫자 형태 (예: S123-456)\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)      # \"123\"\n",
        "        patch = m1.group(2)      # \"456\"\n",
        "\n",
        "        # 패치 번호를 6자리로 패딩 (앞에 0 추가)\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch    # 456 → 000456\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch     # 1456 → 001456\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch      # 12456 → 012456\n",
        "        else:\n",
        "            patch_padded = patch            # 이미 6자리면 그대로\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # 패턴 2: S숫자, 형태 (예: S123,)\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # 패턴 3: S + 6-8자리 숫자 (예: S12345678)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # 매칭되지 않으면 None 반환\n",
        "    return None, ext\n",
        "\n",
        "def convert_file_id_to_excel_format(file_id):\n",
        "    \"\"\"\n",
        "    파일 ID를 Excel에서 사용하는 형태로 변환\n",
        "\n",
        "    Args:\n",
        "        file_id (str): 파일에서 추출한 ID\n",
        "\n",
        "    Returns:\n",
        "        str or None: Excel 형태로 변환된 ID\n",
        "\n",
        "    Example:\n",
        "        convert_file_id_to_excel_format(\"S123-456\") → \"S123000456\"\n",
        "    \"\"\"\n",
        "    if file_id is None:\n",
        "        return None\n",
        "\n",
        "    file_id = str(file_id).strip()\n",
        "\n",
        "    # \"-\"가 포함된 경우 (예: S123-456)\n",
        "    if \"-\" in file_id:\n",
        "        parts = file_id.split(\"-\")\n",
        "        if len(parts) == 2 and parts[1].isdigit():\n",
        "            patch = parts[1]\n",
        "\n",
        "            # 패치 번호를 6자리로 패딩\n",
        "            if len(patch) == 3:\n",
        "                padded_number = \"000\" + patch\n",
        "            elif len(patch) == 4:\n",
        "                padded_number = \"00\" + patch\n",
        "            elif len(patch) == 5:\n",
        "                padded_number = \"0\" + patch\n",
        "            else:\n",
        "                padded_number = patch\n",
        "\n",
        "            return f\"{parts[0]}{padded_number}\"\n",
        "\n",
        "    # 이미 S로 시작하는 긴 형태면 그대로 반환\n",
        "    elif len(file_id) > 3 and file_id.startswith(\"S\"):\n",
        "        return file_id\n",
        "\n",
        "    return None\n",
        "\n",
        "# 데이터 로딩 및 매칭 함수 (여기서는 함수만 정의, 실제 로딩은 다음 셀에서)\n",
        "def load_and_match_data(zip_path, excel_path, base_dir=None):\n",
        "    \"\"\"\n",
        "    ZIP 파일과 Excel 파일을 매칭하여 환자별 데이터를 구성하는 함수\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): 이미지가 들어있는 ZIP 파일 경로\n",
        "        excel_path (str): 라벨 정보가 들어있는 Excel 파일 경로\n",
        "        base_dir (str, optional): ZIP 압축 해제할 디렉토리\n",
        "\n",
        "    Returns:\n",
        "        dict: 환자별로 구성된 데이터 딕셔너리\n",
        "        {\n",
        "            \"patient_id\": {\n",
        "                \"images\": [이미지파일경로들],\n",
        "                \"t_label\": T-stage 라벨,\n",
        "                \"recur_label\": 재발 라벨,\n",
        "                \"grade\": 등급 정보,\n",
        "                ... 기타 정보\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    print(\"🚀 데이터 로딩 및 매칭 시작...\")\n",
        "\n",
        "    # Excel 파일 읽기\n",
        "    print(\"📊 Excel 파일 읽는 중...\")\n",
        "    try:\n",
        "        df = pd.read_excel(excel_path)\n",
        "        print(f\"   ✅ Excel 파일 로드 완료: {len(df)}개 행\")\n",
        "        print(f\"   📋 컬럼들: {list(df.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Excel 파일 읽기 실패: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # T-stage와 재발 라벨 생성\n",
        "    print(\"🏷️  라벨 변환 중...\")\n",
        "\n",
        "        # T-stage 라벨: 1 → 0 (저위험), 2 → 1 (고위험)\n",
        "    second_column = df.columns[1]  # 두 번째 컬럼 (Subtype)\n",
        "    df['t_label'] = df[second_column].apply(\n",
        "        lambda x: 0 if str(x) == '1' else 1\n",
        "    )\n",
        "    t_counts = df['t_label'].value_counts()\n",
        "    print(f\"   📈 T-stage 분포: 저위험(0): {t_counts.get(0, 0)}개, 고위험(1): {t_counts.get(1, 0)}개\")\n",
        "\n",
        "    # 재발 라벨: No → 0, Yes → 1\n",
        "    #if 'Recurrence' in df.columns:\n",
        "        #df['recur_label'] = df['Recurrence'].apply(\n",
        "           # lambda x: 0 if str(x).lower() == 'no' else 1\n",
        "        #)\n",
        "       # recur_counts = df['recur_label'].value_counts()\n",
        "      #  print(f\"   🔄 재발 분포: 없음(0): {recur_counts.get(0, 0)}개, 있음(1): {recur_counts.get(1, 0)}개\")\n",
        "\n",
        "    # ZIP 파일 처리\n",
        "    if base_dir is None:\n",
        "        base_dir = zip_path.replace('.zip', '')\n",
        "\n",
        "    print(f\"📦 ZIP 파일 처리 중: {zip_path}\")\n",
        "\n",
        "    # ZIP 파일이 이미 압축 해제되어 있는지 확인\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(\"   🔄 ZIP 파일 압축 해제 중...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(os.path.dirname(base_dir))\n",
        "        print(\"   ✅ ZIP 파일 압축 해제 완료\")\n",
        "    else:\n",
        "        print(\"   ✅ 이미 압축 해제된 폴더 발견\")\n",
        "\n",
        "    # 이미지 파일들 찾기\n",
        "    print(\"🔍 이미지 파일들 탐색 중...\")\n",
        "    image_files = []\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                full_path = os.path.join(root, file)\n",
        "                image_files.append(full_path)\n",
        "\n",
        "    print(f\"   📷 총 {len(image_files)}개의 이미지 파일 발견\")\n",
        "\n",
        "    # 파일명에서 환자 ID 추출 및 매칭\n",
        "    print(\"🔗 환자 ID 매칭 중...\")\n",
        "    patient_data = {}\n",
        "    matched_count = 0\n",
        "    unmatched_files = []\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"이미지 파일 처리\"):\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        # 파일명에서 환자 ID 추출\n",
        "        file_id, _ = extract_identifier(filename)\n",
        "        if file_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excel 형태로 변환\n",
        "        excel_id = convert_file_id_to_excel_format(file_id)\n",
        "        if excel_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excel에서 해당 환자 찾기\n",
        "        patient_row = df[df.iloc[:, 0].astype(str).str.contains(excel_id, na=False)]\n",
        "\n",
        "        if len(patient_row) > 0:\n",
        "            patient_info = patient_row.iloc[0]\n",
        "            patient_id = str(patient_info.iloc[0])\n",
        "\n",
        "            # 환자 데이터 초기화 (처음 발견된 경우)\n",
        "            if patient_id not in patient_data:\n",
        "                patient_data[patient_id] = {\n",
        "                    'images': [],\n",
        "                    't_label': patient_info.get('t_label', 0),\n",
        "                    'recur_label': patient_info.get('recur_label', 0),\n",
        "                    'grade': patient_info.get('Grade', 'Unknown'),\n",
        "                    't_stage': patient_info.get('T-stage', 'Unknown'),\n",
        "                    'recurrence': patient_info.get('Recurrence', 'Unknown')\n",
        "                }\n",
        "\n",
        "            # 이미지 경로 추가\n",
        "            patient_data[patient_id]['images'].append(img_path)\n",
        "            matched_count += 1\n",
        "        else:\n",
        "            unmatched_files.append(filename)\n",
        "\n",
        "    print(f\"   ✅ 매칭 완료: {matched_count}개 파일 매칭\")\n",
        "    print(f\"   ⚠️  매칭 실패: {len(unmatched_files)}개 파일\")\n",
        "    print(f\"   👥 총 환자 수: {len(patient_data)}명\")\n",
        "\n",
        "    # 환자별 이미지 개수 통계\n",
        "    image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "    if image_counts:\n",
        "        print(f\"   📊 환자별 이미지 개수 - 평균: {np.mean(image_counts):.1f}개, \"\n",
        "              f\"최소: {min(image_counts)}개, 최대: {max(image_counts)}개\")\n",
        "\n",
        "    # 매칭되지 않은 파일 일부 출력 (디버깅용)\n",
        "    if unmatched_files:\n",
        "        print(f\"   📝 매칭 실패 파일 예시 (처음 5개):\")\n",
        "        for file in unmatched_files[:5]:\n",
        "            print(f\"      - {file}\")\n",
        "\n",
        "    print(\"✅ 데이터 로딩 및 매칭 완료!\")\n",
        "    return patient_data\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 2 완료: 데이터 처리 함수들 정의 완료!\")\n",
        "print(\"다음으로 Part 3에서 실제 데이터를 로딩합니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSJh7ioCFvDa"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 3: 메가패치 처리 핵심 함수들\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwFDkxV3FvDa",
        "outputId": "6982101e-6687-4586-a550-62916e5f6168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 3 완료: 메가패치 처리 핵심 함수들 정의 완료!\n",
            "이제 1024x1024 이미지를 16개의 3-stream 패치로 분할할 수 있습니다.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 세 번째로 실행하세요 - FlexAttention의 핵심인 메가패치 처리 함수들을 정의합니다\n",
        "\n",
        "def split_megapatch_to_patches(megapatch_path, grid_size=4):\n",
        "    \"\"\"\n",
        "    🔪 STEP 1: 1024x1024 메가패치를 4x4=16개의 256x256 패치로 분할\n",
        "\n",
        "    FlexAttention 논문의 핵심 아이디어:\n",
        "    - 큰 이미지를 작은 패치들로 나누어 처리\n",
        "    - 각 패치는 동일한 크기로 정규화\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 메가패치 이미지 경로\n",
        "        grid_size (int): 그리드 크기 (4x4 = 16개 패치, 3x3 = 9개 패치 등)\n",
        "\n",
        "    Returns:\n",
        "        list: 16개의 256x256 패치들 (numpy arrays)\n",
        "        list: 각 패치의 위치 정보 [(i, j), ...]\n",
        "\n",
        "    Example:\n",
        "        patches, positions = split_megapatch_to_patches(\"image.jpg\", 4)\n",
        "        # patches[0]: 좌상단 패치, patches[15]: 우하단 패치\n",
        "        # positions[0]: (0, 0), positions[15]: (3, 3)\n",
        "    \"\"\"\n",
        "    # 1024x1024 메가패치 읽기\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"❌ 메가패치를 읽을 수 없습니다: {megapatch_path}\")\n",
        "\n",
        "    # BGR → RGB 변환 (OpenCV는 BGR, 우리는 RGB 사용)\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "    h, w = megapatch.shape[:2]\n",
        "\n",
        "    # 각 패치 크기 계산: 1024/4 = 256\n",
        "    patch_size = h // grid_size  # 256x256\n",
        "\n",
        "    patches = []      # 분할된 패치들을 저장할 리스트\n",
        "    positions = []    # 각 패치의 위치 정보를 저장할 리스트\n",
        "\n",
        "    # 4x4 그리드로 분할 (왼쪽 위부터 오른쪽 아래로)\n",
        "    for i in range(grid_size):        # 세로 방향 (행)\n",
        "        for j in range(grid_size):    # 가로 방향 (열)\n",
        "            # 패치의 시작점과 끝점 계산\n",
        "            y_start = i * patch_size      # 세로 시작 위치\n",
        "            x_start = j * patch_size      # 가로 시작 위치\n",
        "            y_end = y_start + patch_size  # 세로 끝 위치\n",
        "            x_end = x_start + patch_size  # 가로 끝 위치\n",
        "\n",
        "            # 256x256 패치 추출\n",
        "            patch = megapatch[y_start:y_end, x_start:x_end]\n",
        "            patches.append(patch)\n",
        "            positions.append((i, j))  # (행, 열) 위치 저장\n",
        "\n",
        "    return patches, positions\n",
        "\n",
        "def create_three_streams_from_patch(patch_256, megapatch_1024):\n",
        "    \"\"\"\n",
        "    🎯 STEP 2: 각 256x256 패치로부터 3-stream 생성\n",
        "\n",
        "    FlexAttention의 3-stream 구조:\n",
        "    1. LR (Low Resolution): 빠른 처리를 위한 64x64 저해상도\n",
        "    2. HR (High Resolution): 세밀한 분석을 위한 256x256 고해상도\n",
        "    3. Global: 전체 맥락을 위한 64x64 글로벌 컨텍스트\n",
        "\n",
        "    Args:\n",
        "        patch_256 (numpy.ndarray): 256x256 패치 (numpy array)\n",
        "        megapatch_1024 (numpy.ndarray): 전체 1024x1024 메가패치 (Global 생성용)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr': 64x64 LR 패치,\n",
        "            'hr': 256x256 HR 패치 (원본),\n",
        "            'global': 64x64 Global 컨텍스트\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 1. LR 스트림: 256x256 → 64x64 다운샘플링\n",
        "    # INTER_AREA: 축소시 품질이 좋은 보간법\n",
        "    lr_patch =  patch_256.copy()  # 256x256 그대로\n",
        "\n",
        "    # 2. HR 스트림: 256x256 원본 그대로 사용\n",
        "    # 세밀한 특징을 분석하기 위해 원본 해상도 유지\n",
        "    hr_patch = patch_256.copy()\n",
        "\n",
        "    # 3. Global 스트림: 전체 1024x1024 → 64x64 (매우 작은 overview)\n",
        "    # 전체적인 구조와 맥락 정보를 제공\n",
        "    global_context = cv2.resize(megapatch_1024, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return {\n",
        "        'lr': lr_patch,         # 64x64 LR (빠른 처리용)\n",
        "        'hr': hr_patch,         # 256x256 HR (세밀한 분석용)\n",
        "        'global': global_context # 64x64 Global (맥락 정보용)\n",
        "    }\n",
        "\n",
        "def process_megapatch_complete(megapatch_path, patches_per_megapatch=16):\n",
        "    \"\"\"\n",
        "    🚀 STEP 3: 메가패치 전체 처리 파이프라인\n",
        "\n",
        "    전체 과정:\n",
        "    1024x1024 메가패치 → 16개 패치로 분할 → 각각 3-stream 생성\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 메가패치 경로\n",
        "        patches_per_megapatch (int): 메가패치당 패치 개수 (16 or 8 등)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr_patches': 16개의 64x64 LR 패치들,\n",
        "            'hr_patches': 16개의 256x256 HR 패치들,\n",
        "            'global_tokens': 16개의 64x64 Global 토큰들 (모두 동일),\n",
        "            'positions': 패치 위치 정보 [(i,j), ...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 원본 메가패치 읽기\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"❌ 메가패치를 읽을 수 없습니다: {megapatch_path}\")\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # patches_per_megapatch에 따라 grid_size 결정\n",
        "    if patches_per_megapatch == 16:\n",
        "        grid_size = 4    # 4x4 = 16\n",
        "    elif patches_per_megapatch == 9:\n",
        "        grid_size = 3    # 3x3 = 9\n",
        "    elif patches_per_megapatch == 8:\n",
        "        # 8개는 특별 처리: 4x4에서 8개만 선택\n",
        "        grid_size = 4\n",
        "        use_subset = True\n",
        "    else:\n",
        "        grid_size = int(math.sqrt(patches_per_megapatch))\n",
        "        use_subset = False\n",
        "\n",
        "    # STEP 1: 1024x1024 → 여러개 256x256 패치로 분할\n",
        "    patches_256, positions = split_megapatch_to_patches(megapatch_path, grid_size)\n",
        "\n",
        "    # 8개만 사용하는 경우: 체스판 패턴으로 선택 (균등 분포)\n",
        "    if patches_per_megapatch == 8 and len(patches_256) == 16:\n",
        "        # 체스판 패턴: (0,0), (0,2), (1,1), (1,3), (2,0), (2,2), (3,1), (3,3)\n",
        "        selected_indices = []\n",
        "        for i, (row, col) in enumerate(positions):\n",
        "            if (row + col) % 2 == 0:  # 체스판 패턴\n",
        "                selected_indices.append(i)\n",
        "\n",
        "        # 8개만 선택\n",
        "        selected_indices = selected_indices[:patches_per_megapatch]\n",
        "        patches_256 = [patches_256[i] for i in selected_indices]\n",
        "        positions = [positions[i] for i in selected_indices]\n",
        "\n",
        "    # STEP 2: 각 패치별로 3-stream 생성\n",
        "    lr_patches = []       # LR 패치들을 저장할 리스트\n",
        "    hr_patches = []       # HR 패치들을 저장할 리스트\n",
        "    global_tokens = []    # Global 토큰들을 저장할 리스트\n",
        "\n",
        "    for patch_256 in patches_256:\n",
        "        # 각 패치에 대해 3-stream 생성\n",
        "        streams = create_three_streams_from_patch(patch_256, megapatch)\n",
        "\n",
        "        lr_patches.append(streams['lr'])        # 64x64 LR\n",
        "        hr_patches.append(streams['hr'])        # 256x256 HR\n",
        "        global_tokens.append(streams['global']) # 64x64 Global\n",
        "\n",
        "        # 참고: global_tokens는 모두 동일한 전체 이미지의 축소본입니다\n",
        "\n",
        "    return {\n",
        "        'lr_patches': lr_patches,     # patches_per_megapatch개 × 64x64\n",
        "        'hr_patches': hr_patches,     # patches_per_megapatch개 × 256x256\n",
        "        'global_tokens': global_tokens, # patches_per_megapatch개 × 64x64 (모두 동일)\n",
        "        'positions': positions        # patches_per_megapatch개 위치 정보\n",
        "    }\n",
        "\n",
        "# 테스트 및 시각화 함수\n",
        "def visualize_patch_splitting(megapatch_path, save_path=None):\n",
        "    \"\"\"\n",
        "    📊 메가패치 분할 과정을 시각화하는 함수 (디버깅 및 확인용)\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 시각화할 메가패치 경로\n",
        "        save_path (str, optional): 결과 이미지 저장 경로\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 메가패치 처리\n",
        "        processed = process_megapatch_complete(megapatch_path)\n",
        "\n",
        "        # 시각화 설정\n",
        "        fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
        "        fig.suptitle(f'메가패치 분할 결과: {os.path.basename(megapatch_path)}', fontsize=16)\n",
        "\n",
        "        # 원본 메가패치 표시\n",
        "        megapatch = cv2.imread(megapatch_path)\n",
        "        megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "        axes[0, 0].imshow(megapatch)\n",
        "        axes[0, 0].set_title('원본 메가패치\\n(1024x1024)', fontsize=10)\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # 처음 5개 패치의 3-stream 표시\n",
        "        for i in range(min(5, len(processed['lr_patches']))):\n",
        "            row = i // 5 + 1\n",
        "            col_start = (i % 5) + 1\n",
        "\n",
        "            # LR 패치 (64x64)\n",
        "            axes[0, col_start].imshow(processed['lr_patches'][i])\n",
        "            axes[0, col_start].set_title(f'LR {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[0, col_start].axis('off')\n",
        "\n",
        "            # HR 패치 (256x256)\n",
        "            axes[1, col_start].imshow(processed['hr_patches'][i])\n",
        "            axes[1, col_start].set_title(f'HR {i+1}\\n(256x256)', fontsize=8)\n",
        "            axes[1, col_start].axis('off')\n",
        "\n",
        "            # Global 토큰 (64x64)\n",
        "            axes[2, col_start].imshow(processed['global_tokens'][i])\n",
        "            axes[2, col_start].set_title(f'Global {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[2, col_start].axis('off')\n",
        "\n",
        "        # 빈 subplot들 숨기기\n",
        "        for i in range(4):\n",
        "            for j in range(6):\n",
        "                if i > 2 or (i == 0 and j == 0) or (i > 0 and j == 0):\n",
        "                    continue\n",
        "                if not axes[i, j].has_data():\n",
        "                    axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"✅ 시각화 결과 저장: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # 통계 정보 출력\n",
        "        print(f\"📊 메가패치 처리 결과:\")\n",
        "        print(f\"   - LR 패치 개수: {len(processed['lr_patches'])}개 (각 64x64)\")\n",
        "        print(f\"   - HR 패치 개수: {len(processed['hr_patches'])}개 (각 256x256)\")\n",
        "        print(f\"   - Global 토큰 개수: {len(processed['global_tokens'])}개 (각 64x64)\")\n",
        "        print(f\"   - 위치 정보: {processed['positions'][:5]}... (처음 5개)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 시각화 중 오류 발생: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 3 완료: 메가패치 처리 핵심 함수들 정의 완료!\")\n",
        "print(\"이제 1024x1024 이미지를 16개의 3-stream 패치로 분할할 수 있습니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUw1pN87FvDb"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 4: Feature Extractor와 HR Selection\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M3AzkZBFvDb",
        "outputId": "3f7db9bb-4815-4bc7-ac57-dea6836e98a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 4 완료: Feature Extractor와 HR Selector 정의 완료!\n",
            "ResNet18 vs MobileNet vs EfficientNet 중 선택 가능합니다.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 네 번째로 실행하세요 - ResNet 기반 feature extractor와 논문의 threshold 방식 HR selection을 구현합니다\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    🔬 ResNet18 기반 Feature Extractor\n",
        "\n",
        "    역할:\n",
        "    - 64x64 이미지용 (LR, Global streams)\n",
        "    - 256x256 이미지용 (HR stream)\n",
        "    - 이미지를 고정 크기 feature vector로 변환\n",
        "\n",
        "    선택지:\n",
        "    - ResNet18: 안정적이고 검증된 성능 (추천)\n",
        "    - MobileNetV3: 더 빠르지만 성능 약간 낮음\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, model_type='resnet18', pretrained=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): 출력 feature 차원 (256 or 384)\n",
        "            model_type (str): 사용할 백본 모델 ('resnet18', 'mobilenet', 'efficientnet')\n",
        "            pretrained (bool): ImageNet 사전훈련 가중치 사용 여부\n",
        "        \"\"\"\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.model_type = model_type\n",
        "\n",
        "        # 백본 모델 선택 및 설정\n",
        "        if model_type == 'resnet18':\n",
        "            # ResNet18: 안정적이고 널리 사용됨 (11M parameters)\n",
        "            resnet = models.resnet18(pretrained=pretrained)\n",
        "            self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # avgpool, fc 제거\n",
        "            backbone_out_dim = 512\n",
        "\n",
        "        elif model_type == 'mobilenet':\n",
        "            # MobileNetV3-Small: 빠르고 경량 (2.5M parameters)\n",
        "            from torchvision.models import mobilenet_v3_small\n",
        "            mobilenet = mobilenet_v3_small(pretrained=pretrained)\n",
        "            self.backbone = mobilenet.features\n",
        "            backbone_out_dim = 576\n",
        "\n",
        "        elif model_type == 'efficientnet':\n",
        "            # EfficientNet-B0: 효율적이고 성능 좋음 (5.3M parameters)\n",
        "            from torchvision.models import efficientnet_b0\n",
        "            efficientnet = efficientnet_b0(pretrained=pretrained)\n",
        "            self.backbone = efficientnet.features\n",
        "            backbone_out_dim = 1280\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"지원하지 않는 모델 타입: {model_type}\")\n",
        "\n",
        "        # Global Average Pooling: spatial dimensions를 1x1로 축소\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Feature projection: backbone output → 원하는 feature dimension\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(backbone_out_dim, feature_dim),\n",
        "            nn.LayerNorm(feature_dim),  # Layer Normalization으로 안정성 향상\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1)             # 10% 드롭아웃으로 overfitting 방지\n",
        "        )\n",
        "\n",
        "        print(f\"✅ {model_type.upper()} Feature Extractor 초기화 완료\")\n",
        "        print(f\"   - 백본 출력 차원: {backbone_out_dim}\")\n",
        "        print(f\"   - 최종 feature 차원: {feature_dim}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: 이미지 배치를 feature vectors로 변환\n",
        "\n",
        "        Args:\n",
        "            x: [batch_size, 3, H, W] - RGB 이미지 배치\n",
        "               H, W는 64 (LR, Global) 또는 256 (HR)\n",
        "\n",
        "        Returns:\n",
        "            [batch_size, feature_dim] - 추출된 feature vectors\n",
        "        \"\"\"\n",
        "        # 1. 백본 네트워크를 통한 feature map 추출\n",
        "        features = self.backbone(x)      # [B, C, H', W'] - 예: [B, 512, H'/32, W'/32]\n",
        "\n",
        "        # 2. Global Average Pooling으로 spatial dimensions 축소\n",
        "        pooled = self.avgpool(features)  # [B, C, 1, 1]\n",
        "\n",
        "        # 3. Flatten: [B, C, 1, 1] → [B, C]\n",
        "        flattened = pooled.view(pooled.size(0), -1)  # [B, backbone_out_dim]\n",
        "\n",
        "        # 4. Projection을 통해 원하는 차원으로 변환\n",
        "        projected = self.projection(flattened)       # [B, feature_dim]\n",
        "\n",
        "        return projected\n",
        "\n",
        "\n",
        "class ThresholdBasedHRSelector(nn.Module):\n",
        "    \"\"\"\n",
        "    🎯 논문의 정확한 방식: Threshold 기반 HR Feature Selection\n",
        "\n",
        "    FlexAttention 논문의 핵심 아이디어:\n",
        "    - LR attention scores에서 threshold를 계산\n",
        "    - Threshold 이상인 패치들만 HR로 선택\n",
        "    - 약 10% 정도가 선택되도록 동적 조정\n",
        "    - Top-K 고정 선택이 아닌 실제 중요도 기반 선택\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target_selection_ratio=0.1, min_patches=1, max_patches=4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            target_selection_ratio (float): 목표 선택 비율 (0.1 = 약 10%)\n",
        "            min_patches (int): 최소 선택 패치 개수 (너무 적으면 강제 선택)\n",
        "            max_patches (int): 최대 선택 패치 개수 (너무 많으면 제한)\n",
        "        \"\"\"\n",
        "        super(ThresholdBasedHRSelector, self).__init__()\n",
        "        self.target_selection_ratio = target_selection_ratio\n",
        "        self.min_patches = min_patches\n",
        "        self.max_patches = max_patches\n",
        "\n",
        "        print(f\"✅ Threshold 기반 HR Selector 초기화\")\n",
        "        print(f\"   - 목표 선택 비율: {target_selection_ratio*100:.1f}%\")\n",
        "        print(f\"   - 선택 범위: {min_patches}~{max_patches}개\")\n",
        "\n",
        "    def forward(self, lr_attention_scores, hr_features):\n",
        "        \"\"\"\n",
        "        Threshold 기반으로 중요한 HR features만 선택\n",
        "\n",
        "        Args:\n",
        "            lr_attention_scores: [batch_size, 16] - LR patches의 attention scores\n",
        "            hr_features: [batch_size, 16, feature_dim] - HR patch features\n",
        "\n",
        "        Returns:\n",
        "            selected_hr_features: [batch_size, max_patches, feature_dim] - 선택된 HR features\n",
        "            selection_masks: [batch_size, 16] - binary selection mask (시각화용)\n",
        "            thresholds: [batch_size] - 사용된 threshold 값들 (분석용)\n",
        "        \"\"\"\n",
        "        batch_size, num_patches, feature_dim = hr_features.shape\n",
        "\n",
        "        selected_hr_features = []  # 선택된 HR features를 저장할 리스트\n",
        "        selection_masks = []       # 선택 마스크를 저장할 리스트\n",
        "        thresholds = []           # 사용된 threshold들을 저장할 리스트\n",
        "\n",
        "        # 배치의 각 샘플에 대해 개별 처리\n",
        "        for b in range(batch_size):\n",
        "            att_scores = lr_attention_scores[b]  # [16] - 이 샘플의 attention scores\n",
        "\n",
        "            # Step 1: Adaptive threshold 계산\n",
        "            threshold = self._compute_adaptive_threshold(att_scores)\n",
        "\n",
        "            # Step 2: Threshold 적용하여 패치 선택\n",
        "            mask = att_scores > threshold\n",
        "            selected_indices = torch.where(mask)[0]  # threshold 이상인 패치들의 인덱스\n",
        "\n",
        "            num_selected = len(selected_indices)\n",
        "\n",
        "            # Step 3: 선택된 패치 수 검증 및 조정\n",
        "            if num_selected < self.min_patches:\n",
        "                # 너무 적게 선택된 경우: 강제로 최소 개수만큼 선택\n",
        "                _, top_indices = torch.topk(att_scores, self.min_patches)\n",
        "                selected_indices = top_indices\n",
        "                threshold = att_scores[top_indices[-1]]  # 새로운 threshold\n",
        "\n",
        "            elif num_selected > self.max_patches:\n",
        "                # 너무 많이 선택된 경우: 상위 max_patches개만 선택\n",
        "                selected_scores = att_scores[selected_indices]\n",
        "                _, top_within_selected = torch.topk(selected_scores, self.max_patches)\n",
        "                selected_indices = selected_indices[top_within_selected]\n",
        "                threshold = att_scores[selected_indices[-1]]  # 새로운 threshold\n",
        "\n",
        "            # Step 4: 선택된 HR features 추출\n",
        "            selected_features = hr_features[b, selected_indices]  # [num_selected, feature_dim]\n",
        "\n",
        "            # Step 5: 고정 크기로 패딩 (배치 처리를 위해)\n",
        "            if len(selected_indices) < self.max_patches:\n",
        "                padding_size = self.max_patches - len(selected_indices)\n",
        "                padding = torch.zeros(padding_size, feature_dim, device=hr_features.device)\n",
        "                selected_features = torch.cat([selected_features, padding], dim=0)\n",
        "\n",
        "            selected_hr_features.append(selected_features)\n",
        "\n",
        "            # Step 6: Binary mask 생성 (시각화 및 분석용)\n",
        "            binary_mask = torch.zeros_like(att_scores)\n",
        "            if len(selected_indices) > 0:\n",
        "                binary_mask[selected_indices] = 1.0\n",
        "            selection_masks.append(binary_mask)\n",
        "\n",
        "            thresholds.append(threshold)\n",
        "\n",
        "        # 리스트들을 텐서로 변환\n",
        "        selected_hr_features = torch.stack(selected_hr_features)  # [B, max_patches, feature_dim]\n",
        "        selection_masks = torch.stack(selection_masks)            # [B, 16]\n",
        "        thresholds = torch.stack(thresholds)                      # [B]\n",
        "\n",
        "        return selected_hr_features, selection_masks, thresholds\n",
        "\n",
        "    def _compute_adaptive_threshold(self, attention_scores):\n",
        "        \"\"\"\n",
        "        적응적 threshold 계산 - 여러 방법 중 가장 적절한 것 선택\n",
        "\n",
        "        Args:\n",
        "            attention_scores: [16] - 하나의 샘플에 대한 attention scores\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 계산된 threshold 값\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Method 1: Otsu threshold (이진화에서 사용하는 최적 분할점)\n",
        "            # 가장 좋은 방법이지만 sklearn 필요\n",
        "            scores_np = attention_scores.detach().cpu().numpy()\n",
        "            threshold_val = threshold_otsu(scores_np)\n",
        "            return torch.tensor(threshold_val, device=attention_scores.device)\n",
        "\n",
        "        except:\n",
        "            # Method 2: Percentile-based threshold (Fallback)\n",
        "            # 상위 target_selection_ratio*2 정도가 선택되도록\n",
        "            percentile = 1.0 - (self.target_selection_ratio * 2)  # 80th percentile for 10% target\n",
        "            threshold_val = torch.quantile(attention_scores, percentile)\n",
        "            return threshold_val\n",
        "\n",
        "    def get_selection_statistics(self, selection_masks):\n",
        "        \"\"\"\n",
        "        선택 통계 정보 반환 (디버깅 및 모니터링용)\n",
        "\n",
        "        Args:\n",
        "            selection_masks: [batch_size, 16] - binary selection masks\n",
        "\n",
        "        Returns:\n",
        "            dict: 선택 통계 정보\n",
        "        \"\"\"\n",
        "        num_selected_per_sample = selection_masks.sum(dim=1)  # [batch_size]\n",
        "\n",
        "        stats = {\n",
        "            'mean_selected': num_selected_per_sample.float().mean().item(),\n",
        "            'min_selected': num_selected_per_sample.min().item(),\n",
        "            'max_selected': num_selected_per_sample.max().item(),\n",
        "            'selection_ratio': (num_selected_per_sample.float() / selection_masks.shape[1]).mean().item(),\n",
        "            'std_selected': num_selected_per_sample.float().std().item()\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "\n",
        "# Feature Extractor 성능 비교 함수\n",
        "def compare_feature_extractors():\n",
        "    \"\"\"\n",
        "    🔬 다양한 Feature Extractor들의 성능과 속도 비교\n",
        "    실제 선택에 도움을 주는 벤치마크\n",
        "    \"\"\"\n",
        "    print(\"🔬 Feature Extractor 성능 비교\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 테스트용 가상 데이터\n",
        "    dummy_lr = torch.randn(4, 3, 64, 64)    # LR 패치들\n",
        "    dummy_hr = torch.randn(4, 3, 256, 256)  # HR 패치들\n",
        "\n",
        "    extractors = {\n",
        "        'ResNet18': ResNetFeatureExtractor(feature_dim=256, model_type='resnet18'),\n",
        "        'MobileNetV3': ResNetFeatureExtractor(feature_dim=256, model_type='mobilenet'),\n",
        "        'EfficientNet-B0': ResNetFeatureExtractor(feature_dim=256, model_type='efficientnet')\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, extractor in extractors.items():\n",
        "        print(f\"\\n📊 {name} 테스트 중...\")\n",
        "\n",
        "        # 파라미터 수 계산\n",
        "        total_params = sum(p.numel() for p in extractor.parameters())\n",
        "        trainable_params = sum(p.numel() for p in extractor.parameters() if p.requires_grad)\n",
        "\n",
        "        # 속도 측정 (LR 패치)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10번 반복 측정\n",
        "                _ = extractor(dummy_lr)\n",
        "        lr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        # 속도 측정 (HR 패치)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10번 반복 측정\n",
        "                _ = extractor(dummy_hr)\n",
        "        hr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        results[name] = {\n",
        "            'total_params': total_params,\n",
        "            'trainable_params': trainable_params,\n",
        "            'lr_time_ms': lr_time * 1000,\n",
        "            'hr_time_ms': hr_time * 1000\n",
        "        }\n",
        "\n",
        "        print(f\"   파라미터 수: {total_params/1e6:.1f}M\")\n",
        "        print(f\"   LR 처리 속도: {lr_time*1000:.1f}ms\")\n",
        "        print(f\"   HR 처리 속도: {hr_time*1000:.1f}ms\")\n",
        "\n",
        "    # 추천 출력\n",
        "    print(f\"\\n🎯 추천:\")\n",
        "    print(f\"   - 안정성 우선: ResNet18 (검증된 성능)\")\n",
        "    print(f\"   - 속도 우선: MobileNetV3 (가장 빠름)\")\n",
        "    print(f\"   - 밸런스: EfficientNet-B0 (성능-속도 절충)\")\n",
        "    print(f\"   - 2일 안에 완주: ResNet18 또는 MobileNetV3\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# 사용법 예시\n",
        "def example_usage():\n",
        "    \"\"\"Feature Extractor와 HR Selector 사용 예시\"\"\"\n",
        "    print(\"💡 사용 예시:\")\n",
        "\n",
        "    # Feature Extractor 생성\n",
        "    feature_extractor = ResNetFeatureExtractor(\n",
        "        feature_dim=256,\n",
        "        model_type='resnet18',  # 'resnet18', 'mobilenet', 'efficientnet' 중 선택\n",
        "        pretrained=True\n",
        "    )\n",
        "\n",
        "    # HR Selector 생성\n",
        "    hr_selector = ThresholdBasedHRSelector(\n",
        "        target_selection_ratio=0.1,  # 10% 선택 목표\n",
        "        min_patches=1,               # 최소 1개\n",
        "        max_patches=4                # 최대 4개\n",
        "    )\n",
        "\n",
        "    print(\"✅ 모델 컴포넌트들이 준비되었습니다!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 4 완료: Feature Extractor와 HR Selector 정의 완료!\")\n",
        "print(\"ResNet18 vs MobileNet vs EfficientNet 중 선택 가능합니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqHc2tdeFvDc"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 5: 실제 데이터 로딩 (로컬 경로)\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya5dXvOiFvDc",
        "outputId": "83f30392-100e-4bac-feb1-9544f1430efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏠 로컬 환경 설정 완료!\n",
            "🔍 중첩 폴더에서 발견: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\n",
            "\n",
            "🔍 폴더 확인:\n",
            "   C_TIL: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\\C_TIL\n",
            "   P_TIL: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\\P_TIL\n",
            "   C_TIL 이미지: 4261개\n",
            "   P_TIL 이미지: 4446개\n",
            "\n",
            "📋 샘플 파일명:\n",
            "   ._S15-11819,B [d=2.01814,x=18599,y=148794,w=2067,h=2066].png → None\n",
            "   ._S15-16941 [d=2.01814,x=24799,y=169459,w=2067,h=2067].png → None\n",
            "   ._S15-16941 [d=2.01814,x=26866,y=169459,w=2066,h=2067].png → None\n",
            "\n",
            "✅ Excel 파일 로드: 100개 행\n",
            "📋 컬럼: ['Number', 'T', 'Subtype', 'Recur']\n",
            "\n",
            "📊 샘플 Excel 데이터:\n",
            "   S15000922: Subtype=sarc, T=2, Recur=1\n",
            "   S15003203: Subtype=sarc, T=1, Recur=0\n",
            "   S15003380: Subtype=0, T=2, Recur=1\n",
            "   S15004965: Subtype=0, T=1, Recur=0\n",
            "   S15007775: Subtype=0, T=1, Recur=1\n",
            "\n",
            "🏷️ 라벨 분포 확인:\n",
            "   Subtype 분포: {0: np.int64(81), 'sarc': np.int64(7), 'micropapillary': np.int64(4), 'SQ': np.int64(3), 'plasmacytoid': np.int64(2), 'sarcomatoid': np.int64(1), 'giant': np.int64(1), 'small': np.int64(1)}\n",
            "📈 수정된 T-stage 분포: 저위험(0): 100개, 고위험(1): 0개\n",
            "\n",
            "🚀 향상된 매칭 시작...\n",
            "🔍 [매칭 전] GPU 메모리 - 사용중: 0.00GB, 예약됨: 0.00GB, 최대사용: 0.00GB\n",
            "📊 Excel ID 수: 100\n",
            "📋 Excel ID 샘플: ['S17003467', 'S21008159', 'S20005232', 'S22026444', 'S18000751']\n",
            "\n",
            "📁 C_TIL: 4261개 이미지 처리\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C_TIL 매칭: 100%|██████████| 4261/4261 [00:00<00:00, 12970.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   C_TIL 매칭: 2194개\n",
            "\n",
            "📁 P_TIL: 4446개 이미지 처리\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "P_TIL 매칭: 100%|██████████| 4446/4446 [00:00<00:00, 14182.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   P_TIL 매칭: 2193개\n",
            "\n",
            "✅ 전체 매칭 결과: 8707개 이미지 중 4387개 매칭\n",
            "\n",
            "👥 환자별 데이터:\n",
            "   총 환자: 100명\n",
            "   총 이미지: 4387개\n",
            "   환자별 평균 이미지: 43.9개\n",
            "   T-stage 분포: 저위험(0)=64명, 고위험(1)=36명\n",
            "\n",
            "👤 샘플 환자 (S15011819):\n",
            "   이미지 수: 94개\n",
            "   T-stage: T2\n",
            "   재발: Yes\n",
            "\n",
            "✅ 성공! 100명의 환자 데이터 준비 완료\n",
            "🔬 테스트용으로 20명으로 제한\n",
            "💾 데이터 저장: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\\cache\\patient_data.pkl\n",
            "🔍 [매칭 후] GPU 메모리 - 사용중: 0.00GB, 예약됨: 0.00GB, 최대사용: 0.00GB\n",
            "\n",
            "================================================================================\n",
            "Part 5 완료: 향상된 데이터 로딩!\n",
            "최종 환자 수: 20명\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 5: 완전 수정된 데이터 로딩\n",
        "# ========================================================================\n",
        "\n",
        "import re\n",
        "from tqdm import tqdm  # notebook 대신 일반 tqdm 사용\n",
        "\n",
        "\n",
        "# 🏠 로컬 경로 설정\n",
        "zip_path = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710.zip\"\n",
        "excel_path = r\"C:\\Users\\ehdwk\\Downloads\\MIL_TURB_240918_Modified.xlsx\"\n",
        "base_dir = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\"\n",
        "\n",
        "# 📁 작업 디렉토리 설정\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "checkpoint_dir = os.path.join(work_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(work_dir, \"logs\")\n",
        "cache_dir = os.path.join(work_dir, \"cache\")\n",
        "result_dir = os.path.join(work_dir, \"results\")\n",
        "\n",
        "for directory in [work_dir, checkpoint_dir, log_dir, cache_dir, result_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"🏠 로컬 환경 설정 완료!\")\n",
        "\n",
        "# 🔍 실제 데이터 폴더 찾기\n",
        "def find_data_folders(base_dir):\n",
        "    \"\"\"중첩된 폴더 구조에서 실제 C_TIL, P_TIL 폴더 찾기\"\"\"\n",
        "\n",
        "    # 1차: 직접 확인\n",
        "    c_til_dir = os.path.join(base_dir, \"C_TIL\")\n",
        "    p_til_dir = os.path.join(base_dir, \"P_TIL\")\n",
        "\n",
        "    if os.path.exists(c_til_dir) and os.path.exists(p_til_dir):\n",
        "        return c_til_dir, p_til_dir\n",
        "\n",
        "    # 2차: 하위 폴더에서 찾기\n",
        "    for item in os.listdir(base_dir):\n",
        "        item_path = os.path.join(base_dir, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            nested_c_til = os.path.join(item_path, \"C_TIL\")\n",
        "            nested_p_til = os.path.join(item_path, \"P_TIL\")\n",
        "\n",
        "            if os.path.exists(nested_c_til) and os.path.exists(nested_p_til):\n",
        "                print(f\"🔍 중첩 폴더에서 발견: {item_path}\")\n",
        "                return nested_c_til, nested_p_til\n",
        "\n",
        "    return None, None\n",
        "\n",
        "# 🔧 복잡한 파일명에서 환자 ID 추출\n",
        "def extract_patient_id_advanced(filename):\n",
        "    \"\"\"\n",
        "    실제 작동했던 로직 + 숨김파일 필터\n",
        "    \"\"\"\n",
        "    # 숨김파일 제거\n",
        "    if filename.startswith('._'):\n",
        "        return None\n",
        "\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # 대괄호 앞 부분만 사용 (좌표 정보 제거)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # 패턴 1: S15-3380 형식\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)  # 예: \"15\"\n",
        "        patch = m1.group(2)  # 예: \"3380\"\n",
        "\n",
        "        # 패치 번호 길이에 따라 패딩 추가\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch\n",
        "        else:\n",
        "            patch_padded = patch\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # 패턴 2: S16022792,1A 형식\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\"\n",
        "\n",
        "    # 패턴 3: S16021286 형식 (이미 완성된 형식)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# 실제 데이터 폴더 찾기\n",
        "c_til_dir, p_til_dir = find_data_folders(base_dir)\n",
        "\n",
        "print(f\"\\n🔍 폴더 확인:\")\n",
        "print(f\"   C_TIL: {c_til_dir}\")\n",
        "print(f\"   P_TIL: {p_til_dir}\")\n",
        "\n",
        "if c_til_dir and p_til_dir:\n",
        "    c_images = [f for f in os.listdir(c_til_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    p_images = [f for f in os.listdir(p_til_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"   C_TIL 이미지: {len(c_images)}개\")\n",
        "    print(f\"   P_TIL 이미지: {len(p_images)}개\")\n",
        "\n",
        "    # 샘플 파일명 확인\n",
        "    print(f\"\\n📋 샘플 파일명:\")\n",
        "    for i, filename in enumerate(c_images[:3]):\n",
        "        extracted_id = extract_patient_id_advanced(filename)\n",
        "        print(f\"   {filename} → {extracted_id}\")\n",
        "\n",
        "# Excel 파일 로드 및 라벨 확인\n",
        "try:\n",
        "    labels_df = pd.read_excel(excel_path)\n",
        "    print(f\"\\n✅ Excel 파일 로드: {len(labels_df)}개 행\")\n",
        "    print(f\"📋 컬럼: {list(labels_df.columns)}\")\n",
        "\n",
        "    # 샘플 데이터 확인\n",
        "    print(f\"\\n📊 샘플 Excel 데이터:\")\n",
        "    for i in range(min(5, len(labels_df))):\n",
        "        row = labels_df.iloc[i]\n",
        "        print(f\"   {row['Number']}: Subtype={row.get('Subtype', 'N/A')}, T={row.get('T', 'N/A')}, Recur={row.get('Recur', 'N/A')}\")\n",
        "\n",
        "    # Subtype 분포 확인 (수정된 로직)\n",
        "    print(f\"\\n🏷️ 라벨 분포 확인:\")\n",
        "    if 'Subtype' in labels_df.columns:\n",
        "        subtype_counts = labels_df['Subtype'].value_counts()\n",
        "        print(f\"   Subtype 분포: {dict(subtype_counts)}\")\n",
        "\n",
        "        # 올바른 라벨 변환: Subtype 1→0, Subtype 2→1\n",
        "        t_labels_corrected = []\n",
        "        for _, row in labels_df.iterrows():\n",
        "            subtype = row['Subtype']\n",
        "            if subtype == 1:\n",
        "                t_label = 0  # 저위험\n",
        "            elif subtype == 2:\n",
        "                t_label = 1  # 고위험\n",
        "            else:\n",
        "                t_label = 0  # 기본값\n",
        "            t_labels_corrected.append(t_label)\n",
        "\n",
        "        print(f\"📈 수정된 T-stage 분포: 저위험(0): {t_labels_corrected.count(0)}개, 고위험(1): {t_labels_corrected.count(1)}개\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Excel 파일 로딩 실패: {e}\")\n",
        "    labels_df = None\n",
        "\n",
        "# 향상된 이미지-라벨 매칭\n",
        "def match_images_with_labels_v2(c_til_dir, p_til_dir, labels_df):\n",
        "    \"\"\"향상된 이미지-라벨 매칭\"\"\"\n",
        "\n",
        "    if not c_til_dir or not p_til_dir or labels_df is None:\n",
        "        print(\"❌ 필요한 데이터가 없습니다.\")\n",
        "        return []\n",
        "\n",
        "    # Excel ID를 문자열로 변환하여 집합 생성\n",
        "    excel_ids = set(str(id_val) for id_val in labels_df['Number'].values)\n",
        "    print(f\"📊 Excel ID 수: {len(excel_ids)}\")\n",
        "    print(f\"📋 Excel ID 샘플: {list(excel_ids)[:5]}\")\n",
        "\n",
        "    matched_samples = []\n",
        "    total_images = 0\n",
        "    matched_images = 0\n",
        "\n",
        "    # 두 폴더 모두 처리\n",
        "    for folder_name, data_dir in [(\"C_TIL\", c_til_dir), (\"P_TIL\", p_til_dir)]:\n",
        "        if not os.path.exists(data_dir):\n",
        "            continue\n",
        "\n",
        "        image_files = [f for f in os.listdir(data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        total_images += len(image_files)\n",
        "        print(f\"\\n📁 {folder_name}: {len(image_files)}개 이미지 처리\")\n",
        "\n",
        "        folder_matched = 0\n",
        "\n",
        "        for filename in tqdm(image_files, desc=f\"{folder_name} 매칭\"):\n",
        "            # 파일명에서 환자 ID 추출\n",
        "            patient_id = extract_patient_id_advanced(filename)\n",
        "\n",
        "            if patient_id and patient_id in excel_ids:\n",
        "                # Excel에서 해당 환자 정보 찾기\n",
        "                patient_row = labels_df[labels_df['Number'] == patient_id]\n",
        "\n",
        "                if not patient_row.empty:\n",
        "                    row = patient_row.iloc[0]\n",
        "\n",
        "                    # T 컬럼만 사용 (간단!)\n",
        "                    t_value = row.get('T', 1)\n",
        "                    t_label = 0 if t_value == 1 else 1  # T=1→0(저위험), T=2→1(고위험)\n",
        "\n",
        "                    # 재발 라벨\n",
        "                    recur = row.get('Recur', None)\n",
        "                    recur_label = int(recur) if pd.notna(recur) else None\n",
        "\n",
        "                    matched_samples.append({\n",
        "                        'patient_id': patient_id,\n",
        "                        'image_path': os.path.join(data_dir, filename),\n",
        "                        't_label': t_label,\n",
        "                        'recur_label': recur_label,\n",
        "                        'subtype': t_value,  # T 값 저장\n",
        "                        'folder': folder_name\n",
        "                    })\n",
        "\n",
        "                    matched_images += 1\n",
        "                    folder_matched += 1\n",
        "\n",
        "        print(f\"   {folder_name} 매칭: {folder_matched}개\")\n",
        "\n",
        "    print(f\"\\n✅ 전체 매칭 결과: {total_images}개 이미지 중 {matched_images}개 매칭\")\n",
        "    return matched_samples\n",
        "\n",
        "# 환자별 그룹화 (개선됨)\n",
        "def group_by_patient_v2(matched_samples):\n",
        "    \"\"\"환자별 데이터 그룹화 (개선된 버전)\"\"\"\n",
        "\n",
        "    patient_data = {}\n",
        "\n",
        "    for sample in matched_samples:\n",
        "        patient_id = sample['patient_id']\n",
        "\n",
        "        if patient_id not in patient_data:\n",
        "            patient_data[patient_id] = {\n",
        "                't_label': sample['t_label'],\n",
        "                'recur_label': sample['recur_label'],\n",
        "                'images': [],\n",
        "                't_stage': f\"T{sample['subtype']}\",  # T1 또는 T2\n",
        "                'recurrence': 'No' if sample['recur_label'] == 0 else 'Yes' if sample['recur_label'] == 1 else 'Unknown'\n",
        "            }\n",
        "\n",
        "        patient_data[patient_id]['images'].append(sample['image_path'])\n",
        "\n",
        "    # 통계\n",
        "    if patient_data:\n",
        "        image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "        t_distribution = [info['t_label'] for info in patient_data.values()]\n",
        "\n",
        "        print(f\"\\n👥 환자별 데이터:\")\n",
        "        print(f\"   총 환자: {len(patient_data)}명\")\n",
        "        print(f\"   총 이미지: {sum(image_counts)}개\")\n",
        "        print(f\"   환자별 평균 이미지: {np.mean(image_counts):.1f}개\")\n",
        "        print(f\"   T-stage 분포: 저위험(0)={t_distribution.count(0)}명, 고위험(1)={t_distribution.count(1)}명\")\n",
        "\n",
        "        # 샘플 환자 정보\n",
        "        sample_id = list(patient_data.keys())[0]\n",
        "        sample_info = patient_data[sample_id]\n",
        "        print(f\"\\n👤 샘플 환자 ({sample_id}):\")\n",
        "        print(f\"   이미지 수: {len(sample_info['images'])}개\")\n",
        "        print(f\"   T-stage: {sample_info['t_stage']}\")\n",
        "        print(f\"   재발: {sample_info['recurrence']}\")\n",
        "\n",
        "    return patient_data\n",
        "\n",
        "# 실행\n",
        "print(f\"\\n🚀 향상된 매칭 시작...\")\n",
        "log_gpu_memory(\"매칭 전\")\n",
        "\n",
        "try:\n",
        "    all_samples = match_images_with_labels_v2(c_til_dir, p_til_dir, labels_df)\n",
        "    patient_data = group_by_patient_v2(all_samples)\n",
        "\n",
        "    if patient_data and len(patient_data) > 0:\n",
        "        print(f\"\\n✅ 성공! {len(patient_data)}명의 환자 데이터 준비 완료\")\n",
        "\n",
        "        # 20명으로 제한 (테스트)\n",
        "        if len(patient_data) > 20:\n",
        "            limited_ids = list(patient_data.keys())[:20]\n",
        "            patient_data = {pid: patient_data[pid] for pid in limited_ids}\n",
        "            print(f\"🔬 테스트용으로 {len(patient_data)}명으로 제한\")\n",
        "\n",
        "        # 저장\n",
        "        data_save_path = os.path.join(cache_dir, \"patient_data.pkl\")\n",
        "        with open(data_save_path, 'wb') as f:\n",
        "            pickle.dump(patient_data, f)\n",
        "        print(f\"💾 데이터 저장: {data_save_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ 환자 데이터 생성 실패 - 매칭된 데이터가 없습니다\")\n",
        "        patient_data = {}\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 오류 발생: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    patient_data = {}\n",
        "\n",
        "log_gpu_memory(\"매칭 후\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 5 완료: 향상된 데이터 로딩!\")\n",
        "print(f\"최종 환자 수: {len(patient_data) if patient_data else 0}명\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozWjJnVTFvDd"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 6: 체크포인트 시스템 & Hierarchical Self-Attention\n",
        "# ========================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y3qGrfSFvDd",
        "outputId": "7bfc8244-514d-47e3-80b8-e76f4b53a9e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 체크포인트 매니저 초기화: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\\checkpoints\n",
            "✅ Flash Attention 활성화 (메모리 효율성 향상)\n",
            "✅ CUDA 메모리 할당 최적화\n",
            "✅ GPU 메모리 정리 완료\n",
            "\n",
            "================================================================================\n",
            "Part 6 완료: 체크포인트 시스템 & Hierarchical Self-Attention 준비 완료!\n",
            "이제 훈련 중단되어도 마지막 지점부터 재시작 가능합니다!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class CheckpointManager:\n",
        "    \"\"\"\n",
        "    🔄 체크포인트 관리 시스템\n",
        "\n",
        "    기능:\n",
        "    - 매 epoch마다 모델 상태 자동 저장\n",
        "    - 훈련 중단시 마지막 지점부터 재시작 가능\n",
        "    - 최고 성능 모델 별도 저장\n",
        "    - 훈련 로그 및 통계 저장\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir, max_keep=5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            checkpoint_dir (str): 체크포인트 저장 디렉토리\n",
        "            max_keep (int): 최대 보관할 체크포인트 개수 (오래된 것부터 삭제)\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.max_keep = max_keep\n",
        "        self.best_score = 0.0\n",
        "        self.training_log = []\n",
        "\n",
        "        # 디렉토리 생성\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        print(f\"📁 체크포인트 매니저 초기화: {checkpoint_dir}\")\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, fold,\n",
        "                       train_loss, val_metrics=None, is_best=False):\n",
        "        \"\"\"\n",
        "        체크포인트 저장 (매 epoch마다 호출)\n",
        "\n",
        "        Args:\n",
        "            model: 훈련 중인 모델\n",
        "            optimizer: 옵티마이저\n",
        "            scheduler: 스케줄러\n",
        "            epoch: 현재 epoch\n",
        "            fold: 현재 fold 번호\n",
        "            train_loss: 훈련 loss\n",
        "            val_metrics: 검증 메트릭들 (dict)\n",
        "            is_best: 최고 성능 모델인지 여부\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # 체크포인트 정보\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.module.state_dict() if hasattr(model, 'module') else model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp,\n",
        "            'best_score': self.best_score\n",
        "        }\n",
        "\n",
        "        # 정규 체크포인트 저장\n",
        "        checkpoint_path = os.path.join(\n",
        "            self.checkpoint_dir,\n",
        "            f\"checkpoint_fold{fold}_epoch{epoch:03d}_{timestamp}.pt\"\n",
        "        )\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "        # 최신 체크포인트로 링크 (재시작 시 사용)\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        # 최고 성능 모델 별도 저장\n",
        "        if is_best:\n",
        "            best_path = os.path.join(self.checkpoint_dir, f\"best_model_fold{fold}.pt\")\n",
        "            torch.save(checkpoint, best_path)\n",
        "            self.best_score = val_metrics.get('f1', 0.0) if val_metrics else 0.0\n",
        "            print(f\"🏆 새로운 최고 성능 모델 저장! F1: {self.best_score:.4f}\")\n",
        "\n",
        "        # 훈련 로그 업데이트\n",
        "        log_entry = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "        self.training_log.append(log_entry)\n",
        "\n",
        "        # 로그 파일 저장\n",
        "        log_path = os.path.join(self.checkpoint_dir, f\"training_log_fold{fold}.json\")\n",
        "        with open(log_path, 'w') as f:\n",
        "            json.dump(self.training_log, f, indent=2)\n",
        "\n",
        "        print(f\"💾 체크포인트 저장: Fold {fold}, Epoch {epoch}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # 오래된 체크포인트 정리\n",
        "        self._cleanup_old_checkpoints(fold)\n",
        "\n",
        "    def _cleanup_old_checkpoints(self, fold):\n",
        "        \"\"\"오래된 체크포인트 파일들 정리\"\"\"\n",
        "        import glob\n",
        "\n",
        "        # 해당 fold의 체크포인트 파일들 찾기\n",
        "        pattern = os.path.join(self.checkpoint_dir, f\"checkpoint_fold{fold}_*.pt\")\n",
        "        checkpoints = glob.glob(pattern)\n",
        "\n",
        "        # 생성 시간 순으로 정렬\n",
        "        checkpoints.sort(key=os.path.getctime)\n",
        "\n",
        "        # max_keep 개수를 초과하면 오래된 것부터 삭제\n",
        "        while len(checkpoints) > self.max_keep:\n",
        "            old_checkpoint = checkpoints.pop(0)\n",
        "            try:\n",
        "                os.remove(old_checkpoint)\n",
        "                print(f\"🗑️  오래된 체크포인트 삭제: {os.path.basename(old_checkpoint)}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    def load_latest_checkpoint(self, fold):\n",
        "        \"\"\"\n",
        "        최신 체크포인트 로딩 (재시작 시 사용)\n",
        "\n",
        "        Args:\n",
        "            fold: 로딩할 fold 번호\n",
        "\n",
        "        Returns:\n",
        "            dict or None: 체크포인트 데이터, 없으면 None\n",
        "        \"\"\"\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "\n",
        "        if os.path.exists(latest_path):\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            print(f\"📂 체크포인트 로딩: Fold {fold}, Epoch {checkpoint['epoch']}\")\n",
        "            return checkpoint\n",
        "        else:\n",
        "            print(f\"📂 체크포인트 없음: Fold {fold} (처음부터 시작)\")\n",
        "            return None\n",
        "\n",
        "\n",
        "class HierarchicalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    🎯 FlexAttention 논문의 핵심: Hierarchical Self-Attention\n",
        "\n",
        "    핵심 아이디어:\n",
        "    - 일반 Self-Attention: O(n²) - 모든 토큰이 모든 토큰과 상호작용\n",
        "    - Hierarchical: O(n×M) - 선택된 HR 토큰만 상호작용 (M << n)\n",
        "    - 계산량 대폭 감소하면서 성능 유지!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_heads=4, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): feature 차원 (256 추천, 384는 메모리 많이 사용)\n",
        "            num_heads (int): attention head 개수 (4 추천, 6은 메모리 많이 사용)\n",
        "            dropout (float): 드롭아웃 비율\n",
        "        \"\"\"\n",
        "        super(HierarchicalSelfAttention, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = feature_dim // num_heads\n",
        "\n",
        "        # feature_dim이 num_heads로 나누어떨어지는지 확인\n",
        "        assert feature_dim % num_heads == 0, f\"feature_dim({feature_dim})이 num_heads({num_heads})로 나누어떨어지지 않습니다!\"\n",
        "\n",
        "        # 🔵 일반 hidden states용 projections (LR + Global + CLS tokens)\n",
        "        self.q_proj = nn.Linear(feature_dim, feature_dim)  # Query projection\n",
        "        self.k_proj = nn.Linear(feature_dim, feature_dim)  # Key projection\n",
        "        self.v_proj = nn.Linear(feature_dim, feature_dim)  # Value projection\n",
        "\n",
        "        # 🔴 HR features 전용 projections (논문의 W'_K, W'_V)\n",
        "        # 중요: HR features는 별도의 projection을 사용!\n",
        "        self.k_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_K for HR\n",
        "        self.v_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_V for HR\n",
        "\n",
        "        # 출력 projection\n",
        "        self.out_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = math.sqrt(self.head_dim)  # attention scaling factor\n",
        "\n",
        "        print(f\"✅ Hierarchical Self-Attention 초기화\")\n",
        "        print(f\"   - Feature dim: {feature_dim}, Heads: {num_heads}, Head dim: {self.head_dim}\")\n",
        "\n",
        "    def forward(self, hidden_states, selected_hr_features):\n",
        "        \"\"\"\n",
        "        Hierarchical Self-Attention 계산 (논문의 핵심 알고리즘)\n",
        "\n",
        "        Args:\n",
        "            hidden_states: [batch_size, N, feature_dim]\n",
        "                          N = LR tokens + Global tokens + CLS token\n",
        "            selected_hr_features: [batch_size, M, feature_dim]\n",
        "                                M = 선택된 HR tokens (보통 1~4개)\n",
        "\n",
        "        Returns:\n",
        "            output: [batch_size, N, feature_dim] - 업데이트된 hidden states\n",
        "            attention_map: [batch_size, N-1] - CLS token의 attention (다음 layer용)\n",
        "        \"\"\"\n",
        "        batch_size, N, _ = hidden_states.shape          # N: LR + Global + CLS 개수\n",
        "        _, M, _ = selected_hr_features.shape            # M: 선택된 HR 개수\n",
        "\n",
        "        # 🔵 Step 1: 일반 hidden states에 대한 Q, K, V 계산\n",
        "        Q = self.q_proj(hidden_states)      # [B, N, D] - Query (어디에 집중할지?)\n",
        "        K_h = self.k_proj(hidden_states)    # [B, N, D] - Key (나는 이런 정보야)\n",
        "        V_h = self.v_proj(hidden_states)    # [B, N, D] - Value (실제 전달할 정보)\n",
        "\n",
        "        # 🔴 Step 2: HR features에 대한 별도 K, V 계산 (논문의 핵심!)\n",
        "        K_hr = self.k_proj_hr(selected_hr_features)  # [B, M, D] - HR용 Key\n",
        "        V_hr = self.v_proj_hr(selected_hr_features)  # [B, M, D] - HR용 Value\n",
        "\n",
        "        # 🔗 Step 3: Key와 Value를 연결 [일반 tokens + HR tokens]\n",
        "        K_all = torch.cat([K_h, K_hr], dim=1)  # [B, N+M, D] - 모든 Keys\n",
        "        V_all = torch.cat([V_h, V_hr], dim=1)  # [B, N+M, D] - 모든 Values\n",
        "\n",
        "        # 🧠 Step 4: Multi-head attention을 위한 reshape\n",
        "        # [B, seq_len, D] → [B, num_heads, seq_len, head_dim]\n",
        "        Q = Q.view(batch_size, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K_all = K_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V_all = V_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # ⚡ Step 5: Attention 계산 - 여기서 계산량 O(N×(N+M))\n",
        "        # 일반 Self-Attention이라면 O((N+M)²)이지만,\n",
        "        # Query는 N개뿐이므로 O(N×(N+M)) = O(N²+NM)\n",
        "        scores = torch.matmul(Q, K_all.transpose(-2, -1)) / self.scale  # [B, H, N, N+M]\n",
        "        attention_weights = F.softmax(scores, dim=-1)                   # attention 확률\n",
        "        attention_weights = self.dropout(attention_weights)             # 드롭아웃 적용\n",
        "\n",
        "        # 🎯 Step 6: Attention 적용하여 정보 집약\n",
        "        attended = torch.matmul(attention_weights, V_all)  # [B, H, N, head_dim]\n",
        "\n",
        "        # 🔄 Step 7: Multi-head 결과 합치기\n",
        "        attended = attended.transpose(1, 2).contiguous()  # [B, N, H, head_dim]\n",
        "        attended = attended.view(batch_size, N, self.feature_dim)  # [B, N, D]\n",
        "\n",
        "        # 📤 Step 8: 최종 출력 projection\n",
        "        output = self.out_proj(attended)  # [B, N, D]\n",
        "\n",
        "        # 📊 Step 9: 다음 layer용 attention map 추출\n",
        "        # CLS token (마지막 토큰)이 LR tokens에 주는 attention\n",
        "        cls_attention = attention_weights[:, :, -1, :N-1]  # [B, H, N-1] - CLS → LR\n",
        "        attention_map = cls_attention.mean(dim=1)          # [B, N-1] - head 평균\n",
        "\n",
        "        return output, attention_map\n",
        "\n",
        "\n",
        "# 메모리 사용량 최적화 함수들\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"메모리 사용량 최적화 설정\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # 메모리 효율적인 attention 사용 (PyTorch 2.0+)\n",
        "        try:\n",
        "            torch.backends.cuda.enable_flash_sdp(True)\n",
        "            print(\"✅ Flash Attention 활성화 (메모리 효율성 향상)\")\n",
        "        except:\n",
        "            print(\"⚠️  Flash Attention 미지원 (PyTorch 버전 확인)\")\n",
        "\n",
        "        # CUDA 메모리 할당 최적화\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "        print(\"✅ CUDA 메모리 할당 최적화\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"✅ GPU 메모리 정리 완료\")\n",
        "\n",
        "def log_model_info(model):\n",
        "    \"\"\"모델 정보 로깅\"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"🔍 모델 정보:\")\n",
        "    print(f\"   - 총 파라미터: {total_params:,}개 ({total_params/1e6:.1f}M)\")\n",
        "    print(f\"   - 훈련 가능: {trainable_params:,}개 ({trainable_params/1e6:.1f}M)\")\n",
        "    print(f\"   - 모델 크기: {total_params * 4 / 1024**2:.1f}MB (float32 기준)\")\n",
        "\n",
        "# 체크포인트 매니저 초기화\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    max_keep=3  # 최대 3개 체크포인트 보관 (디스크 공간 절약)\n",
        ")\n",
        "\n",
        "# 메모리 최적화 실행\n",
        "optimize_memory_usage()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 6 완료: 체크포인트 시스템 & Hierarchical Self-Attention 준비 완료!\")\n",
        "print(\"이제 훈련 중단되어도 마지막 지점부터 재시작 가능합니다!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1p4fmUNFvDe"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 7: 완전한 MIL 모델과 Dataset\n",
        "# ========================================================================\n",
        "\n",
        "# 이 셀을 일곱 번째로 실행하세요 - 완전한 FlexAttention MIL 모델과 Dataset을 구현합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKnx_vVnFvDe",
        "outputId": "969e7632-01ad-45ae-9698-5fac53430370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 7 완료: Feature Dimension 통일된 FlexAttention MIL 모델!\n",
            "모든 Feature Extractor가 256 차원으로 통일되어 텐서 크기 오류가 해결되었습니다!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class FlexAttentionPatientMIL(nn.Module):\n",
        "    \"\"\"\n",
        "    🎯 완전한 FlexAttention Multiple Instance Learning 모델\n",
        "\n",
        "    전체 구조:\n",
        "    1. 환자별 여러 메가패치 → 각각 8개 패치 → 3-stream features\n",
        "    2. LR + Global tokens → Standard Self-Attention layers\n",
        "    3. LR attention → HR selection → FlexAttention layers\n",
        "    4. CLS token → Patient-level classification (암 단계/재발 예측)\n",
        "\n",
        "    계산량 최적화:\n",
        "    - 메가패치당 16개 → 8개 패치로 감소 (50% 절약)\n",
        "    - Feature dim 384 → 256로 감소 (33% 절약)\n",
        "    - FA layers 2개 → 1개로 감소 (50% 절약)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_classes=2, num_heads=4,\n",
        "                 num_sa_layers=1, num_fa_layers=1, dropout=0.1,\n",
        "                 extractor_type='resnet18'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): Feature 차원 (256 추천, 메모리 효율적)\n",
        "            num_classes (int): 분류 클래스 수 (2: binary classification)\n",
        "            num_heads (int): Attention head 수 (4 추천, 메모리 효율적)\n",
        "            num_sa_layers (int): Standard Self-Attention layer 수\n",
        "            num_fa_layers (int): FlexAttention layer 수\n",
        "            dropout (float): 드롭아웃 비율\n",
        "            extractor_type (str): Feature extractor 타입 ('resnet18', 'mobilenet')\n",
        "        \"\"\"\n",
        "        super(FlexAttentionPatientMIL, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_sa_layers = num_sa_layers\n",
        "        self.num_fa_layers = num_fa_layers\n",
        "\n",
        "        print(f\"🏗️  FlexAttention MIL 모델 초기화 중...\")\n",
        "        print(f\"   - Feature dim: {feature_dim}\")\n",
        "        print(f\"   - Attention heads: {num_heads}\")\n",
        "        print(f\"   - SA layers: {num_sa_layers}, FA layers: {num_fa_layers}\")\n",
        "        print(f\"   - Extractor: {extractor_type}\")\n",
        "\n",
        "        # 🔬 Feature extractors (3개의 서로 다른 해상도용) - 모두 256 차원으로 통일!\n",
        "        if extractor_type == 'resnet18':\n",
        "            self.lr_extractor = ResNetFeatureExtractor(feature_dim=feature_dim)    # 256으로 통일\n",
        "            self.global_extractor = ResNetFeatureExtractor(feature_dim=feature_dim) # 256으로 통일\n",
        "            self.hr_extractor = ResNetFeatureExtractor(feature_dim=feature_dim)    # 256으로 통일\n",
        "        elif extractor_type == 'mobilenet':\n",
        "            self.lr_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "            self.global_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "            self.hr_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "        else:\n",
        "            raise ValueError(f\"지원하지 않는 extractor_type: {extractor_type}\")\n",
        "\n",
        "        # 🎯 CLS token (환자 레벨 분류를 위한 특별한 토큰)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, feature_dim))\n",
        "\n",
        "        # 📍 Positional encoding (토큰 위치 정보)\n",
        "        # 최대 토큰 수: 환자당 20메가패치 × 8패치 = 160 LR + 20 Global + 1 CLS = 181\n",
        "        max_tokens = 200  # 여유있게 설정\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, max_tokens, feature_dim))\n",
        "\n",
        "        # 🧠 Standard Self-Attention layers (LR + Global + CLS만 사용)\n",
        "        self.sa_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=feature_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=feature_dim * 4,  # FFN hidden dim\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True  # Pre-LN for better training stability\n",
        "            ) for _ in range(num_sa_layers)\n",
        "        ])\n",
        "\n",
        "        # 🎯 FlexAttention components\n",
        "        self.hr_selectors = nn.ModuleList([\n",
        "            ThresholdBasedHRSelector(\n",
        "                target_selection_ratio=0.1,  # 10% 선택\n",
        "                min_patches=1,\n",
        "                max_patches=4\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.hierarchical_attentions = nn.ModuleList([\n",
        "            HierarchicalSelfAttention(feature_dim, num_heads, dropout)\n",
        "            for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # FlexAttention layer용 FFN과 LayerNorm\n",
        "        self.fa_ffns = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(feature_dim, feature_dim * 4),\n",
        "                nn.GELU(),  # ReLU보다 더 부드러운 활성화 함수\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(feature_dim * 4, feature_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.fa_layer_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(feature_dim) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # 🏥 최종 분류기 (환자 레벨 예측)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feature_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # 가중치 초기화\n",
        "        self._initialize_weights()\n",
        "\n",
        "        print(f\"✅ FlexAttention MIL 모델 초기화 완료!\")\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"가중치 초기화 (더 안정적인 훈련을 위해)\"\"\"\n",
        "        # CLS token 초기화\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "\n",
        "        # Positional encoding 초기화\n",
        "        nn.init.trunc_normal_(self.pos_encoding, std=0.02)\n",
        "\n",
        "        # Linear layer 초기화\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.trunc_normal_(module.weight, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def forward(self, lr_features, global_features, hr_features):\n",
        "        \"\"\"\n",
        "        FlexAttention MIL Forward Pass\n",
        "\n",
        "        Args:\n",
        "            lr_features: [batch_size, total_lr_patches, feature_dim] - 모든 LR features\n",
        "            global_features: [batch_size, num_megapatches, feature_dim] - Global features\n",
        "            hr_features: [batch_size, total_hr_patches, feature_dim] - 모든 HR features\n",
        "\n",
        "        Returns:\n",
        "            logits: [batch_size, num_classes] - 환자 레벨 예측\n",
        "            attention_maps: List[Tensor] - attention maps (시각화용)\n",
        "            selection_stats: Dict - HR selection 통계 (분석용)\n",
        "        \"\"\"\n",
        "        batch_size = lr_features.shape[0]\n",
        "\n",
        "        # 📊 입력 데이터 크기 확인 및 메모리 효율적 처리\n",
        "        max_lr_tokens = min(lr_features.shape[1], 128)    # 최대 128개 LR tokens\n",
        "        max_global_tokens = min(global_features.shape[1], 16)  # 최대 16개 Global tokens\n",
        "        max_hr_tokens = min(hr_features.shape[1], 128)    # 최대 128개 HR tokens\n",
        "\n",
        "        # 메모리 절약을 위해 일부 토큰만 사용\n",
        "        lr_subset = lr_features[:, :max_lr_tokens]        # [B, ≤128, D]\n",
        "        global_subset = global_features[:, :max_global_tokens]  # [B, ≤16, D]\n",
        "        hr_subset = hr_features[:, :max_hr_tokens]        # [B, ≤128, D] (나중에 일부만 선택됨)\n",
        "\n",
        "        # 🔧 Feature dimension 체크 및 통일 (수정된 부분!)\n",
        "        assert lr_subset.shape[2] == self.feature_dim, f\"LR features dim mismatch: {lr_subset.shape[2]} vs {self.feature_dim}\"\n",
        "        assert global_subset.shape[2] == self.feature_dim, f\"Global features dim mismatch: {global_subset.shape[2]} vs {self.feature_dim}\"\n",
        "        assert hr_subset.shape[2] == self.feature_dim, f\"HR features dim mismatch: {hr_subset.shape[2]} vs {self.feature_dim}\"\n",
        "\n",
        "        # 🎯 Step 1: Token sequence 구성 [LR + Global + CLS]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # [B, 1, D]\n",
        "\n",
        "        # 초기 hidden states: LR tokens + Global tokens + CLS token (모두 같은 차원!)\n",
        "        hidden_states = torch.cat([lr_subset, global_subset, cls_tokens], dim=1)  # [B, N, D]\n",
        "\n",
        "        # 📍 Positional encoding 추가\n",
        "        seq_len = hidden_states.shape[1]\n",
        "        if seq_len <= self.pos_encoding.shape[1]:\n",
        "            hidden_states = hidden_states + self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        attention_maps = []  # attention map들을 저장할 리스트\n",
        "        selection_stats = {'total_selected': [], 'selection_ratios': []}\n",
        "\n",
        "        # 🧠 Step 2: Standard Self-Attention layers (Algorithm 1, lines 8-12)\n",
        "        for i in range(self.num_sa_layers):\n",
        "            hidden_states = self.sa_layers[i](hidden_states)\n",
        "\n",
        "        # 🎯 Step 3: FlexAttention layers (Algorithm 1, lines 14-19)\n",
        "        for i in range(self.num_fa_layers):\n",
        "            # Step 3a: LR attention 기반 HR selection\n",
        "            if i == 0:\n",
        "                # 첫 번째 layer: uniform attention (모든 LR 토큰에 동일한 가중치)\n",
        "                num_lr_tokens = lr_subset.shape[1]\n",
        "                lr_attention_map = torch.ones(batch_size, num_lr_tokens, device=lr_features.device)\n",
        "                lr_attention_map = lr_attention_map / lr_attention_map.sum(dim=1, keepdim=True)\n",
        "            else:\n",
        "                # 이전 layer의 attention 사용\n",
        "                lr_attention_map = attention_maps[-1][:, :lr_subset.shape[1]]  # LR 부분만\n",
        "\n",
        "            # HR features를 LR과 대응되도록 크기 맞춤\n",
        "            hr_corresponding_size = min(hr_subset.shape[1], lr_subset.shape[1])\n",
        "            hr_for_selection = hr_subset[:, :hr_corresponding_size]\n",
        "            lr_attention_for_selection = lr_attention_map[:, :hr_corresponding_size]\n",
        "\n",
        "            # Step 3b: 중요한 HR features 선택 (논문의 핵심!)\n",
        "            selected_hr_features, selection_masks, thresholds = self.hr_selectors[i](\n",
        "                lr_attention_for_selection, hr_for_selection\n",
        "            )\n",
        "\n",
        "            # 선택 통계 수집\n",
        "            stats = self.hr_selectors[i].get_selection_statistics(selection_masks)\n",
        "            selection_stats['total_selected'].append(stats['mean_selected'])\n",
        "            selection_stats['selection_ratios'].append(stats['selection_ratio'])\n",
        "\n",
        "            # Step 3c: Hierarchical Self-Attention (Algorithm 1, line 16)\n",
        "            attended_output, new_attention_map = self.hierarchical_attentions[i](\n",
        "                hidden_states, selected_hr_features\n",
        "            )\n",
        "\n",
        "            # Step 3d: Residual connection + Layer normalization\n",
        "            hidden_states = self.fa_layer_norms[i](hidden_states + attended_output)\n",
        "\n",
        "            # Step 3e: FFN + residual connection (Algorithm 1, line 18)\n",
        "            ffn_output = self.fa_ffns[i](hidden_states)\n",
        "            hidden_states = hidden_states + ffn_output\n",
        "\n",
        "            attention_maps.append(new_attention_map)\n",
        "\n",
        "        # 🏥 Step 4: 환자 레벨 분류 (Algorithm 1, line 20)\n",
        "        cls_output = hidden_states[:, -1]  # CLS token의 최종 representation\n",
        "        logits = self.classifier(cls_output)  # [B, num_classes]\n",
        "\n",
        "        return logits, attention_maps, selection_stats\n",
        "\n",
        "\n",
        "# 나머지 DynamicFlexAttentionDataset은 그대로 유지\n",
        "class DynamicFlexAttentionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    🗂️  FlexAttention용 동적 환자 Dataset\n",
        "\n",
        "    특징:\n",
        "    - 환자별로 다른 메가패치 개수 처리\n",
        "    - 메가패치당 8개 패치로 감소 (속도 향상)\n",
        "    - 캐싱으로 반복 로딩 방지\n",
        "    - 메모리 효율적 처리\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patient_data, target_type='t_label',\n",
        "                 patches_per_megapatch=8, cache_dir=None,\n",
        "                 max_megapatches=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patient_data (dict): 환자별 데이터 딕셔너리\n",
        "            target_type (str): 라벨 타입 ('t_label', 'recur_label')\n",
        "            patches_per_megapatch (int): 메가패치당 패치 개수 (8 추천)\n",
        "            cache_dir (str): 캐시 디렉토리 (처리된 features 저장)\n",
        "            max_megapatches (int): 환자당 최대 메가패치 수 (None이면 자동 결정)\n",
        "        \"\"\"\n",
        "        self.patient_data = patient_data\n",
        "        self.patient_ids = list(patient_data.keys())\n",
        "        self.target_type = target_type\n",
        "        self.patches_per_megapatch = patches_per_megapatch\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        if cache_dir:\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "        # 환자별 메가패치 개수 분석 및 최적 max_megapatches 결정\n",
        "        self._analyze_megapatch_distribution()\n",
        "        if max_megapatches is None:\n",
        "            self.max_megapatches = self._determine_optimal_max_megapatches()\n",
        "        else:\n",
        "            self.max_megapatches = max_megapatches\n",
        "\n",
        "        print(f\"📊 Dataset 초기화 완료:\")\n",
        "        print(f\"   - 환자 수: {len(self.patient_ids)}명\")\n",
        "        print(f\"   - 라벨 타입: {target_type}\")\n",
        "        print(f\"   - 메가패치당 패치 수: {patches_per_megapatch}개\")\n",
        "        print(f\"   - 환자당 최대 메가패치: {self.max_megapatches}개\")\n",
        "\n",
        "        # 이미지 전처리 transform\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # ImageNet 평균/표준편차로 정규화 (사전훈련 모델과 맞춤)\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def _analyze_megapatch_distribution(self):\n",
        "        \"\"\"환자별 메가패치 개수 분포 분석\"\"\"\n",
        "        counts = []\n",
        "        for patient_id, info in self.patient_data.items():\n",
        "            counts.append(len(info['images']))\n",
        "\n",
        "        if counts:\n",
        "            print(f\"📈 메가패치 개수 분포:\")\n",
        "            print(f\"   - 평균: {np.mean(counts):.1f}개\")\n",
        "            print(f\"   - 중간값: {np.median(counts):.1f}개\")\n",
        "            print(f\"   - 25%/75% 지점: {np.percentile(counts, 25):.1f}/{np.percentile(counts, 75):.1f}개\")\n",
        "            print(f\"   - 최소/최대: {min(counts)}/{max(counts)}개\")\n",
        "\n",
        "        self.megapatch_counts = counts\n",
        "\n",
        "    def _determine_optimal_max_megapatches(self):\n",
        "        \"\"\"메모리와 성능을 고려한 최적 max_megapatches 결정\"\"\"\n",
        "        if not self.megapatch_counts:\n",
        "            return 10  # 기본값\n",
        "\n",
        "        # 75% percentile 사용 (대부분 환자를 커버하면서 메모리 효율적)\n",
        "        optimal = int(np.percentile(self.megapatch_counts, 75))\n",
        "\n",
        "        # 최소 5개, 최대 15개로 제한 (메모리 고려)\n",
        "        optimal = max(5, min(optimal, 15))\n",
        "\n",
        "        print(f\"🎯 최적 max_megapatches 결정: {optimal}개 (75th percentile 기준)\")\n",
        "        return optimal\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        환자 데이터 로딩 및 전처리\n",
        "\n",
        "        Returns:\n",
        "            dict: {\n",
        "                'patient_id': 환자 ID,\n",
        "                'lr_patches': [total_lr, 3, 64, 64] - LR 패치들,\n",
        "                'global_patches': [num_megapatches, 3, 64, 64] - Global 패치들,\n",
        "                'hr_patches': [total_hr, 3, 256, 256] - HR 패치들,\n",
        "                'label': 라벨,\n",
        "                'num_megapatches': 실제 메가패치 개수\n",
        "            }\n",
        "        \"\"\"\n",
        "        patient_id = self.patient_ids[idx]\n",
        "        patient_info = self.patient_data[patient_id]\n",
        "\n",
        "        # 라벨 가져오기\n",
        "        label = patient_info.get(self.target_type, 0)\n",
        "        if label is None:\n",
        "            label = 0\n",
        "\n",
        "        # 이 환자의 모든 메가패치 경로\n",
        "        megapatch_paths = patient_info['images']\n",
        "\n",
        "        # 메가패치 개수 조정\n",
        "        if len(megapatch_paths) > self.max_megapatches:\n",
        "            # 너무 많으면 랜덤 샘플링\n",
        "            megapatch_paths = random.sample(megapatch_paths, self.max_megapatches)\n",
        "        elif len(megapatch_paths) == 0:\n",
        "            # 메가패치가 없으면 더미 데이터\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # 각 stream별 데이터 저장할 리스트들\n",
        "        all_lr_features = []\n",
        "        all_global_features = []\n",
        "        all_hr_features = []\n",
        "\n",
        "        # 각 메가패치 처리\n",
        "        processed_count = 0\n",
        "        for megapatch_path in megapatch_paths:\n",
        "            try:\n",
        "                # 캐싱 확인\n",
        "                if self.cache_dir:\n",
        "                    cache_key = hashlib.md5(\n",
        "                        f\"{megapatch_path}_{self.patches_per_megapatch}\".encode()\n",
        "                    ).hexdigest()\n",
        "                    cache_path = os.path.join(self.cache_dir, f\"{cache_key}.pkl\")\n",
        "\n",
        "                    if os.path.exists(cache_path):\n",
        "                        with open(cache_path, 'rb') as f:\n",
        "                            processed = pickle.load(f)\n",
        "                    else:\n",
        "                        processed = process_megapatch_complete(\n",
        "                            megapatch_path, self.patches_per_megapatch\n",
        "                        )\n",
        "                        with open(cache_path, 'wb') as f:\n",
        "                            pickle.dump(processed, f)\n",
        "                else:\n",
        "                    processed = process_megapatch_complete(\n",
        "                        megapatch_path, self.patches_per_megapatch\n",
        "                    )\n",
        "\n",
        "                # 각 stream별로 tensor 변환\n",
        "                for lr_patch in processed['lr_patches']:\n",
        "                    lr_pil = Image.fromarray(lr_patch)\n",
        "                    lr_tensor = self.transform(lr_pil)\n",
        "                    all_lr_features.append(lr_tensor)\n",
        "\n",
        "                # Global token (메가패치당 1개)\n",
        "                global_pil = Image.fromarray(processed['global_tokens'][0])\n",
        "                global_tensor = self.transform(global_pil)\n",
        "                all_global_features.append(global_tensor)\n",
        "\n",
        "                # HR patches\n",
        "                for hr_patch in processed['hr_patches']:\n",
        "                    hr_pil = Image.fromarray(hr_patch)\n",
        "                    hr_tensor = self.transform(hr_pil)\n",
        "                    all_hr_features.append(hr_tensor)\n",
        "\n",
        "                processed_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  메가패치 처리 실패 {megapatch_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # 처리된 메가패치가 없으면 더미 데이터\n",
        "        if processed_count == 0:\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # Tensor로 변환\n",
        "        lr_tensor = torch.stack(all_lr_features)      # [total_lr, 3, 64, 64]\n",
        "        global_tensor = torch.stack(all_global_features)  # [num_megapatches, 3, 64, 64]\n",
        "        hr_tensor = torch.stack(all_hr_features)      # [total_hr, 3, 256, 256]\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': lr_tensor,\n",
        "            'global_patches': global_tensor,\n",
        "            'hr_patches': hr_tensor,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': processed_count\n",
        "        }\n",
        "\n",
        "    def _create_dummy_data(self, patient_id, label):\n",
        "        \"\"\"메가패치가 없거나 처리 실패시 더미 데이터 생성\"\"\"\n",
        "        dummy_lr = torch.zeros(self.patches_per_megapatch, 3, 64, 64)\n",
        "        dummy_global = torch.zeros(1, 3, 64, 64)\n",
        "        dummy_hr = torch.zeros(self.patches_per_megapatch, 3, 256, 256)\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': dummy_lr,\n",
        "            'global_patches': dummy_global,\n",
        "            'hr_patches': dummy_hr,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': 1\n",
        "        }\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 7 완료: Feature Dimension 통일된 FlexAttention MIL 모델!\")\n",
        "print(\"모든 Feature Extractor가 256 차원으로 통일되어 텐서 크기 오류가 해결되었습니다!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_X-jwFDFvDf"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 8: 훈련 함수 (체크포인트 완벽 지원)\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ5xkOuOFvDf",
        "outputId": "233dcc8c-d366-4c7e-ef50-bed11f8e3ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 8 완전 수정 완료: 모든 오류 해결!\n",
            "이제 extract_features_fixed 함수와 함께 정상 작동합니다!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# 완전히 수정된 Part 8: FlexAttention 훈련 함수\n",
        "# ========================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "\n",
        "def train_flexattention_model_with_checkpoints(\n",
        "    patient_data,\n",
        "    target_type='t_label',\n",
        "    num_folds=5,\n",
        "    num_epochs=8,\n",
        "    batch_size=1,\n",
        "    accumulation_steps=4,\n",
        "    learning_rate=3e-4,\n",
        "    extractor_type='resnet18',\n",
        "    device=device,\n",
        "    work_dir=work_dir,\n",
        "    resume_from_checkpoint=True\n",
        "):\n",
        "    \"\"\"\n",
        "    🚀 완전히 수정된 FlexAttention MIL 훈련 함수\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"🚀 FlexAttention MIL 훈련 시작!\")\n",
        "    print(f\"   Target: {target_type}\")\n",
        "    print(f\"   Folds: {num_folds}, Epochs: {num_epochs}\")\n",
        "    print(f\"   Batch size: {batch_size} × {accumulation_steps} = {batch_size * accumulation_steps}\")\n",
        "    print(f\"   Learning rate: {learning_rate}\")\n",
        "    print(f\"   Extractor: {extractor_type}\")\n",
        "\n",
        "    # 결과 저장 디렉토리\n",
        "    target_dir = os.path.join(work_dir, f\"results_{target_type}\")\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    # 체크포인트 매니저 초기화\n",
        "    checkpoint_manager = CheckpointManager(\n",
        "        checkpoint_dir=os.path.join(target_dir, \"checkpoints\"),\n",
        "        max_keep=3\n",
        "    )\n",
        "\n",
        "    # 환자 데이터 준비\n",
        "    patient_ids = list(patient_data.keys())\n",
        "    patient_labels = [patient_data[pid].get(target_type, 0) for pid in patient_ids]\n",
        "    patient_labels = [0 if label is None else label for label in patient_labels]\n",
        "\n",
        "    print(f\"\\n👥 환자 데이터 준비 완료:\")\n",
        "    print(f\"   총 환자 수: {len(patient_ids)}명\")\n",
        "    print(f\"   라벨 분포: {dict(zip(*np.unique(patient_labels, return_counts=True)))}\")\n",
        "\n",
        "    # Stratified K-Fold 설정\n",
        "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # 전체 결과 저장\n",
        "    all_results = {\n",
        "        'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'auc': [],\n",
        "        'fold_details': []\n",
        "    }\n",
        "\n",
        "    # 각 fold 별 훈련\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(patient_ids, patient_labels)):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"🔄 Fold {fold+1}/{num_folds} 시작\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # 데이터 분할\n",
        "        train_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in train_idx}\n",
        "        test_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in test_idx}\n",
        "\n",
        "        print(f\"   훈련 환자: {len(train_patients)}명\")\n",
        "        print(f\"   테스트 환자: {len(test_patients)}명\")\n",
        "\n",
        "        # Dataset 생성\n",
        "        train_dataset = DynamicFlexAttentionDataset(\n",
        "            train_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=4,  # 메모리 절약\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=6         # 메모리 절약\n",
        "        )\n",
        "\n",
        "        test_dataset = DynamicFlexAttentionDataset(\n",
        "            test_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=4,\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=6\n",
        "        )\n",
        "\n",
        "        # DataLoader 생성\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=False,\n",
        "            drop_last=False\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            pin_memory=False,\n",
        "        )\n",
        "\n",
        "        print(f\"   훈련 배치 수: {len(train_loader)}\")\n",
        "        print(f\"   테스트 배치 수: {len(test_loader)}\")\n",
        "\n",
        "        # 모델 초기화 (작은 크기로)\n",
        "        model = FlexAttentionPatientMIL(\n",
        "            feature_dim=128,           # 256→128로 줄임\n",
        "            num_classes=2,\n",
        "            num_heads=2,               # 4→2로 줄임\n",
        "            num_sa_layers=1,\n",
        "            num_fa_layers=1,\n",
        "            dropout=0.1,\n",
        "            extractor_type=extractor_type\n",
        "        )\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        # 옵티마이저 설정\n",
        "        optimizer = AdamW(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        # 스케줄러 없음 (간단하게)\n",
        "        scheduler = None\n",
        "\n",
        "        # Loss function & Scaler\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scaler = GradScaler()\n",
        "\n",
        "        print(f\"✅ 모델 및 옵티마이저 초기화 완료\")\n",
        "\n",
        "        # 훈련 루프\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\n🔄 Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            # 훈련 단계\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            num_batches = 0\n",
        "\n",
        "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"훈련 진행\")):\n",
        "                try:\n",
        "                    # 데이터를 GPU로 이동\n",
        "                    lr_patches = batch['lr_patches'].to(device)\n",
        "                    global_patches = batch['global_patches'].to(device)\n",
        "                    hr_patches = batch['hr_patches'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "\n",
        "                    with autocast():\n",
        "                        # Feature extraction (수정된 함수 사용)\n",
        "                        lr_features, global_features, hr_features = extract_features_fixed(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        # Forward pass\n",
        "                        logits, attention_maps, selection_stats = model(\n",
        "                            lr_features, global_features, hr_features\n",
        "                        )\n",
        "\n",
        "                        # Loss 계산 (이 부분이 빠져있었음!)\n",
        "                        loss = criterion(logits, labels) / accumulation_steps\n",
        "\n",
        "                    # Backward pass\n",
        "                    scaler.scale(loss).backward()\n",
        "\n",
        "                    # Gradient accumulation\n",
        "                    if (batch_idx + 1) % accumulation_steps == 0:\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                    total_loss += loss.item() * accumulation_steps\n",
        "                    num_batches += 1\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(f\"💥 OOM 발생! 배치 {batch_idx} 스킵\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        continue\n",
        "                    else:\n",
        "                        print(f\"❌ 훈련 오류: {e}\")\n",
        "                        break\n",
        "\n",
        "            avg_loss = total_loss / max(num_batches, 1)\n",
        "            print(f\"   평균 Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # 간단한 검증\n",
        "            model.eval()\n",
        "            test_preds = []\n",
        "            test_labels = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in test_loader:\n",
        "                    try:\n",
        "                        lr_patches = batch['lr_patches'].to(device)\n",
        "                        global_patches = batch['global_patches'].to(device)\n",
        "                        hr_patches = batch['hr_patches'].to(device)\n",
        "                        labels = batch['label'].to(device)\n",
        "\n",
        "                        lr_features, global_features, hr_features = extract_features_fixed(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        logits, _, _ = model(lr_features, global_features, hr_features)\n",
        "                        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "                        test_preds.extend(preds.cpu().tolist())\n",
        "                        test_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"⚠️ 검증 중 오류: {e}\")\n",
        "                        continue\n",
        "\n",
        "            # 성능 계산\n",
        "            if test_labels and test_preds:\n",
        "                accuracy = accuracy_score(test_labels, test_preds)\n",
        "                f1 = f1_score(test_labels, test_preds, zero_division=0)\n",
        "\n",
        "                print(f\"   검증 결과: Acc={accuracy:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "                # 체크포인트 저장\n",
        "                checkpoint_manager.save_checkpoint(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    scheduler=scheduler,\n",
        "                    epoch=epoch,\n",
        "                    fold=fold + 1,\n",
        "                    train_loss=avg_loss,\n",
        "                    val_metrics={'accuracy': accuracy, 'f1': f1},\n",
        "                    is_best=(f1 > checkpoint_manager.best_score)\n",
        "                )\n",
        "\n",
        "            # 메모리 정리\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Fold 완료 후 결과 저장\n",
        "        if test_labels and test_preds:\n",
        "            fold_accuracy = accuracy_score(test_labels, test_preds)\n",
        "            fold_f1 = f1_score(test_labels, test_preds, zero_division=0)\n",
        "\n",
        "            all_results['accuracy'].append(fold_accuracy)\n",
        "            all_results['f1'].append(fold_f1)\n",
        "\n",
        "            print(f\"✅ Fold {fold+1} 완료: Acc={fold_accuracy:.3f}, F1={fold_f1:.3f}\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # 최종 결과\n",
        "    if all_results['accuracy']:\n",
        "        avg_acc = np.mean(all_results['accuracy'])\n",
        "        avg_f1 = np.mean(all_results['f1'])\n",
        "\n",
        "        print(f\"\\n🎉 최종 결과 ({target_type}):\")\n",
        "        print(f\"   평균 Accuracy: {avg_acc:.3f}\")\n",
        "        print(f\"   평균 F1-Score: {avg_f1:.3f}\")\n",
        "\n",
        "        return {\n",
        "            'target_type': target_type,\n",
        "            'avg_accuracy': avg_acc,\n",
        "            'avg_f1': avg_f1,\n",
        "            'accuracy': all_results['accuracy'],\n",
        "            'f1': all_results['f1']\n",
        "        }\n",
        "    else:\n",
        "        print(f\"❌ 유효한 결과가 없습니다.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 8 완전 수정 완료: 모든 오류 해결!\")\n",
        "print(\"이제 extract_features_fixed 함수와 함께 정상 작동합니다!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRyxDkraFvDf"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 9: 실제 훈련 실행\n",
        "# ========================================================================\n",
        "\n",
        "# 이 셀을 아홉 번째로 실행하세요 - 실제 훈련을 시작합니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NzeF7nhFvDf",
        "outputId": "54920646-912a-4825-db9d-8495dbb9d492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 FlexAttention MIL 훈련 준비 완료!\n",
            "================================================================================\n",
            "💾 데이터: 20명의 환자\n",
            "🖥️  디바이스: cuda:0\n",
            "📁 작업 디렉토리: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\n",
            "⏰ 예상 소요 시간: 1-2일 (최적화된 설정)\n",
            "================================================================================\n",
            "🔍 [훈련 시작 전] GPU 메모리 - 사용중: 0.00GB, 예약됨: 0.00GB, 최대사용: 0.00GB\n",
            "\n",
            "⚙️  훈련 설정:\n",
            "   - 메가패치당 패치 수: 8개 (16→8, 50% 절약)\n",
            "   - Feature dimension: 256 (384→256, 33% 절약)\n",
            "   - Attention heads: 4개 (6→4, 33% 절약)\n",
            "   - FlexAttention layers: 1개 (2→1, 50% 절약)\n",
            "   - 배치 크기: 1 (물리적) × 4 (누적) = 4 (효과적)\n",
            "   - Feature extractor: ResNet18 (안정성 우선)\n",
            "\n",
            "❓ 설정이 맞다면 다음 셀을 실행하세요!\n",
            "   T-stage 분류와 재발 예측을 순차적으로 훈련합니다.\n",
            "   각 fold마다 체크포인트가 자동 저장됩니다.\n",
            "\n",
            "📋 훈련 파라미터:\n",
            "   num_folds: 5\n",
            "   num_epochs: 8\n",
            "   batch_size: 1\n",
            "   accumulation_steps: 4\n",
            "   learning_rate: 0.0003\n",
            "   extractor_type: resnet18\n",
            "   resume_from_checkpoint: True\n",
            "\n",
            "✅ 환자 데이터 준비 완료: 20명\n",
            "📊 라벨 분포:\n",
            "   T-stage: {np.int64(0): np.int64(12), np.int64(1): np.int64(8)}\n",
            "   재발: {np.int64(0): np.int64(7), np.int64(1): np.int64(13)}\n",
            "\n",
            "================================================================================\n",
            "Part 9 완료: 훈련 실행 준비 완료!\n",
            "다음 셀에서 실제 훈련을 시작합니다.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 훈련 전 최종 확인 및 설정\n",
        "print(\"🚀 FlexAttention MIL 훈련 준비 완료!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"💾 데이터: {len(patient_data) if 'patient_data' in locals() else 0}명의 환자\")\n",
        "print(f\"🖥️  디바이스: {device}\")\n",
        "print(f\"📁 작업 디렉토리: {work_dir}\")\n",
        "print(f\"⏰ 예상 소요 시간: 1-2일 (최적화된 설정)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 메모리 및 시스템 상태 확인\n",
        "log_gpu_memory(\"훈련 시작 전\")\n",
        "\n",
        "# 훈련 설정 확인\n",
        "print(\"\\n⚙️  훈련 설정:\")\n",
        "print(\"   - 메가패치당 패치 수: 8개 (16→8, 50% 절약)\")\n",
        "print(\"   - Feature dimension: 256 (384→256, 33% 절약)\")\n",
        "print(\"   - Attention heads: 4개 (6→4, 33% 절약)\")\n",
        "print(\"   - FlexAttention layers: 1개 (2→1, 50% 절약)\")\n",
        "print(\"   - 배치 크기: 1 (물리적) × 4 (누적) = 4 (효과적)\")\n",
        "print(\"   - Feature extractor: ResNet18 (안정성 우선)\")\n",
        "\n",
        "# 사용자 확인\n",
        "print(f\"\\n❓ 설정이 맞다면 다음 셀을 실행하세요!\")\n",
        "print(f\"   T-stage 분류와 재발 예측을 순차적으로 훈련합니다.\")\n",
        "print(f\"   각 fold마다 체크포인트가 자동 저장됩니다.\")\n",
        "\n",
        "# 훈련 파라미터 설정\n",
        "TRAINING_CONFIG = {\n",
        "    'num_folds': 5,\n",
        "    'num_epochs': 8,           # 2일 안에 완주하기 위해 12→10\n",
        "    'batch_size': 1,            # 메모리 안전\n",
        "    'accumulation_steps': 4,    # 효과적 배치 크기 = 4\n",
        "    'learning_rate': 3e-4,\n",
        "    'extractor_type': 'resnet18',  # 안정성 우선\n",
        "    'resume_from_checkpoint': True\n",
        "}\n",
        "\n",
        "print(f\"\\n📋 훈련 파라미터:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# 데이터 존재 확인\n",
        "if 'patient_data' not in locals() or not patient_data:\n",
        "    print(f\"\\n❌ 환자 데이터가 로딩되지 않았습니다!\")\n",
        "    print(f\"   Part 5를 먼저 실행하여 데이터를 로딩하세요.\")\n",
        "else:\n",
        "    print(f\"\\n✅ 환자 데이터 준비 완료: {len(patient_data)}명\")\n",
        "\n",
        "    # 라벨 분포 재확인\n",
        "    t_labels = [info.get('t_label', 0) for info in patient_data.values()]\n",
        "    recur_labels = [info.get('recur_label', 0) for info in patient_data.values()]\n",
        "\n",
        "    print(f\"📊 라벨 분포:\")\n",
        "    print(f\"   T-stage: {dict(zip(*np.unique(t_labels, return_counts=True)))}\")\n",
        "    print(f\"   재발: {dict(zip(*np.unique(recur_labels, return_counts=True)))}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 9 완료: 훈련 실행 준비 완료!\")\n",
        "print(\"다음 셀에서 실제 훈련을 시작합니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrghSaZrFvDg"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 10: T-stage 분류 훈련 실행\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP44_GEvFvDg",
        "outputId": "0256667b-43b5-4428-a529-019138a4e2c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 T-stage 분류 훈련 시작!\n",
            "============================================================\n",
            "📋 T-stage 분류:\n",
            "   - 클래스 0: Ta, T1 (저위험 - 근육층 침범 없음)\n",
            "   - 클래스 1: T2+ (고위험 - 근육층 침범 있음)\n",
            "   - 임상적 중요성: 치료 계획 및 예후 예측에 핵심\n",
            "============================================================\n",
            "🕒 훈련 시작 시간: 2025-05-31 14:11:12\n",
            "🔍 [T-stage 훈련 시작] GPU 메모리 - 사용중: 0.00GB, 예약됨: 0.00GB, 최대사용: 0.00GB\n",
            "\n",
            "🚀 T-stage 분류 훈련 시작...\n",
            "\n",
            "❌ T-stage 훈련 중 오류 발생: name 'TRAINING_CONFIG' is not defined\n",
            "📋 오류 상세:\n",
            "\n",
            "🔧 문제 해결 방법:\n",
            "   1. GPU 메모리 부족: batch_size를 1로 줄이기\n",
            "   2. 시스템 메모리 부족: patches_per_megapatch를 8→6으로 줄이기\n",
            "   3. 데이터 문제: Part 5에서 데이터 로딩 다시 확인\n",
            "   4. 체크포인트에서 재시작: resume_from_checkpoint=True 설정\n",
            "\n",
            "================================================================================\n",
            "Part 10 완료: T-stage 분류 훈련 실행!\n",
            "⚠️  훈련에 문제가 발생했습니다. 위의 해결 방법을 참고하세요.\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_203128\\2362231652.py\", line 28, in <module>\n",
            "    **TRAINING_CONFIG  # Part 9에서 정의한 설정 사용\n",
            "      ^^^^^^^^^^^^^^^\n",
            "NameError: name 'TRAINING_CONFIG' is not defined\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 열 번째로 실행하세요 - T-stage 분류 훈련을 시작합니다!\n",
        "\n",
        "print(\"🎯 T-stage 분류 훈련 시작!\")\n",
        "print(\"=\"*60)\n",
        "print(\"📋 T-stage 분류:\")\n",
        "print(\"   - 클래스 0: Ta, T1 (저위험 - 근육층 침범 없음)\")\n",
        "print(\"   - 클래스 1: T2+ (고위험 - 근육층 침범 있음)\")\n",
        "print(\"   - 임상적 중요성: 치료 계획 및 예후 예측에 핵심\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 훈련 시작 시간 기록\n",
        "import time\n",
        "start_time = time.time()\n",
        "start_datetime = datetime.now()\n",
        "\n",
        "print(f\"🕒 훈련 시작 시간: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# 초기 메모리 상태 확인\n",
        "log_gpu_memory(\"T-stage 훈련 시작\")\n",
        "\n",
        "try:\n",
        "    # T-stage 분류 훈련 실행\n",
        "    print(f\"\\n🚀 T-stage 분류 훈련 시작...\")\n",
        "\n",
        "    t_stage_results = train_flexattention_model_with_checkpoints(\n",
        "        patient_data=patient_data,\n",
        "        target_type='t_label',\n",
        "        **TRAINING_CONFIG  # Part 9에서 정의한 설정 사용\n",
        "    )\n",
        "\n",
        "    # 훈련 완료 시간 계산\n",
        "    end_time = time.time()\n",
        "    training_duration = end_time - start_time\n",
        "    hours = int(training_duration // 3600)\n",
        "    minutes = int((training_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\n🎉 T-stage 분류 훈련 완료!\")\n",
        "    print(f\"⏱️  소요 시간: {hours}시간 {minutes}분\")\n",
        "    print(f\"📊 최종 성능:\")\n",
        "\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        print(f\"   평균 Accuracy: {np.mean(t_stage_results['accuracy']):.4f} ± {np.std(t_stage_results['accuracy']):.4f}\")\n",
        "        print(f\"   평균 F1 Score: {np.mean(t_stage_results['f1']):.4f} ± {np.std(t_stage_results['f1']):.4f}\")\n",
        "        print(f\"   평균 AUC: {np.mean(t_stage_results['auc']):.4f} ± {np.std(t_stage_results['auc']):.4f}\")\n",
        "\n",
        "        # 최고 성능 fold 찾기\n",
        "        best_fold_idx = np.argmax(t_stage_results['f1'])\n",
        "        best_f1 = t_stage_results['f1'][best_fold_idx]\n",
        "        print(f\"   최고 성능: Fold {best_fold_idx + 1} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    # 결과 시각화 (간단한 성능 그래프)\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            values = t_stage_results[metric]\n",
        "            plt.bar(range(1, len(values)+1), values, alpha=0.7)\n",
        "            plt.title(f'{name}')\n",
        "            plt.xlabel('Fold')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            # 평균선 추가\n",
        "            mean_val = np.mean(values)\n",
        "            plt.axhline(y=mean_val, color='red', linestyle='--', alpha=0.8)\n",
        "            plt.text(0.5, mean_val + 0.02, f'평균: {mean_val:.3f}', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # 그래프 저장\n",
        "        plot_path = os.path.join(work_dir, \"results_t_label\", \"t_stage_performance.png\")\n",
        "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"📈 성능 그래프 저장: {plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # 메모리 정리\n",
        "    torch.cuda.empty_cache()\n",
        "    log_gpu_memory(\"T-stage 훈련 완료\")\n",
        "\n",
        "    print(f\"\\n✅ T-stage 분류 훈련 성공적으로 완료!\")\n",
        "    print(f\"📁 결과 저장 위치: {os.path.join(work_dir, 'results_t_label')}\")\n",
        "    print(f\"💾 체크포인트: {os.path.join(work_dir, 'results_t_label', 'checkpoints')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ T-stage 훈련 중 오류 발생: {e}\")\n",
        "    print(f\"📋 오류 상세:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # 메모리 정리\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\n🔧 문제 해결 방법:\")\n",
        "    print(f\"   1. GPU 메모리 부족: batch_size를 1로 줄이기\")\n",
        "    print(f\"   2. 시스템 메모리 부족: patches_per_megapatch를 8→6으로 줄이기\")\n",
        "    print(f\"   3. 데이터 문제: Part 5에서 데이터 로딩 다시 확인\")\n",
        "    print(f\"   4. 체크포인트에서 재시작: resume_from_checkpoint=True 설정\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 10 완료: T-stage 분류 훈련 실행!\")\n",
        "if 't_stage_results' in locals():\n",
        "    print(\"✅ 훈련 성공! 다음 Part에서 재발 예측 훈련을 진행합니다.\")\n",
        "else:\n",
        "    print(\"⚠️  훈련에 문제가 발생했습니다. 위의 해결 방법을 참고하세요.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCmYihyqFvDg"
      },
      "source": [
        "# part 12 메모리 정리 + 빠른 테스트 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpS00423FvDg",
        "outputId": "8c607020-f855-41b7-d50a-71fd82a1134d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 초고속 테스트 설정 준비!\n",
            "   예상 시간: 30분-1시간\n",
            "   2-fold × 2-epoch = 총 4번만 훈련\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# 메모리 정리\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# 초고속 테스트 설정\n",
        "FAST_TEST_CONFIG = {\n",
        "    'num_folds': 2,              # 5→2 (빠르게)\n",
        "    'num_epochs': 2,             # 8→2 (빠르게)\n",
        "    'batch_size': 1,\n",
        "    'accumulation_steps': 2,     # 4→2 (메모리 절약)\n",
        "    'learning_rate': 3e-4,\n",
        "    'extractor_type': 'resnet18',\n",
        "    'resume_from_checkpoint': False  # 처음부터\n",
        "}\n",
        "\n",
        "print(\"🚀 초고속 테스트 설정 준비!\")\n",
        "print(f\"   예상 시간: 30분-1시간\")\n",
        "print(f\"   2-fold × 2-epoch = 총 4번만 훈련\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}