{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongwoonalee/jongwoonalee.github.io/blob/main/bladdder_flexattention_0531_final_%EB%B3%B5%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y66udHITeyJ-"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ê¸°ë³¸ ì„¤ì •\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "491d6O58eyKB",
        "outputId": "2809959b-0467-44a4-f768-5427aa87748d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\n",
            "ğŸš€ 1ê°œì˜ GPU ë°œê²¬!\n",
            "   GPU 0: NVIDIA GeForce RTX 4060 (8.0GB)\n",
            "âœ… ì£¼ ë””ë°”ì´ìŠ¤: cuda:0\n",
            "PyTorch ë²„ì „: 2.7.0+cu118\n",
            "CUDA ì‚¬ìš© ê°€ëŠ¥: True\n",
            "âœ… ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ 42ë¡œ ê³ ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "ğŸ” [ì´ˆê¸° ìƒíƒœ] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "\n",
            "================================================================================\n",
            "Part 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ì™„ë£Œ!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ì´ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš” - í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ import í•©ë‹ˆë‹¤\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from skimage.filters import threshold_otsu\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")\n",
        "\n",
        "# GPU ì„¤ì • ë° í™•ì¸ - RTX 6000 Ada x2 ìµœì í™”\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"ğŸš€ {num_gpus}ê°œì˜ GPU ë°œê²¬!\")\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "        print(f\"   GPU {i}: {gpu_name} ({memory_gb:.1f}GB)\")\n",
        "\n",
        "    # CUDA ìµœì í™” ì„¤ì •\n",
        "    torch.backends.cudnn.benchmark = True  # ë™ì¼í•œ ì…ë ¥ í¬ê¸°ì— ëŒ€í•´ ìµœì í™”\n",
        "    torch.cuda.empty_cache()               # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "\n",
        "    print(f\"âœ… ì£¼ ë””ë°”ì´ìŠ¤: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"âš ï¸  GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
        "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
        "\n",
        "# ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    Args:\n",
        "        seed (int): ê³ ì •í•  ì‹œë“œ ê°’ (ê¸°ë³¸ê°’: 42)\n",
        "    \"\"\"\n",
        "    random.seed(seed)              # Python ê¸°ë³¸ random\n",
        "    np.random.seed(seed)           # NumPy random\n",
        "    torch.manual_seed(seed)        # PyTorch CPU random\n",
        "    torch.cuda.manual_seed(seed)   # PyTorch GPU random (í˜„ì¬ ë””ë°”ì´ìŠ¤)\n",
        "    torch.cuda.manual_seed_all(seed)  # PyTorch ëª¨ë“  GPU random\n",
        "\n",
        "    # ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì • (ì†ë„ê°€ ì•½ê°„ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì‹œë“œ ì„¤ì •\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    print(f\"âœ… ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ {seed}ë¡œ ê³ ì •í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ì‹œë“œ ê³ ì • ì‹¤í–‰\n",
        "set_seed(42)\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜\n",
        "def log_gpu_memory(step_name=\"\"):\n",
        "    \"\"\"\n",
        "    í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "    Args:\n",
        "        step_name (str): í˜„ì¬ ë‹¨ê³„ ì´ë¦„ (ë¡œê·¸ êµ¬ë¶„ìš©)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3  # GB ë‹¨ìœ„\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3    # GB ë‹¨ìœ„\n",
        "        max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
        "\n",
        "        print(f\"ğŸ” [{step_name}] GPU ë©”ëª¨ë¦¬ - \"\n",
        "              f\"ì‚¬ìš©ì¤‘: {allocated:.2f}GB, \"\n",
        "              f\"ì˜ˆì•½ë¨: {reserved:.2f}GB, \"\n",
        "              f\"ìµœëŒ€ì‚¬ìš©: {max_allocated:.2f}GB\")\n",
        "    else:\n",
        "        print(f\"ğŸ” [{step_name}] CPU ëª¨ë“œ ì‹¤í–‰ ì¤‘\")\n",
        "\n",
        "# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"ì´ˆê¸° ìƒíƒœ\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X42txZmeyKD"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 2: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TSFYXw5eyKD",
        "outputId": "e0361ad8-aeb9-4c67-8736-cecb5753db07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 2 ì™„ë£Œ: ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\n",
            "ë‹¤ìŒìœ¼ë¡œ Part 3ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ë‘ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ë°ì´í„° ì²˜ë¦¬ì— í•„ìš”í•œ ëª¨ë“  í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
        "\n",
        "def extract_identifier(filename):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ëª…ì—ì„œ í™˜ì IDë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        filename (str): ì´ë¯¸ì§€ íŒŒì¼ëª… (ì˜ˆ: \"S123-456.jpg\")\n",
        "\n",
        "    Returns:\n",
        "        str or None: ì¶”ì¶œëœ í™˜ì ID (ì˜ˆ: \"S123000456\")\n",
        "        str: íŒŒì¼ í™•ì¥ì\n",
        "\n",
        "    Example:\n",
        "        extract_identifier(\"S123-456.jpg\") â†’ (\"S123000456\", \".jpg\")\n",
        "    \"\"\"\n",
        "    # íŒŒì¼ëª…ê³¼ í™•ì¥ì ë¶„ë¦¬\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # ëŒ€ê´„í˜¸ê°€ ìˆìœ¼ë©´ ì œê±° (ì˜ˆ: \"[comment]\" ë¶€ë¶„)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # íŒ¨í„´ 1: Sìˆ«ì-ìˆ«ì í˜•íƒœ (ì˜ˆ: S123-456)\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)      # \"123\"\n",
        "        patch = m1.group(2)      # \"456\"\n",
        "\n",
        "        # íŒ¨ì¹˜ ë²ˆí˜¸ë¥¼ 6ìë¦¬ë¡œ íŒ¨ë”© (ì•ì— 0 ì¶”ê°€)\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch    # 456 â†’ 000456\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch     # 1456 â†’ 001456\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch      # 12456 â†’ 012456\n",
        "        else:\n",
        "            patch_padded = patch            # ì´ë¯¸ 6ìë¦¬ë©´ ê·¸ëŒ€ë¡œ\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # íŒ¨í„´ 2: Sìˆ«ì, í˜•íƒœ (ì˜ˆ: S123,)\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # íŒ¨í„´ 3: S + 6-8ìë¦¬ ìˆ«ì (ì˜ˆ: S12345678)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜\n",
        "    return None, ext\n",
        "\n",
        "def convert_file_id_to_excel_format(file_id):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ IDë¥¼ Excelì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜\n",
        "\n",
        "    Args:\n",
        "        file_id (str): íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ ID\n",
        "\n",
        "    Returns:\n",
        "        str or None: Excel í˜•íƒœë¡œ ë³€í™˜ëœ ID\n",
        "\n",
        "    Example:\n",
        "        convert_file_id_to_excel_format(\"S123-456\") â†’ \"S123000456\"\n",
        "    \"\"\"\n",
        "    if file_id is None:\n",
        "        return None\n",
        "\n",
        "    file_id = str(file_id).strip()\n",
        "\n",
        "    # \"-\"ê°€ í¬í•¨ëœ ê²½ìš° (ì˜ˆ: S123-456)\n",
        "    if \"-\" in file_id:\n",
        "        parts = file_id.split(\"-\")\n",
        "        if len(parts) == 2 and parts[1].isdigit():\n",
        "            patch = parts[1]\n",
        "\n",
        "            # íŒ¨ì¹˜ ë²ˆí˜¸ë¥¼ 6ìë¦¬ë¡œ íŒ¨ë”©\n",
        "            if len(patch) == 3:\n",
        "                padded_number = \"000\" + patch\n",
        "            elif len(patch) == 4:\n",
        "                padded_number = \"00\" + patch\n",
        "            elif len(patch) == 5:\n",
        "                padded_number = \"0\" + patch\n",
        "            else:\n",
        "                padded_number = patch\n",
        "\n",
        "            return f\"{parts[0]}{padded_number}\"\n",
        "\n",
        "    # ì´ë¯¸ Së¡œ ì‹œì‘í•˜ëŠ” ê¸´ í˜•íƒœë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
        "    elif len(file_id) > 3 and file_id.startswith(\"S\"):\n",
        "        return file_id\n",
        "\n",
        "    return None\n",
        "\n",
        "# ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ í•¨ìˆ˜ (ì—¬ê¸°ì„œëŠ” í•¨ìˆ˜ë§Œ ì •ì˜, ì‹¤ì œ ë¡œë”©ì€ ë‹¤ìŒ ì…€ì—ì„œ)\n",
        "def load_and_match_data(zip_path, excel_path, base_dir=None):\n",
        "    \"\"\"\n",
        "    ZIP íŒŒì¼ê³¼ Excel íŒŒì¼ì„ ë§¤ì¹­í•˜ì—¬ í™˜ìë³„ ë°ì´í„°ë¥¼ êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” ZIP íŒŒì¼ ê²½ë¡œ\n",
        "        excel_path (str): ë¼ë²¨ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” Excel íŒŒì¼ ê²½ë¡œ\n",
        "        base_dir (str, optional): ZIP ì••ì¶• í•´ì œí•  ë””ë ‰í† ë¦¬\n",
        "\n",
        "    Returns:\n",
        "        dict: í™˜ìë³„ë¡œ êµ¬ì„±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
        "        {\n",
        "            \"patient_id\": {\n",
        "                \"images\": [ì´ë¯¸ì§€íŒŒì¼ê²½ë¡œë“¤],\n",
        "                \"t_label\": T-stage ë¼ë²¨,\n",
        "                \"recur_label\": ì¬ë°œ ë¼ë²¨,\n",
        "                \"grade\": ë“±ê¸‰ ì •ë³´,\n",
        "                ... ê¸°íƒ€ ì •ë³´\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ ì‹œì‘...\")\n",
        "\n",
        "    # Excel íŒŒì¼ ì½ê¸°\n",
        "    print(\"ğŸ“Š Excel íŒŒì¼ ì½ëŠ” ì¤‘...\")\n",
        "    try:\n",
        "        df = pd.read_excel(excel_path)\n",
        "        print(f\"   âœ… Excel íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰\")\n",
        "        print(f\"   ğŸ“‹ ì»¬ëŸ¼ë“¤: {list(df.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # T-stageì™€ ì¬ë°œ ë¼ë²¨ ìƒì„±\n",
        "    print(\"ğŸ·ï¸  ë¼ë²¨ ë³€í™˜ ì¤‘...\")\n",
        "\n",
        "        # T-stage ë¼ë²¨: 1 â†’ 0 (ì €ìœ„í—˜), 2 â†’ 1 (ê³ ìœ„í—˜)\n",
        "    second_column = df.columns[1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ (Subtype)\n",
        "    df['t_label'] = df[second_column].apply(\n",
        "        lambda x: 0 if str(x) == '1' else 1\n",
        "    )\n",
        "    t_counts = df['t_label'].value_counts()\n",
        "    print(f\"   ğŸ“ˆ T-stage ë¶„í¬: ì €ìœ„í—˜(0): {t_counts.get(0, 0)}ê°œ, ê³ ìœ„í—˜(1): {t_counts.get(1, 0)}ê°œ\")\n",
        "\n",
        "    # ì¬ë°œ ë¼ë²¨: No â†’ 0, Yes â†’ 1\n",
        "    #if 'Recurrence' in df.columns:\n",
        "        #df['recur_label'] = df['Recurrence'].apply(\n",
        "           # lambda x: 0 if str(x).lower() == 'no' else 1\n",
        "        #)\n",
        "       # recur_counts = df['recur_label'].value_counts()\n",
        "      #  print(f\"   ğŸ”„ ì¬ë°œ ë¶„í¬: ì—†ìŒ(0): {recur_counts.get(0, 0)}ê°œ, ìˆìŒ(1): {recur_counts.get(1, 0)}ê°œ\")\n",
        "\n",
        "    # ZIP íŒŒì¼ ì²˜ë¦¬\n",
        "    if base_dir is None:\n",
        "        base_dir = zip_path.replace('.zip', '')\n",
        "\n",
        "    print(f\"ğŸ“¦ ZIP íŒŒì¼ ì²˜ë¦¬ ì¤‘: {zip_path}\")\n",
        "\n",
        "    # ZIP íŒŒì¼ì´ ì´ë¯¸ ì••ì¶• í•´ì œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(\"   ğŸ”„ ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(os.path.dirname(base_dir))\n",
        "        print(\"   âœ… ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì™„ë£Œ\")\n",
        "    else:\n",
        "        print(\"   âœ… ì´ë¯¸ ì••ì¶• í•´ì œëœ í´ë” ë°œê²¬\")\n",
        "\n",
        "    # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°\n",
        "    print(\"ğŸ” ì´ë¯¸ì§€ íŒŒì¼ë“¤ íƒìƒ‰ ì¤‘...\")\n",
        "    image_files = []\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                full_path = os.path.join(root, file)\n",
        "                image_files.append(full_path)\n",
        "\n",
        "    print(f\"   ğŸ“· ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬\")\n",
        "\n",
        "    # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ ë° ë§¤ì¹­\n",
        "    print(\"ğŸ”— í™˜ì ID ë§¤ì¹­ ì¤‘...\")\n",
        "    patient_data = {}\n",
        "    matched_count = 0\n",
        "    unmatched_files = []\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬\"):\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ\n",
        "        file_id, _ = extract_identifier(filename)\n",
        "        if file_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excel í˜•íƒœë¡œ ë³€í™˜\n",
        "        excel_id = convert_file_id_to_excel_format(file_id)\n",
        "        if excel_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excelì—ì„œ í•´ë‹¹ í™˜ì ì°¾ê¸°\n",
        "        patient_row = df[df.iloc[:, 0].astype(str).str.contains(excel_id, na=False)]\n",
        "\n",
        "        if len(patient_row) > 0:\n",
        "            patient_info = patient_row.iloc[0]\n",
        "            patient_id = str(patient_info.iloc[0])\n",
        "\n",
        "            # í™˜ì ë°ì´í„° ì´ˆê¸°í™” (ì²˜ìŒ ë°œê²¬ëœ ê²½ìš°)\n",
        "            if patient_id not in patient_data:\n",
        "                patient_data[patient_id] = {\n",
        "                    'images': [],\n",
        "                    't_label': patient_info.get('t_label', 0),\n",
        "                    'recur_label': patient_info.get('recur_label', 0),\n",
        "                    'grade': patient_info.get('Grade', 'Unknown'),\n",
        "                    't_stage': patient_info.get('T-stage', 'Unknown'),\n",
        "                    'recurrence': patient_info.get('Recurrence', 'Unknown')\n",
        "                }\n",
        "\n",
        "            # ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€\n",
        "            patient_data[patient_id]['images'].append(img_path)\n",
        "            matched_count += 1\n",
        "        else:\n",
        "            unmatched_files.append(filename)\n",
        "\n",
        "    print(f\"   âœ… ë§¤ì¹­ ì™„ë£Œ: {matched_count}ê°œ íŒŒì¼ ë§¤ì¹­\")\n",
        "    print(f\"   âš ï¸  ë§¤ì¹­ ì‹¤íŒ¨: {len(unmatched_files)}ê°œ íŒŒì¼\")\n",
        "    print(f\"   ğŸ‘¥ ì´ í™˜ì ìˆ˜: {len(patient_data)}ëª…\")\n",
        "\n",
        "    # í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜ í†µê³„\n",
        "    image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "    if image_counts:\n",
        "        print(f\"   ğŸ“Š í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜ - í‰ê· : {np.mean(image_counts):.1f}ê°œ, \"\n",
        "              f\"ìµœì†Œ: {min(image_counts)}ê°œ, ìµœëŒ€: {max(image_counts)}ê°œ\")\n",
        "\n",
        "    # ë§¤ì¹­ë˜ì§€ ì•Šì€ íŒŒì¼ ì¼ë¶€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)\n",
        "    if unmatched_files:\n",
        "        print(f\"   ğŸ“ ë§¤ì¹­ ì‹¤íŒ¨ íŒŒì¼ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):\")\n",
        "        for file in unmatched_files[:5]:\n",
        "            print(f\"      - {file}\")\n",
        "\n",
        "    print(\"âœ… ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ ì™„ë£Œ!\")\n",
        "    return patient_data\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 2 ì™„ë£Œ: ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒìœ¼ë¡œ Part 3ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaji-vnMeyKE"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 3: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isBSx1I_eyKE",
        "outputId": "03821a0d-381c-4278-8e49-a8c3e23c84a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 3 ì™„ë£Œ: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\n",
            "ì´ì œ 1024x1024 ì´ë¯¸ì§€ë¥¼ 16ê°œì˜ 3-stream íŒ¨ì¹˜ë¡œ ë¶„í• í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ì„¸ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - FlexAttentionì˜ í•µì‹¬ì¸ ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
        "\n",
        "def split_megapatch_to_patches(megapatch_path, grid_size=4):\n",
        "    \"\"\"\n",
        "    ğŸ”ª STEP 1: 1024x1024 ë©”ê°€íŒ¨ì¹˜ë¥¼ 4x4=16ê°œì˜ 256x256 íŒ¨ì¹˜ë¡œ ë¶„í• \n",
        "\n",
        "    FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - í° ì´ë¯¸ì§€ë¥¼ ì‘ì€ íŒ¨ì¹˜ë“¤ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬\n",
        "    - ê° íŒ¨ì¹˜ëŠ” ë™ì¼í•œ í¬ê¸°ë¡œ ì •ê·œí™”\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 ë©”ê°€íŒ¨ì¹˜ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "        grid_size (int): ê·¸ë¦¬ë“œ í¬ê¸° (4x4 = 16ê°œ íŒ¨ì¹˜, 3x3 = 9ê°œ íŒ¨ì¹˜ ë“±)\n",
        "\n",
        "    Returns:\n",
        "        list: 16ê°œì˜ 256x256 íŒ¨ì¹˜ë“¤ (numpy arrays)\n",
        "        list: ê° íŒ¨ì¹˜ì˜ ìœ„ì¹˜ ì •ë³´ [(i, j), ...]\n",
        "\n",
        "    Example:\n",
        "        patches, positions = split_megapatch_to_patches(\"image.jpg\", 4)\n",
        "        # patches[0]: ì¢Œìƒë‹¨ íŒ¨ì¹˜, patches[15]: ìš°í•˜ë‹¨ íŒ¨ì¹˜\n",
        "        # positions[0]: (0, 0), positions[15]: (3, 3)\n",
        "    \"\"\"\n",
        "    # 1024x1024 ë©”ê°€íŒ¨ì¹˜ ì½ê¸°\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"âŒ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {megapatch_path}\")\n",
        "\n",
        "    # BGR â†’ RGB ë³€í™˜ (OpenCVëŠ” BGR, ìš°ë¦¬ëŠ” RGB ì‚¬ìš©)\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "    h, w = megapatch.shape[:2]\n",
        "\n",
        "    # ê° íŒ¨ì¹˜ í¬ê¸° ê³„ì‚°: 1024/4 = 256\n",
        "    patch_size = h // grid_size  # 256x256\n",
        "\n",
        "    patches = []      # ë¶„í• ëœ íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    positions = []    # ê° íŒ¨ì¹˜ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    # 4x4 ê·¸ë¦¬ë“œë¡œ ë¶„í•  (ì™¼ìª½ ìœ„ë¶€í„° ì˜¤ë¥¸ìª½ ì•„ë˜ë¡œ)\n",
        "    for i in range(grid_size):        # ì„¸ë¡œ ë°©í–¥ (í–‰)\n",
        "        for j in range(grid_size):    # ê°€ë¡œ ë°©í–¥ (ì—´)\n",
        "            # íŒ¨ì¹˜ì˜ ì‹œì‘ì ê³¼ ëì  ê³„ì‚°\n",
        "            y_start = i * patch_size      # ì„¸ë¡œ ì‹œì‘ ìœ„ì¹˜\n",
        "            x_start = j * patch_size      # ê°€ë¡œ ì‹œì‘ ìœ„ì¹˜\n",
        "            y_end = y_start + patch_size  # ì„¸ë¡œ ë ìœ„ì¹˜\n",
        "            x_end = x_start + patch_size  # ê°€ë¡œ ë ìœ„ì¹˜\n",
        "\n",
        "            # 256x256 íŒ¨ì¹˜ ì¶”ì¶œ\n",
        "            patch = megapatch[y_start:y_end, x_start:x_end]\n",
        "            patches.append(patch)\n",
        "            positions.append((i, j))  # (í–‰, ì—´) ìœ„ì¹˜ ì €ì¥\n",
        "\n",
        "    return patches, positions\n",
        "\n",
        "def create_three_streams_from_patch(patch_256, megapatch_1024):\n",
        "    \"\"\"\n",
        "    ğŸ¯ STEP 2: ê° 256x256 íŒ¨ì¹˜ë¡œë¶€í„° 3-stream ìƒì„± (ìˆ˜ì •ë¨!)\n",
        "\n",
        "    FlexAttentionì˜ 3-stream êµ¬ì¡°:\n",
        "    1. LR (Low Resolution): ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ 64x64 ì €í•´ìƒë„ â† ìˆ˜ì •!\n",
        "    2. HR (High Resolution): ì„¸ë°€í•œ ë¶„ì„ì„ ìœ„í•œ 256x256 ê³ í•´ìƒë„\n",
        "    3. Global: ì „ì²´ ë§¥ë½ì„ ìœ„í•œ 64x64 ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸\n",
        "\n",
        "    Args:\n",
        "        patch_256 (numpy.ndarray): 256x256 íŒ¨ì¹˜ (numpy array)\n",
        "        megapatch_1024 (numpy.ndarray): ì „ì²´ 1024x1024 ë©”ê°€íŒ¨ì¹˜ (Global ìƒì„±ìš©)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr': 64x64 LR íŒ¨ì¹˜,\n",
        "            'hr': 256x256 HR íŒ¨ì¹˜ (ì›ë³¸),\n",
        "            'global': 64x64 Global ì»¨í…ìŠ¤íŠ¸\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 1. LR ìŠ¤íŠ¸ë¦¼: 256x256 â†’ 64x64 ë‹¤ìš´ìƒ˜í”Œë§ (ìˆ˜ì •ëœ ë¶€ë¶„!)\n",
        "    # INTER_AREA: ì¶•ì†Œì‹œ í’ˆì§ˆì´ ì¢‹ì€ ë³´ê°„ë²•\n",
        "    lr_patch = cv2.resize(patch_256, (64, 64), interpolation=cv2.INTER_AREA)  # â† ì´ê²ƒì´ í•µì‹¬ ìˆ˜ì •!\n",
        "\n",
        "    # 2. HR ìŠ¤íŠ¸ë¦¼: 256x256 ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "    # ì„¸ë°€í•œ íŠ¹ì§•ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ì›ë³¸ í•´ìƒë„ ìœ ì§€\n",
        "    hr_patch = patch_256.copy()\n",
        "\n",
        "    # 3. Global ìŠ¤íŠ¸ë¦¼: ì „ì²´ 1024x1024 â†’ 64x64 (ë§¤ìš° ì‘ì€ overview)\n",
        "    # ì „ì²´ì ì¸ êµ¬ì¡°ì™€ ë§¥ë½ ì •ë³´ë¥¼ ì œê³µ\n",
        "    global_context = cv2.resize(megapatch_1024, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return {\n",
        "        'lr': lr_patch,         # 64x64 LR (ë¹ ë¥¸ ì²˜ë¦¬ìš©) â† ì´ì œ ì˜¬ë°”ë¥¸ í¬ê¸°!\n",
        "        'hr': hr_patch,         # 256x256 HR (ì„¸ë°€í•œ ë¶„ì„ìš©)\n",
        "        'global': global_context # 64x64 Global (ë§¥ë½ ì •ë³´ìš©)\n",
        "    }\n",
        "\n",
        "def process_megapatch_complete(megapatch_path, patches_per_megapatch=16):\n",
        "    \"\"\"\n",
        "    ğŸš€ STEP 3: ë©”ê°€íŒ¨ì¹˜ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "    ì „ì²´ ê³¼ì •:\n",
        "    1024x1024 ë©”ê°€íŒ¨ì¹˜ â†’ 16ê°œ íŒ¨ì¹˜ë¡œ ë¶„í•  â†’ ê°ê° 3-stream ìƒì„±\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        patches_per_megapatch (int): ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ê°œìˆ˜ (16 or 8 ë“±)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr_patches': 16ê°œì˜ 64x64 LR íŒ¨ì¹˜ë“¤,\n",
        "            'hr_patches': 16ê°œì˜ 256x256 HR íŒ¨ì¹˜ë“¤,\n",
        "            'global_tokens': 16ê°œì˜ 64x64 Global í† í°ë“¤ (ëª¨ë‘ ë™ì¼),\n",
        "            'positions': íŒ¨ì¹˜ ìœ„ì¹˜ ì •ë³´ [(i,j), ...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    # ì›ë³¸ ë©”ê°€íŒ¨ì¹˜ ì½ê¸°\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"âŒ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {megapatch_path}\")\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # patches_per_megapatchì— ë”°ë¼ grid_size ê²°ì •\n",
        "    if patches_per_megapatch == 16:\n",
        "        grid_size = 4    # 4x4 = 16\n",
        "    elif patches_per_megapatch == 9:\n",
        "        grid_size = 3    # 3x3 = 9\n",
        "    elif patches_per_megapatch == 8:\n",
        "        # 8ê°œëŠ” íŠ¹ë³„ ì²˜ë¦¬: 4x4ì—ì„œ 8ê°œë§Œ ì„ íƒ\n",
        "        grid_size = 4\n",
        "        use_subset = True\n",
        "    else:\n",
        "        grid_size = int(math.sqrt(patches_per_megapatch))\n",
        "        use_subset = False\n",
        "\n",
        "    # STEP 1: 1024x1024 â†’ ì—¬ëŸ¬ê°œ 256x256 íŒ¨ì¹˜ë¡œ ë¶„í• \n",
        "    patches_256, positions = split_megapatch_to_patches(megapatch_path, grid_size)\n",
        "\n",
        "    # 8ê°œë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°: ì²´ìŠ¤íŒ íŒ¨í„´ìœ¼ë¡œ ì„ íƒ (ê· ë“± ë¶„í¬)\n",
        "    if patches_per_megapatch == 8 and len(patches_256) == 16:\n",
        "        # ì²´ìŠ¤íŒ íŒ¨í„´: (0,0), (0,2), (1,1), (1,3), (2,0), (2,2), (3,1), (3,3)\n",
        "        selected_indices = []\n",
        "        for i, (row, col) in enumerate(positions):\n",
        "            if (row + col) % 2 == 0:  # ì²´ìŠ¤íŒ íŒ¨í„´\n",
        "                selected_indices.append(i)\n",
        "\n",
        "        # 8ê°œë§Œ ì„ íƒ\n",
        "        selected_indices = selected_indices[:patches_per_megapatch]\n",
        "        patches_256 = [patches_256[i] for i in selected_indices]\n",
        "        positions = [positions[i] for i in selected_indices]\n",
        "\n",
        "    # STEP 2: ê° íŒ¨ì¹˜ë³„ë¡œ 3-stream ìƒì„±\n",
        "    lr_patches = []       # LR íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    hr_patches = []       # HR íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    global_tokens = []    # Global í† í°ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    for patch_256 in patches_256:\n",
        "        # ê° íŒ¨ì¹˜ì— ëŒ€í•´ 3-stream ìƒì„±\n",
        "        streams = create_three_streams_from_patch(patch_256, megapatch)\n",
        "\n",
        "        lr_patches.append(streams['lr'])        # 64x64 LR\n",
        "        hr_patches.append(streams['hr'])        # 256x256 HR\n",
        "        global_tokens.append(streams['global']) # 64x64 Global\n",
        "\n",
        "        # ì°¸ê³ : global_tokensëŠ” ëª¨ë‘ ë™ì¼í•œ ì „ì²´ ì´ë¯¸ì§€ì˜ ì¶•ì†Œë³¸ì…ë‹ˆë‹¤\n",
        "\n",
        "    return {\n",
        "        'lr_patches': lr_patches,     # patches_per_megapatchê°œ Ã— 64x64\n",
        "        'hr_patches': hr_patches,     # patches_per_megapatchê°œ Ã— 256x256\n",
        "        'global_tokens': global_tokens, # patches_per_megapatchê°œ Ã— 64x64 (ëª¨ë‘ ë™ì¼)\n",
        "        'positions': positions        # patches_per_megapatchê°œ ìœ„ì¹˜ ì •ë³´\n",
        "    }\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™” í•¨ìˆ˜\n",
        "def visualize_patch_splitting(megapatch_path, save_path=None):\n",
        "    \"\"\"\n",
        "    ğŸ“Š ë©”ê°€íŒ¨ì¹˜ ë¶„í•  ê³¼ì •ì„ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ (ë””ë²„ê¹… ë° í™•ì¸ìš©)\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): ì‹œê°í™”í•  ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        save_path (str, optional): ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬\n",
        "        processed = process_megapatch_complete(megapatch_path)\n",
        "\n",
        "        # ì‹œê°í™” ì„¤ì •\n",
        "        fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
        "        fig.suptitle(f'ë©”ê°€íŒ¨ì¹˜ ë¶„í•  ê²°ê³¼: {os.path.basename(megapatch_path)}', fontsize=16)\n",
        "\n",
        "        # ì›ë³¸ ë©”ê°€íŒ¨ì¹˜ í‘œì‹œ\n",
        "        megapatch = cv2.imread(megapatch_path)\n",
        "        megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "        axes[0, 0].imshow(megapatch)\n",
        "        axes[0, 0].set_title('ì›ë³¸ ë©”ê°€íŒ¨ì¹˜\\n(1024x1024)', fontsize=10)\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # ì²˜ìŒ 5ê°œ íŒ¨ì¹˜ì˜ 3-stream í‘œì‹œ\n",
        "        for i in range(min(5, len(processed['lr_patches']))):\n",
        "            row = i // 5 + 1\n",
        "            col_start = (i % 5) + 1\n",
        "\n",
        "            # LR íŒ¨ì¹˜ (64x64)\n",
        "            axes[0, col_start].imshow(processed['lr_patches'][i])\n",
        "            axes[0, col_start].set_title(f'LR {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[0, col_start].axis('off')\n",
        "\n",
        "            # HR íŒ¨ì¹˜ (256x256)\n",
        "            axes[1, col_start].imshow(processed['hr_patches'][i])\n",
        "            axes[1, col_start].set_title(f'HR {i+1}\\n(256x256)', fontsize=8)\n",
        "            axes[1, col_start].axis('off')\n",
        "\n",
        "            # Global í† í° (64x64)\n",
        "            axes[2, col_start].imshow(processed['global_tokens'][i])\n",
        "            axes[2, col_start].set_title(f'Global {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[2, col_start].axis('off')\n",
        "\n",
        "        # ë¹ˆ subplotë“¤ ìˆ¨ê¸°ê¸°\n",
        "        for i in range(4):\n",
        "            for j in range(6):\n",
        "                if i > 2 or (i == 0 and j == 0) or (i > 0 and j == 0):\n",
        "                    continue\n",
        "                if not axes[i, j].has_data():\n",
        "                    axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"âœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # í†µê³„ ì •ë³´ ì¶œë ¥\n",
        "        print(f\"ğŸ“Š ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ ê²°ê³¼:\")\n",
        "        print(f\"   - LR íŒ¨ì¹˜ ê°œìˆ˜: {len(processed['lr_patches'])}ê°œ (ê° 64x64)\")\n",
        "        print(f\"   - HR íŒ¨ì¹˜ ê°œìˆ˜: {len(processed['hr_patches'])}ê°œ (ê° 256x256)\")\n",
        "        print(f\"   - Global í† í° ê°œìˆ˜: {len(processed['global_tokens'])}ê°œ (ê° 64x64)\")\n",
        "        print(f\"   - ìœ„ì¹˜ ì •ë³´: {processed['positions'][:5]}... (ì²˜ìŒ 5ê°œ)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 3 ì™„ë£Œ: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ 1024x1024 ì´ë¯¸ì§€ë¥¼ 16ê°œì˜ 3-stream íŒ¨ì¹˜ë¡œ ë¶„í• í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4_l6H3eeyKF"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 4: Feature Extractorì™€ HR Selection\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJAjreSJeyKF",
        "outputId": "dd144660-88d7-4761-a4f4-d073ab1837c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 4 ì™„ë£Œ: Feature Extractorì™€ HR Selector ì •ì˜ ì™„ë£Œ!\n",
            "ResNet18 vs MobileNet vs EfficientNet ì¤‘ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ë„¤ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ResNet ê¸°ë°˜ feature extractorì™€ ë…¼ë¬¸ì˜ threshold ë°©ì‹ HR selectionì„ êµ¬í˜„í•©ë‹ˆë‹¤\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ”¬ ResNet18 ê¸°ë°˜ Feature Extractor\n",
        "\n",
        "    ì—­í• :\n",
        "    - 64x64 ì´ë¯¸ì§€ìš© (LR, Global streams)\n",
        "    - 256x256 ì´ë¯¸ì§€ìš© (HR stream)\n",
        "    - ì´ë¯¸ì§€ë¥¼ ê³ ì • í¬ê¸° feature vectorë¡œ ë³€í™˜\n",
        "\n",
        "    ì„ íƒì§€:\n",
        "    - ResNet18: ì•ˆì •ì ì´ê³  ê²€ì¦ëœ ì„±ëŠ¥ (ì¶”ì²œ)\n",
        "    - MobileNetV3: ë” ë¹ ë¥´ì§€ë§Œ ì„±ëŠ¥ ì•½ê°„ ë‚®ìŒ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, model_type='resnet18', pretrained=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): ì¶œë ¥ feature ì°¨ì› (256 or 384)\n",
        "            model_type (str): ì‚¬ìš©í•  ë°±ë³¸ ëª¨ë¸ ('resnet18', 'mobilenet', 'efficientnet')\n",
        "            pretrained (bool): ImageNet ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€\n",
        "        \"\"\"\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.model_type = model_type\n",
        "\n",
        "        # ë°±ë³¸ ëª¨ë¸ ì„ íƒ ë° ì„¤ì •\n",
        "        if model_type == 'resnet18':\n",
        "            # ResNet18: ì•ˆì •ì ì´ê³  ë„ë¦¬ ì‚¬ìš©ë¨ (11M parameters)\n",
        "            resnet = models.resnet18(pretrained=pretrained)\n",
        "            self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # avgpool, fc ì œê±°\n",
        "            backbone_out_dim = 512\n",
        "\n",
        "        elif model_type == 'mobilenet':\n",
        "            # MobileNetV3-Small: ë¹ ë¥´ê³  ê²½ëŸ‰ (2.5M parameters)\n",
        "            from torchvision.models import mobilenet_v3_small\n",
        "            mobilenet = mobilenet_v3_small(pretrained=pretrained)\n",
        "            self.backbone = mobilenet.features\n",
        "            backbone_out_dim = 576\n",
        "\n",
        "        elif model_type == 'efficientnet':\n",
        "            # EfficientNet-B0: íš¨ìœ¨ì ì´ê³  ì„±ëŠ¥ ì¢‹ìŒ (5.3M parameters)\n",
        "            from torchvision.models import efficientnet_b0\n",
        "            efficientnet = efficientnet_b0(pretrained=pretrained)\n",
        "            self.backbone = efficientnet.features\n",
        "            backbone_out_dim = 1280\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}\")\n",
        "\n",
        "        # Global Average Pooling: spatial dimensionsë¥¼ 1x1ë¡œ ì¶•ì†Œ\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Feature projection: backbone output â†’ ì›í•˜ëŠ” feature dimension\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(backbone_out_dim, feature_dim),\n",
        "            nn.LayerNorm(feature_dim),  # Layer Normalizationìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1)             # 10% ë“œë¡­ì•„ì›ƒìœ¼ë¡œ overfitting ë°©ì§€\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… {model_type.upper()} Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "        print(f\"   - ë°±ë³¸ ì¶œë ¥ ì°¨ì›: {backbone_out_dim}\")\n",
        "        print(f\"   - ìµœì¢… feature ì°¨ì›: {feature_dim}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ feature vectorsë¡œ ë³€í™˜\n",
        "\n",
        "        Args:\n",
        "            x: [batch_size, 3, H, W] - RGB ì´ë¯¸ì§€ ë°°ì¹˜\n",
        "               H, WëŠ” 64 (LR, Global) ë˜ëŠ” 256 (HR)\n",
        "\n",
        "        Returns:\n",
        "            [batch_size, feature_dim] - ì¶”ì¶œëœ feature vectors\n",
        "        \"\"\"\n",
        "        # 1. ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ feature map ì¶”ì¶œ\n",
        "        features = self.backbone(x)      # [B, C, H', W'] - ì˜ˆ: [B, 512, H'/32, W'/32]\n",
        "\n",
        "        # 2. Global Average Poolingìœ¼ë¡œ spatial dimensions ì¶•ì†Œ\n",
        "        pooled = self.avgpool(features)  # [B, C, 1, 1]\n",
        "\n",
        "        # 3. Flatten: [B, C, 1, 1] â†’ [B, C]\n",
        "        flattened = pooled.view(pooled.size(0), -1)  # [B, backbone_out_dim]\n",
        "\n",
        "        # 4. Projectionì„ í†µí•´ ì›í•˜ëŠ” ì°¨ì›ìœ¼ë¡œ ë³€í™˜\n",
        "        projected = self.projection(flattened)       # [B, feature_dim]\n",
        "\n",
        "        return projected\n",
        "\n",
        "\n",
        "class ThresholdBasedHRSelector(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ ë…¼ë¬¸ì˜ ì •í™•í•œ ë°©ì‹: Threshold ê¸°ë°˜ HR Feature Selection\n",
        "\n",
        "    FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - LR attention scoresì—ì„œ thresholdë¥¼ ê³„ì‚°\n",
        "    - Threshold ì´ìƒì¸ íŒ¨ì¹˜ë“¤ë§Œ HRë¡œ ì„ íƒ\n",
        "    - ì•½ 10% ì •ë„ê°€ ì„ íƒë˜ë„ë¡ ë™ì  ì¡°ì •\n",
        "    - Top-K ê³ ì • ì„ íƒì´ ì•„ë‹Œ ì‹¤ì œ ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target_selection_ratio=0.1, min_patches=1, max_patches=4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            target_selection_ratio (float): ëª©í‘œ ì„ íƒ ë¹„ìœ¨ (0.1 = ì•½ 10%)\n",
        "            min_patches (int): ìµœì†Œ ì„ íƒ íŒ¨ì¹˜ ê°œìˆ˜ (ë„ˆë¬´ ì ìœ¼ë©´ ê°•ì œ ì„ íƒ)\n",
        "            max_patches (int): ìµœëŒ€ ì„ íƒ íŒ¨ì¹˜ ê°œìˆ˜ (ë„ˆë¬´ ë§ìœ¼ë©´ ì œí•œ)\n",
        "        \"\"\"\n",
        "        super(ThresholdBasedHRSelector, self).__init__()\n",
        "        self.target_selection_ratio = target_selection_ratio\n",
        "        self.min_patches = min_patches\n",
        "        self.max_patches = max_patches\n",
        "\n",
        "        print(f\"âœ… Threshold ê¸°ë°˜ HR Selector ì´ˆê¸°í™”\")\n",
        "        print(f\"   - ëª©í‘œ ì„ íƒ ë¹„ìœ¨: {target_selection_ratio*100:.1f}%\")\n",
        "        print(f\"   - ì„ íƒ ë²”ìœ„: {min_patches}~{max_patches}ê°œ\")\n",
        "\n",
        "    def forward(self, lr_attention_scores, hr_features):\n",
        "        \"\"\"\n",
        "        Threshold ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”í•œ HR featuresë§Œ ì„ íƒ\n",
        "\n",
        "        Args:\n",
        "            lr_attention_scores: [batch_size, 16] - LR patchesì˜ attention scores\n",
        "            hr_features: [batch_size, 16, feature_dim] - HR patch features\n",
        "\n",
        "        Returns:\n",
        "            selected_hr_features: [batch_size, max_patches, feature_dim] - ì„ íƒëœ HR features\n",
        "            selection_masks: [batch_size, 16] - binary selection mask (ì‹œê°í™”ìš©)\n",
        "            thresholds: [batch_size] - ì‚¬ìš©ëœ threshold ê°’ë“¤ (ë¶„ì„ìš©)\n",
        "        \"\"\"\n",
        "        batch_size, num_patches, feature_dim = hr_features.shape\n",
        "\n",
        "        selected_hr_features = []  # ì„ íƒëœ HR featuresë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        selection_masks = []       # ì„ íƒ ë§ˆìŠ¤í¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        thresholds = []           # ì‚¬ìš©ëœ thresholdë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "        # ë°°ì¹˜ì˜ ê° ìƒ˜í”Œì— ëŒ€í•´ ê°œë³„ ì²˜ë¦¬\n",
        "        for b in range(batch_size):\n",
        "            att_scores = lr_attention_scores[b]  # [16] - ì´ ìƒ˜í”Œì˜ attention scores\n",
        "\n",
        "            # Step 1: Adaptive threshold ê³„ì‚°\n",
        "            threshold = self._compute_adaptive_threshold(att_scores)\n",
        "\n",
        "            # Step 2: Threshold ì ìš©í•˜ì—¬ íŒ¨ì¹˜ ì„ íƒ\n",
        "            mask = att_scores > threshold\n",
        "            selected_indices = torch.where(mask)[0]  # threshold ì´ìƒì¸ íŒ¨ì¹˜ë“¤ì˜ ì¸ë±ìŠ¤\n",
        "\n",
        "            num_selected = len(selected_indices)\n",
        "\n",
        "            # Step 3: ì„ íƒëœ íŒ¨ì¹˜ ìˆ˜ ê²€ì¦ ë° ì¡°ì •\n",
        "            if num_selected < self.min_patches:\n",
        "                # ë„ˆë¬´ ì ê²Œ ì„ íƒëœ ê²½ìš°: ê°•ì œë¡œ ìµœì†Œ ê°œìˆ˜ë§Œí¼ ì„ íƒ\n",
        "                _, top_indices = torch.topk(att_scores, self.min_patches)\n",
        "                selected_indices = top_indices\n",
        "                threshold = att_scores[top_indices[-1]]  # ìƒˆë¡œìš´ threshold\n",
        "\n",
        "            elif num_selected > self.max_patches:\n",
        "                # ë„ˆë¬´ ë§ì´ ì„ íƒëœ ê²½ìš°: ìƒìœ„ max_patchesê°œë§Œ ì„ íƒ\n",
        "                selected_scores = att_scores[selected_indices]\n",
        "                _, top_within_selected = torch.topk(selected_scores, self.max_patches)\n",
        "                selected_indices = selected_indices[top_within_selected]\n",
        "                threshold = att_scores[selected_indices[-1]]  # ìƒˆë¡œìš´ threshold\n",
        "\n",
        "            # Step 4: ì„ íƒëœ HR features ì¶”ì¶œ\n",
        "            selected_features = hr_features[b, selected_indices]  # [num_selected, feature_dim]\n",
        "\n",
        "            # Step 5: ê³ ì • í¬ê¸°ë¡œ íŒ¨ë”© (ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´)\n",
        "            if len(selected_indices) < self.max_patches:\n",
        "                padding_size = self.max_patches - len(selected_indices)\n",
        "                padding = torch.zeros(padding_size, feature_dim, device=hr_features.device)\n",
        "                selected_features = torch.cat([selected_features, padding], dim=0)\n",
        "\n",
        "            selected_hr_features.append(selected_features)\n",
        "\n",
        "            # Step 6: Binary mask ìƒì„± (ì‹œê°í™” ë° ë¶„ì„ìš©)\n",
        "            binary_mask = torch.zeros_like(att_scores)\n",
        "            if len(selected_indices) > 0:\n",
        "                binary_mask[selected_indices] = 1.0\n",
        "            selection_masks.append(binary_mask)\n",
        "\n",
        "            thresholds.append(threshold)\n",
        "\n",
        "        # ë¦¬ìŠ¤íŠ¸ë“¤ì„ í…ì„œë¡œ ë³€í™˜\n",
        "        selected_hr_features = torch.stack(selected_hr_features)  # [B, max_patches, feature_dim]\n",
        "        selection_masks = torch.stack(selection_masks)            # [B, 16]\n",
        "        thresholds = torch.stack(thresholds)                      # [B]\n",
        "\n",
        "        return selected_hr_features, selection_masks, thresholds\n",
        "\n",
        "    def _compute_adaptive_threshold(self, attention_scores):\n",
        "        \"\"\"\n",
        "        ì ì‘ì  threshold ê³„ì‚° - ì—¬ëŸ¬ ë°©ë²• ì¤‘ ê°€ì¥ ì ì ˆí•œ ê²ƒ ì„ íƒ\n",
        "\n",
        "        Args:\n",
        "            attention_scores: [16] - í•˜ë‚˜ì˜ ìƒ˜í”Œì— ëŒ€í•œ attention scores\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: ê³„ì‚°ëœ threshold ê°’\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Method 1: Otsu threshold (ì´ì§„í™”ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìµœì  ë¶„í• ì )\n",
        "            # ê°€ì¥ ì¢‹ì€ ë°©ë²•ì´ì§€ë§Œ sklearn í•„ìš”\n",
        "            scores_np = attention_scores.detach().cpu().numpy()\n",
        "            threshold_val = threshold_otsu(scores_np)\n",
        "            return torch.tensor(threshold_val, device=attention_scores.device)\n",
        "\n",
        "        except:\n",
        "            # Method 2: Percentile-based threshold (Fallback)\n",
        "            # ìƒìœ„ target_selection_ratio*2 ì •ë„ê°€ ì„ íƒë˜ë„ë¡\n",
        "            percentile = 1.0 - (self.target_selection_ratio * 2)  # 80th percentile for 10% target\n",
        "            threshold_val = torch.quantile(attention_scores, percentile)\n",
        "            return threshold_val\n",
        "\n",
        "    def get_selection_statistics(self, selection_masks):\n",
        "        \"\"\"\n",
        "        ì„ íƒ í†µê³„ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§ìš©)\n",
        "\n",
        "        Args:\n",
        "            selection_masks: [batch_size, 16] - binary selection masks\n",
        "\n",
        "        Returns:\n",
        "            dict: ì„ íƒ í†µê³„ ì •ë³´\n",
        "        \"\"\"\n",
        "        num_selected_per_sample = selection_masks.sum(dim=1)  # [batch_size]\n",
        "\n",
        "        stats = {\n",
        "            'mean_selected': num_selected_per_sample.float().mean().item(),\n",
        "            'min_selected': num_selected_per_sample.min().item(),\n",
        "            'max_selected': num_selected_per_sample.max().item(),\n",
        "            'selection_ratio': (num_selected_per_sample.float() / selection_masks.shape[1]).mean().item(),\n",
        "            'std_selected': num_selected_per_sample.float().std().item()\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "\n",
        "# Feature Extractor ì„±ëŠ¥ ë¹„êµ í•¨ìˆ˜\n",
        "def compare_feature_extractors():\n",
        "    \"\"\"\n",
        "    ğŸ”¬ ë‹¤ì–‘í•œ Feature Extractorë“¤ì˜ ì„±ëŠ¥ê³¼ ì†ë„ ë¹„êµ\n",
        "    ì‹¤ì œ ì„ íƒì— ë„ì›€ì„ ì£¼ëŠ” ë²¤ì¹˜ë§ˆí¬\n",
        "    \"\"\"\n",
        "    print(\"ğŸ”¬ Feature Extractor ì„±ëŠ¥ ë¹„êµ\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ ë°ì´í„°\n",
        "    dummy_lr = torch.randn(4, 3, 64, 64)    # LR íŒ¨ì¹˜ë“¤\n",
        "    dummy_hr = torch.randn(4, 3, 256, 256)  # HR íŒ¨ì¹˜ë“¤\n",
        "\n",
        "    extractors = {\n",
        "        'ResNet18': ResNetFeatureExtractor(feature_dim=256, model_type='resnet18'),\n",
        "        'MobileNetV3': ResNetFeatureExtractor(feature_dim=256, model_type='mobilenet'),\n",
        "        'EfficientNet-B0': ResNetFeatureExtractor(feature_dim=256, model_type='efficientnet')\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, extractor in extractors.items():\n",
        "        print(f\"\\nğŸ“Š {name} í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
        "\n",
        "        # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
        "        total_params = sum(p.numel() for p in extractor.parameters())\n",
        "        trainable_params = sum(p.numel() for p in extractor.parameters() if p.requires_grad)\n",
        "\n",
        "        # ì†ë„ ì¸¡ì • (LR íŒ¨ì¹˜)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10ë²ˆ ë°˜ë³µ ì¸¡ì •\n",
        "                _ = extractor(dummy_lr)\n",
        "        lr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        # ì†ë„ ì¸¡ì • (HR íŒ¨ì¹˜)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10ë²ˆ ë°˜ë³µ ì¸¡ì •\n",
        "                _ = extractor(dummy_hr)\n",
        "        hr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        results[name] = {\n",
        "            'total_params': total_params,\n",
        "            'trainable_params': trainable_params,\n",
        "            'lr_time_ms': lr_time * 1000,\n",
        "            'hr_time_ms': hr_time * 1000\n",
        "        }\n",
        "\n",
        "        print(f\"   íŒŒë¼ë¯¸í„° ìˆ˜: {total_params/1e6:.1f}M\")\n",
        "        print(f\"   LR ì²˜ë¦¬ ì†ë„: {lr_time*1000:.1f}ms\")\n",
        "        print(f\"   HR ì²˜ë¦¬ ì†ë„: {hr_time*1000:.1f}ms\")\n",
        "\n",
        "    # ì¶”ì²œ ì¶œë ¥\n",
        "    print(f\"\\nğŸ¯ ì¶”ì²œ:\")\n",
        "    print(f\"   - ì•ˆì •ì„± ìš°ì„ : ResNet18 (ê²€ì¦ëœ ì„±ëŠ¥)\")\n",
        "    print(f\"   - ì†ë„ ìš°ì„ : MobileNetV3 (ê°€ì¥ ë¹ ë¦„)\")\n",
        "    print(f\"   - ë°¸ëŸ°ìŠ¤: EfficientNet-B0 (ì„±ëŠ¥-ì†ë„ ì ˆì¶©)\")\n",
        "    print(f\"   - 2ì¼ ì•ˆì— ì™„ì£¼: ResNet18 ë˜ëŠ” MobileNetV3\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ì‚¬ìš©ë²• ì˜ˆì‹œ\n",
        "def example_usage():\n",
        "    \"\"\"Feature Extractorì™€ HR Selector ì‚¬ìš© ì˜ˆì‹œ\"\"\"\n",
        "    print(\"ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:\")\n",
        "\n",
        "    # Feature Extractor ìƒì„±\n",
        "    feature_extractor = ResNetFeatureExtractor(\n",
        "        feature_dim=256,\n",
        "        model_type='resnet18',  # 'resnet18', 'mobilenet', 'efficientnet' ì¤‘ ì„ íƒ\n",
        "        pretrained=True\n",
        "    )\n",
        "\n",
        "    # HR Selector ìƒì„±\n",
        "    hr_selector = ThresholdBasedHRSelector(\n",
        "        target_selection_ratio=0.1,  # 10% ì„ íƒ ëª©í‘œ\n",
        "        min_patches=1,               # ìµœì†Œ 1ê°œ\n",
        "        max_patches=4                # ìµœëŒ€ 4ê°œ\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 4 ì™„ë£Œ: Feature Extractorì™€ HR Selector ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ResNet18 vs MobileNet vs EfficientNet ì¤‘ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8r_kN9peyKG"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 5: ì‹¤ì œ ë°ì´í„° ë¡œë”© (ë¡œì»¬ ê²½ë¡œ)\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSvuOBoDeyKG",
        "outputId": "9bae53f5-7cbc-4489-c20c-364b456dd433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ  ë¡œì»¬ í™˜ê²½ ì„¤ì • ì™„ë£Œ!\n",
            "ğŸ” ì¤‘ì²© í´ë”ì—ì„œ ë°œê²¬: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\n",
            "\n",
            "ğŸ” í´ë” í™•ì¸:\n",
            "   C_TIL: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\\C_TIL\n",
            "   P_TIL: C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\\ExternalUSB_Bladder_240710\\P_TIL\n",
            "   C_TIL ì´ë¯¸ì§€: 4261ê°œ\n",
            "   P_TIL ì´ë¯¸ì§€: 4446ê°œ\n",
            "\n",
            "ğŸ“‹ ìƒ˜í”Œ íŒŒì¼ëª…:\n",
            "   ._S15-11819,B [d=2.01814,x=18599,y=148794,w=2067,h=2066].png â†’ None\n",
            "   ._S15-16941 [d=2.01814,x=24799,y=169459,w=2067,h=2067].png â†’ None\n",
            "   ._S15-16941 [d=2.01814,x=26866,y=169459,w=2066,h=2067].png â†’ None\n",
            "\n",
            "âœ… Excel íŒŒì¼ ë¡œë“œ: 100ê°œ í–‰\n",
            "ğŸ“‹ ì»¬ëŸ¼: ['Number', 'T', 'Subtype', 'Recur']\n",
            "\n",
            "ğŸ“Š ìƒ˜í”Œ Excel ë°ì´í„°:\n",
            "   S15000922: Subtype=sarc, T=2, Recur=1\n",
            "   S15003203: Subtype=sarc, T=1, Recur=0\n",
            "   S15003380: Subtype=0, T=2, Recur=1\n",
            "   S15004965: Subtype=0, T=1, Recur=0\n",
            "   S15007775: Subtype=0, T=1, Recur=1\n",
            "\n",
            "ğŸ·ï¸ ë¼ë²¨ ë¶„í¬ í™•ì¸:\n",
            "   Subtype ë¶„í¬: {0: np.int64(81), 'sarc': np.int64(7), 'micropapillary': np.int64(4), 'SQ': np.int64(3), 'plasmacytoid': np.int64(2), 'sarcomatoid': np.int64(1), 'giant': np.int64(1), 'small': np.int64(1)}\n",
            "ğŸ“ˆ ìˆ˜ì •ëœ T-stage ë¶„í¬: ì €ìœ„í—˜(0): 100ê°œ, ê³ ìœ„í—˜(1): 0ê°œ\n",
            "\n",
            "ğŸš€ í–¥ìƒëœ ë§¤ì¹­ ì‹œì‘...\n",
            "ğŸ” [ë§¤ì¹­ ì „] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "ğŸ“Š Excel ID ìˆ˜: 100\n",
            "ğŸ“‹ Excel ID ìƒ˜í”Œ: ['S22016735', 'S16002693', 'S21005946', 'S22015315', 'S19032688']\n",
            "\n",
            "ğŸ“ C_TIL: 4261ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C_TIL ë§¤ì¹­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4261/4261 [00:00<00:00, 13226.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   C_TIL ë§¤ì¹­: 2194ê°œ\n",
            "\n",
            "ğŸ“ P_TIL: 4446ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "P_TIL ë§¤ì¹­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4446/4446 [00:00<00:00, 14893.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   P_TIL ë§¤ì¹­: 2193ê°œ\n",
            "\n",
            "âœ… ì „ì²´ ë§¤ì¹­ ê²°ê³¼: 8707ê°œ ì´ë¯¸ì§€ ì¤‘ 4387ê°œ ë§¤ì¹­\n",
            "\n",
            "ğŸ‘¥ í™˜ìë³„ ë°ì´í„°:\n",
            "   ì´ í™˜ì: 100ëª…\n",
            "   ì´ ì´ë¯¸ì§€: 4387ê°œ\n",
            "   í™˜ìë³„ í‰ê·  ì´ë¯¸ì§€: 43.9ê°œ\n",
            "   T-stage ë¶„í¬: ì €ìœ„í—˜(0)=64ëª…, ê³ ìœ„í—˜(1)=36ëª…\n",
            "\n",
            "ğŸ‘¤ ìƒ˜í”Œ í™˜ì (S15011819):\n",
            "   ì´ë¯¸ì§€ ìˆ˜: 94ê°œ\n",
            "   T-stage: T2\n",
            "   ì¬ë°œ: Yes\n",
            "\n",
            "âœ… ì„±ê³µ! 100ëª…ì˜ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n",
            "ğŸš€ ì „ì²´ ëª¨ë“œ: 100ëª… ëª¨ë“  í™˜ì ì‚¬ìš©\n",
            "ğŸ’¾ ë°ì´í„° ì €ì¥: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\\cache\\patient_data.pkl\n",
            "ğŸ” [ë§¤ì¹­ í›„] GPU ë©”ëª¨ë¦¬ - ì‚¬ìš©ì¤‘: 0.00GB, ì˜ˆì•½ë¨: 0.00GB, ìµœëŒ€ì‚¬ìš©: 0.00GB\n",
            "\n",
            "================================================================================\n",
            "Part 5 ì™„ë£Œ: í–¥ìƒëœ ë°ì´í„° ë¡œë”©!\n",
            "ìµœì¢… í™˜ì ìˆ˜: 100ëª…\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 5: ì™„ì „ ìˆ˜ì •ëœ ë°ì´í„° ë¡œë”©\n",
        "# ========================================================================\n",
        "\n",
        "import re\n",
        "from tqdm import tqdm  # notebook ëŒ€ì‹  ì¼ë°˜ tqdm ì‚¬ìš©\n",
        "\n",
        "\n",
        "# ğŸ  ë¡œì»¬ ê²½ë¡œ ì„¤ì •\n",
        "zip_path = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710.zip\"\n",
        "excel_path = r\"C:\\Users\\ehdwk\\Downloads\\MIL_TURB_240918_Modified.xlsx\"\n",
        "base_dir = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\"\n",
        "\n",
        "# ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "checkpoint_dir = os.path.join(work_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(work_dir, \"logs\")\n",
        "cache_dir = os.path.join(work_dir, \"cache\")\n",
        "result_dir = os.path.join(work_dir, \"results\")\n",
        "\n",
        "for directory in [work_dir, checkpoint_dir, log_dir, cache_dir, result_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ  ë¡œì»¬ í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n",
        "\n",
        "# ğŸ” ì‹¤ì œ ë°ì´í„° í´ë” ì°¾ê¸°\n",
        "def find_data_folders(base_dir):\n",
        "    \"\"\"ì¤‘ì²©ëœ í´ë” êµ¬ì¡°ì—ì„œ ì‹¤ì œ C_TIL, P_TIL í´ë” ì°¾ê¸°\"\"\"\n",
        "\n",
        "    # 1ì°¨: ì§ì ‘ í™•ì¸\n",
        "    c_til_dir = os.path.join(base_dir, \"C_TIL\")\n",
        "    p_til_dir = os.path.join(base_dir, \"P_TIL\")\n",
        "\n",
        "    if os.path.exists(c_til_dir) and os.path.exists(p_til_dir):\n",
        "        return c_til_dir, p_til_dir\n",
        "\n",
        "    # 2ì°¨: í•˜ìœ„ í´ë”ì—ì„œ ì°¾ê¸°\n",
        "    for item in os.listdir(base_dir):\n",
        "        item_path = os.path.join(base_dir, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            nested_c_til = os.path.join(item_path, \"C_TIL\")\n",
        "            nested_p_til = os.path.join(item_path, \"P_TIL\")\n",
        "\n",
        "            if os.path.exists(nested_c_til) and os.path.exists(nested_p_til):\n",
        "                print(f\"ğŸ” ì¤‘ì²© í´ë”ì—ì„œ ë°œê²¬: {item_path}\")\n",
        "                return nested_c_til, nested_p_til\n",
        "\n",
        "    return None, None\n",
        "\n",
        "# ğŸ”§ ë³µì¡í•œ íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ\n",
        "def extract_patient_id_advanced(filename):\n",
        "    \"\"\"\n",
        "    ì‹¤ì œ ì‘ë™í–ˆë˜ ë¡œì§ + ìˆ¨ê¹€íŒŒì¼ í•„í„°\n",
        "    \"\"\"\n",
        "    # ìˆ¨ê¹€íŒŒì¼ ì œê±°\n",
        "    if filename.startswith('._'):\n",
        "        return None\n",
        "\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # ëŒ€ê´„í˜¸ ì• ë¶€ë¶„ë§Œ ì‚¬ìš© (ì¢Œí‘œ ì •ë³´ ì œê±°)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # íŒ¨í„´ 1: S15-3380 í˜•ì‹\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)  # ì˜ˆ: \"15\"\n",
        "        patch = m1.group(2)  # ì˜ˆ: \"3380\"\n",
        "\n",
        "        # íŒ¨ì¹˜ ë²ˆí˜¸ ê¸¸ì´ì— ë”°ë¼ íŒ¨ë”© ì¶”ê°€\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch\n",
        "        else:\n",
        "            patch_padded = patch\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # íŒ¨í„´ 2: S16022792,1A í˜•ì‹\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\"\n",
        "\n",
        "    # íŒ¨í„´ 3: S16021286 í˜•ì‹ (ì´ë¯¸ ì™„ì„±ëœ í˜•ì‹)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# ì‹¤ì œ ë°ì´í„° í´ë” ì°¾ê¸°\n",
        "c_til_dir, p_til_dir = find_data_folders(base_dir)\n",
        "\n",
        "print(f\"\\nğŸ” í´ë” í™•ì¸:\")\n",
        "print(f\"   C_TIL: {c_til_dir}\")\n",
        "print(f\"   P_TIL: {p_til_dir}\")\n",
        "\n",
        "if c_til_dir and p_til_dir:\n",
        "    c_images = [f for f in os.listdir(c_til_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    p_images = [f for f in os.listdir(p_til_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"   C_TIL ì´ë¯¸ì§€: {len(c_images)}ê°œ\")\n",
        "    print(f\"   P_TIL ì´ë¯¸ì§€: {len(p_images)}ê°œ\")\n",
        "\n",
        "    # ìƒ˜í”Œ íŒŒì¼ëª… í™•ì¸\n",
        "    print(f\"\\nğŸ“‹ ìƒ˜í”Œ íŒŒì¼ëª…:\")\n",
        "    for i, filename in enumerate(c_images[:3]):\n",
        "        extracted_id = extract_patient_id_advanced(filename)\n",
        "        print(f\"   {filename} â†’ {extracted_id}\")\n",
        "\n",
        "# Excel íŒŒì¼ ë¡œë“œ ë° ë¼ë²¨ í™•ì¸\n",
        "try:\n",
        "    labels_df = pd.read_excel(excel_path)\n",
        "    print(f\"\\nâœ… Excel íŒŒì¼ ë¡œë“œ: {len(labels_df)}ê°œ í–‰\")\n",
        "    print(f\"ğŸ“‹ ì»¬ëŸ¼: {list(labels_df.columns)}\")\n",
        "\n",
        "    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
        "    print(f\"\\nğŸ“Š ìƒ˜í”Œ Excel ë°ì´í„°:\")\n",
        "    for i in range(min(5, len(labels_df))):\n",
        "        row = labels_df.iloc[i]\n",
        "        print(f\"   {row['Number']}: Subtype={row.get('Subtype', 'N/A')}, T={row.get('T', 'N/A')}, Recur={row.get('Recur', 'N/A')}\")\n",
        "\n",
        "    # Subtype ë¶„í¬ í™•ì¸ (ìˆ˜ì •ëœ ë¡œì§)\n",
        "    print(f\"\\nğŸ·ï¸ ë¼ë²¨ ë¶„í¬ í™•ì¸:\")\n",
        "    if 'Subtype' in labels_df.columns:\n",
        "        subtype_counts = labels_df['Subtype'].value_counts()\n",
        "        print(f\"   Subtype ë¶„í¬: {dict(subtype_counts)}\")\n",
        "\n",
        "        # ì˜¬ë°”ë¥¸ ë¼ë²¨ ë³€í™˜: Subtype 1â†’0, Subtype 2â†’1\n",
        "        t_labels_corrected = []\n",
        "        for _, row in labels_df.iterrows():\n",
        "            subtype = row['Subtype']\n",
        "            if subtype == 1:\n",
        "                t_label = 0  # ì €ìœ„í—˜\n",
        "            elif subtype == 2:\n",
        "                t_label = 1  # ê³ ìœ„í—˜\n",
        "            else:\n",
        "                t_label = 0  # ê¸°ë³¸ê°’\n",
        "            t_labels_corrected.append(t_label)\n",
        "\n",
        "        print(f\"ğŸ“ˆ ìˆ˜ì •ëœ T-stage ë¶„í¬: ì €ìœ„í—˜(0): {t_labels_corrected.count(0)}ê°œ, ê³ ìœ„í—˜(1): {t_labels_corrected.count(1)}ê°œ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Excel íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
        "    labels_df = None\n",
        "\n",
        "# í–¥ìƒëœ ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­\n",
        "def match_images_with_labels_v2(c_til_dir, p_til_dir, labels_df):\n",
        "    \"\"\"í–¥ìƒëœ ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­\"\"\"\n",
        "\n",
        "    if not c_til_dir or not p_til_dir or labels_df is None:\n",
        "        print(\"âŒ í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return []\n",
        "\n",
        "    # Excel IDë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì§‘í•© ìƒì„±\n",
        "    excel_ids = set(str(id_val) for id_val in labels_df['Number'].values)\n",
        "    print(f\"ğŸ“Š Excel ID ìˆ˜: {len(excel_ids)}\")\n",
        "    print(f\"ğŸ“‹ Excel ID ìƒ˜í”Œ: {list(excel_ids)[:5]}\")\n",
        "\n",
        "    matched_samples = []\n",
        "    total_images = 0\n",
        "    matched_images = 0\n",
        "\n",
        "    # ë‘ í´ë” ëª¨ë‘ ì²˜ë¦¬\n",
        "    for folder_name, data_dir in [(\"C_TIL\", c_til_dir), (\"P_TIL\", p_til_dir)]:\n",
        "        if not os.path.exists(data_dir):\n",
        "            continue\n",
        "\n",
        "        image_files = [f for f in os.listdir(data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        total_images += len(image_files)\n",
        "        print(f\"\\nğŸ“ {folder_name}: {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬\")\n",
        "\n",
        "        folder_matched = 0\n",
        "\n",
        "        for filename in tqdm(image_files, desc=f\"{folder_name} ë§¤ì¹­\"):\n",
        "            # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ\n",
        "            patient_id = extract_patient_id_advanced(filename)\n",
        "\n",
        "            if patient_id and patient_id in excel_ids:\n",
        "                # Excelì—ì„œ í•´ë‹¹ í™˜ì ì •ë³´ ì°¾ê¸°\n",
        "                patient_row = labels_df[labels_df['Number'] == patient_id]\n",
        "\n",
        "                if not patient_row.empty:\n",
        "                    row = patient_row.iloc[0]\n",
        "\n",
        "                    # T ì»¬ëŸ¼ë§Œ ì‚¬ìš© (ê°„ë‹¨!)\n",
        "                    t_value = row.get('T', 1)\n",
        "                    t_label = 0 if t_value == 1 else 1  # T=1â†’0(ì €ìœ„í—˜), T=2â†’1(ê³ ìœ„í—˜)\n",
        "\n",
        "                    # ì¬ë°œ ë¼ë²¨\n",
        "                    recur = row.get('Recur', None)\n",
        "                    recur_label = int(recur) if pd.notna(recur) else None\n",
        "\n",
        "                    matched_samples.append({\n",
        "                        'patient_id': patient_id,\n",
        "                        'image_path': os.path.join(data_dir, filename),\n",
        "                        't_label': t_label,\n",
        "                        'recur_label': recur_label,\n",
        "                        'subtype': t_value,  # T ê°’ ì €ì¥\n",
        "                        'folder': folder_name\n",
        "                    })\n",
        "\n",
        "                    matched_images += 1\n",
        "                    folder_matched += 1\n",
        "\n",
        "        print(f\"   {folder_name} ë§¤ì¹­: {folder_matched}ê°œ\")\n",
        "\n",
        "    print(f\"\\nâœ… ì „ì²´ ë§¤ì¹­ ê²°ê³¼: {total_images}ê°œ ì´ë¯¸ì§€ ì¤‘ {matched_images}ê°œ ë§¤ì¹­\")\n",
        "    return matched_samples\n",
        "\n",
        "# í™˜ìë³„ ê·¸ë£¹í™” (ê°œì„ ë¨)\n",
        "def group_by_patient_v2(matched_samples):\n",
        "    \"\"\"í™˜ìë³„ ë°ì´í„° ê·¸ë£¹í™” (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
        "\n",
        "    patient_data = {}\n",
        "\n",
        "    for sample in matched_samples:\n",
        "        patient_id = sample['patient_id']\n",
        "\n",
        "        if patient_id not in patient_data:\n",
        "            patient_data[patient_id] = {\n",
        "                't_label': sample['t_label'],\n",
        "                'recur_label': sample['recur_label'],\n",
        "                'images': [],\n",
        "                't_stage': f\"T{sample['subtype']}\",  # T1 ë˜ëŠ” T2\n",
        "                'recurrence': 'No' if sample['recur_label'] == 0 else 'Yes' if sample['recur_label'] == 1 else 'Unknown'\n",
        "            }\n",
        "\n",
        "        patient_data[patient_id]['images'].append(sample['image_path'])\n",
        "\n",
        "    # í†µê³„\n",
        "    if patient_data:\n",
        "        image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "        t_distribution = [info['t_label'] for info in patient_data.values()]\n",
        "\n",
        "        print(f\"\\nğŸ‘¥ í™˜ìë³„ ë°ì´í„°:\")\n",
        "        print(f\"   ì´ í™˜ì: {len(patient_data)}ëª…\")\n",
        "        print(f\"   ì´ ì´ë¯¸ì§€: {sum(image_counts)}ê°œ\")\n",
        "        print(f\"   í™˜ìë³„ í‰ê·  ì´ë¯¸ì§€: {np.mean(image_counts):.1f}ê°œ\")\n",
        "        print(f\"   T-stage ë¶„í¬: ì €ìœ„í—˜(0)={t_distribution.count(0)}ëª…, ê³ ìœ„í—˜(1)={t_distribution.count(1)}ëª…\")\n",
        "\n",
        "        # ìƒ˜í”Œ í™˜ì ì •ë³´\n",
        "        sample_id = list(patient_data.keys())[0]\n",
        "        sample_info = patient_data[sample_id]\n",
        "        print(f\"\\nğŸ‘¤ ìƒ˜í”Œ í™˜ì ({sample_id}):\")\n",
        "        print(f\"   ì´ë¯¸ì§€ ìˆ˜: {len(sample_info['images'])}ê°œ\")\n",
        "        print(f\"   T-stage: {sample_info['t_stage']}\")\n",
        "        print(f\"   ì¬ë°œ: {sample_info['recurrence']}\")\n",
        "\n",
        "    return patient_data\n",
        "\n",
        "# ì‹¤í–‰\n",
        "# ì‹¤í–‰\n",
        "print(f\"\\nğŸš€ í–¥ìƒëœ ë§¤ì¹­ ì‹œì‘...\")\n",
        "log_gpu_memory(\"ë§¤ì¹­ ì „\")\n",
        "\n",
        "try:\n",
        "    all_samples = match_images_with_labels_v2(c_til_dir, p_til_dir, labels_df)\n",
        "    patient_data = group_by_patient_v2(all_samples)\n",
        "\n",
        "    if patient_data and len(patient_data) > 0:  # â† ì—¬ê¸° ë“¤ì—¬ì“°ê¸° ìˆ˜ì •!\n",
        "        print(f\"\\nâœ… ì„±ê³µ! {len(patient_data)}ëª…ì˜ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
        "\n",
        "        # í…ŒìŠ¤íŠ¸ìš© 10ëª…ìœ¼ë¡œ ì œí•œ (ë‚´ì¼ í™•ì¸ í›„ ì „ì²´ ì‚¬ìš©)\n",
        "        TEST_MODE = False  # â† ì´ í•œ ì¤„ë§Œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤! Falseë¡œ ë°”ê¾¸ë©´ ì „ì²´\n",
        "\n",
        "        if TEST_MODE:\n",
        "            if len(patient_data) > 10:\n",
        "                limited_ids = list(patient_data.keys())[:10]\n",
        "                patient_data = {pid: patient_data[pid] for pid in limited_ids}\n",
        "                print(f\"ğŸ”¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {len(patient_data)}ëª…ìœ¼ë¡œ ì œí•œ\")\n",
        "        else:\n",
        "            print(f\"ğŸš€ ì „ì²´ ëª¨ë“œ: {len(patient_data)}ëª… ëª¨ë“  í™˜ì ì‚¬ìš©\")\n",
        "\n",
        "        # ì €ì¥\n",
        "        data_save_path = os.path.join(cache_dir, \"patient_data.pkl\")\n",
        "        with open(data_save_path, 'wb') as f:\n",
        "            pickle.dump(patient_data, f)\n",
        "        print(f\"ğŸ’¾ ë°ì´í„° ì €ì¥: {data_save_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ í™˜ì ë°ì´í„° ìƒì„± ì‹¤íŒ¨ - ë§¤ì¹­ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤\")\n",
        "        patient_data = {}\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    patient_data = {}\n",
        "\n",
        "log_gpu_memory(\"ë§¤ì¹­ í›„\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 5 ì™„ë£Œ: í–¥ìƒëœ ë°ì´í„° ë¡œë”©!\")\n",
        "print(f\"ìµœì¢… í™˜ì ìˆ˜: {len(patient_data) if patient_data else 0}ëª…\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQVEUKAaeyKG"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 6: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention\n",
        "# ========================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHgBDG-PeyKG",
        "outputId": "91abad3e-ad94-4f07-d87f-1616ee52a787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\\checkpoints\n",
            "âœ… Flash Attention í™œì„±í™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)\n",
            "âœ… CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\n",
            "âœ… GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
            "\n",
            "================================================================================\n",
            "Part 6 ì™„ë£Œ: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention ì¤€ë¹„ ì™„ë£Œ!\n",
            "ì´ì œ í›ˆë ¨ ì¤‘ë‹¨ë˜ì–´ë„ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class CheckpointManager:\n",
        "    \"\"\"\n",
        "    ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
        "\n",
        "    ê¸°ëŠ¥:\n",
        "    - ë§¤ epochë§ˆë‹¤ ëª¨ë¸ ìƒíƒœ ìë™ ì €ì¥\n",
        "    - í›ˆë ¨ ì¤‘ë‹¨ì‹œ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥\n",
        "    - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ì¥\n",
        "    - í›ˆë ¨ ë¡œê·¸ ë° í†µê³„ ì €ì¥\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir, max_keep=5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            checkpoint_dir (str): ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "            max_keep (int): ìµœëŒ€ ë³´ê´€í•  ì²´í¬í¬ì¸íŠ¸ ê°œìˆ˜ (ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ)\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.max_keep = max_keep\n",
        "        self.best_score = 0.0\n",
        "        self.training_log = []\n",
        "\n",
        "        # ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        print(f\"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”: {checkpoint_dir}\")\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, fold,\n",
        "                       train_loss, val_metrics=None, is_best=False):\n",
        "        \"\"\"\n",
        "        ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë§¤ epochë§ˆë‹¤ í˜¸ì¶œ)\n",
        "\n",
        "        Args:\n",
        "            model: í›ˆë ¨ ì¤‘ì¸ ëª¨ë¸\n",
        "            optimizer: ì˜µí‹°ë§ˆì´ì €\n",
        "            scheduler: ìŠ¤ì¼€ì¤„ëŸ¬\n",
        "            epoch: í˜„ì¬ epoch\n",
        "            fold: í˜„ì¬ fold ë²ˆí˜¸\n",
        "            train_loss: í›ˆë ¨ loss\n",
        "            val_metrics: ê²€ì¦ ë©”íŠ¸ë¦­ë“¤ (dict)\n",
        "            is_best: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì¸ì§€ ì—¬ë¶€\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ì •ë³´\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.module.state_dict() if hasattr(model, 'module') else model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp,\n",
        "            'best_score': self.best_score\n",
        "        }\n",
        "\n",
        "        # ì •ê·œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
        "        checkpoint_path = os.path.join(\n",
        "            self.checkpoint_dir,\n",
        "            f\"checkpoint_fold{fold}_epoch{epoch:03d}_{timestamp}.pt\"\n",
        "        )\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "        # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ë¡œ ë§í¬ (ì¬ì‹œì‘ ì‹œ ì‚¬ìš©)\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ì¥\n",
        "        if is_best:\n",
        "            best_path = os.path.join(self.checkpoint_dir, f\"best_model_fold{fold}.pt\")\n",
        "            torch.save(checkpoint, best_path)\n",
        "            self.best_score = val_metrics.get('f1', 0.0) if val_metrics else 0.0\n",
        "            print(f\"ğŸ† ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥! F1: {self.best_score:.4f}\")\n",
        "\n",
        "        # í›ˆë ¨ ë¡œê·¸ ì—…ë°ì´íŠ¸\n",
        "        log_entry = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "        self.training_log.append(log_entry)\n",
        "\n",
        "        # ë¡œê·¸ íŒŒì¼ ì €ì¥\n",
        "        log_path = os.path.join(self.checkpoint_dir, f\"training_log_fold{fold}.json\")\n",
        "        with open(log_path, 'w') as f:\n",
        "            json.dump(self.training_log, f, indent=2)\n",
        "\n",
        "        print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold {fold}, Epoch {epoch}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬\n",
        "        self._cleanup_old_checkpoints(fold)\n",
        "\n",
        "    def _cleanup_old_checkpoints(self, fold):\n",
        "        \"\"\"ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì •ë¦¬\"\"\"\n",
        "        import glob\n",
        "\n",
        "        # í•´ë‹¹ foldì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì°¾ê¸°\n",
        "        pattern = os.path.join(self.checkpoint_dir, f\"checkpoint_fold{fold}_*.pt\")\n",
        "        checkpoints = glob.glob(pattern)\n",
        "\n",
        "        # ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
        "        checkpoints.sort(key=os.path.getctime)\n",
        "\n",
        "        # max_keep ê°œìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ\n",
        "        while len(checkpoints) > self.max_keep:\n",
        "            old_checkpoint = checkpoints.pop(0)\n",
        "            try:\n",
        "                os.remove(old_checkpoint)\n",
        "                print(f\"ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: {os.path.basename(old_checkpoint)}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    def load_latest_checkpoint(self, fold):\n",
        "        \"\"\"\n",
        "        ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë¡œë”© (ì¬ì‹œì‘ ì‹œ ì‚¬ìš©)\n",
        "\n",
        "        Args:\n",
        "            fold: ë¡œë”©í•  fold ë²ˆí˜¸\n",
        "\n",
        "        Returns:\n",
        "            dict or None: ì²´í¬í¬ì¸íŠ¸ ë°ì´í„°, ì—†ìœ¼ë©´ None\n",
        "        \"\"\"\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "\n",
        "        if os.path.exists(latest_path):\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            print(f\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: Fold {fold}, Epoch {checkpoint['epoch']}\")\n",
        "            return checkpoint\n",
        "        else:\n",
        "            print(f\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ: Fold {fold} (ì²˜ìŒë¶€í„° ì‹œì‘)\")\n",
        "            return None\n",
        "\n",
        "\n",
        "class HierarchicalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬: Hierarchical Self-Attention\n",
        "\n",
        "    í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - ì¼ë°˜ Self-Attention: O(nÂ²) - ëª¨ë“  í† í°ì´ ëª¨ë“  í† í°ê³¼ ìƒí˜¸ì‘ìš©\n",
        "    - Hierarchical: O(nÃ—M) - ì„ íƒëœ HR í† í°ë§Œ ìƒí˜¸ì‘ìš© (M << n)\n",
        "    - ê³„ì‚°ëŸ‰ ëŒ€í­ ê°ì†Œí•˜ë©´ì„œ ì„±ëŠ¥ ìœ ì§€!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_heads=4, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): feature ì°¨ì› (256 ì¶”ì²œ, 384ëŠ” ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)\n",
        "            num_heads (int): attention head ê°œìˆ˜ (4 ì¶”ì²œ, 6ì€ ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)\n",
        "            dropout (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
        "        \"\"\"\n",
        "        super(HierarchicalSelfAttention, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = feature_dim // num_heads\n",
        "\n",
        "        # feature_dimì´ num_headsë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ëŠ”ì§€ í™•ì¸\n",
        "        assert feature_dim % num_heads == 0, f\"feature_dim({feature_dim})ì´ num_heads({num_heads})ë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤!\"\n",
        "\n",
        "        # ğŸ”µ ì¼ë°˜ hidden statesìš© projections (LR + Global + CLS tokens)\n",
        "        self.q_proj = nn.Linear(feature_dim, feature_dim)  # Query projection\n",
        "        self.k_proj = nn.Linear(feature_dim, feature_dim)  # Key projection\n",
        "        self.v_proj = nn.Linear(feature_dim, feature_dim)  # Value projection\n",
        "\n",
        "        # ğŸ”´ HR features ì „ìš© projections (ë…¼ë¬¸ì˜ W'_K, W'_V)\n",
        "        # ì¤‘ìš”: HR featuresëŠ” ë³„ë„ì˜ projectionì„ ì‚¬ìš©!\n",
        "        self.k_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_K for HR\n",
        "        self.v_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_V for HR\n",
        "\n",
        "        # ì¶œë ¥ projection\n",
        "        self.out_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = math.sqrt(self.head_dim)  # attention scaling factor\n",
        "\n",
        "        print(f\"âœ… Hierarchical Self-Attention ì´ˆê¸°í™”\")\n",
        "        print(f\"   - Feature dim: {feature_dim}, Heads: {num_heads}, Head dim: {self.head_dim}\")\n",
        "\n",
        "    def forward(self, hidden_states, selected_hr_features):\n",
        "        \"\"\"\n",
        "        Hierarchical Self-Attention ê³„ì‚° (ë…¼ë¬¸ì˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜)\n",
        "\n",
        "        Args:\n",
        "            hidden_states: [batch_size, N, feature_dim]\n",
        "                          N = LR tokens + Global tokens + CLS token\n",
        "            selected_hr_features: [batch_size, M, feature_dim]\n",
        "                                M = ì„ íƒëœ HR tokens (ë³´í†µ 1~4ê°œ)\n",
        "\n",
        "        Returns:\n",
        "            output: [batch_size, N, feature_dim] - ì—…ë°ì´íŠ¸ëœ hidden states\n",
        "            attention_map: [batch_size, N-1] - CLS tokenì˜ attention (ë‹¤ìŒ layerìš©)\n",
        "        \"\"\"\n",
        "        batch_size, N, _ = hidden_states.shape          # N: LR + Global + CLS ê°œìˆ˜\n",
        "        _, M, _ = selected_hr_features.shape            # M: ì„ íƒëœ HR ê°œìˆ˜\n",
        "\n",
        "        # ğŸ”µ Step 1: ì¼ë°˜ hidden statesì— ëŒ€í•œ Q, K, V ê³„ì‚°\n",
        "        Q = self.q_proj(hidden_states)      # [B, N, D] - Query (ì–´ë””ì— ì§‘ì¤‘í• ì§€?)\n",
        "        K_h = self.k_proj(hidden_states)    # [B, N, D] - Key (ë‚˜ëŠ” ì´ëŸ° ì •ë³´ì•¼)\n",
        "        V_h = self.v_proj(hidden_states)    # [B, N, D] - Value (ì‹¤ì œ ì „ë‹¬í•  ì •ë³´)\n",
        "\n",
        "        # ğŸ”´ Step 2: HR featuresì— ëŒ€í•œ ë³„ë„ K, V ê³„ì‚° (ë…¼ë¬¸ì˜ í•µì‹¬!)\n",
        "        K_hr = self.k_proj_hr(selected_hr_features)  # [B, M, D] - HRìš© Key\n",
        "        V_hr = self.v_proj_hr(selected_hr_features)  # [B, M, D] - HRìš© Value\n",
        "\n",
        "        # ğŸ”— Step 3: Keyì™€ Valueë¥¼ ì—°ê²° [ì¼ë°˜ tokens + HR tokens]\n",
        "        K_all = torch.cat([K_h, K_hr], dim=1)  # [B, N+M, D] - ëª¨ë“  Keys\n",
        "        V_all = torch.cat([V_h, V_hr], dim=1)  # [B, N+M, D] - ëª¨ë“  Values\n",
        "\n",
        "        # ğŸ§  Step 4: Multi-head attentionì„ ìœ„í•œ reshape\n",
        "        # [B, seq_len, D] â†’ [B, num_heads, seq_len, head_dim]\n",
        "        Q = Q.view(batch_size, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K_all = K_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V_all = V_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # âš¡ Step 5: Attention ê³„ì‚° - ì—¬ê¸°ì„œ ê³„ì‚°ëŸ‰ O(NÃ—(N+M))\n",
        "        # ì¼ë°˜ Self-Attentionì´ë¼ë©´ O((N+M)Â²)ì´ì§€ë§Œ,\n",
        "        # QueryëŠ” Nê°œë¿ì´ë¯€ë¡œ O(NÃ—(N+M)) = O(NÂ²+NM)\n",
        "        scores = torch.matmul(Q, K_all.transpose(-2, -1)) / self.scale  # [B, H, N, N+M]\n",
        "        attention_weights = F.softmax(scores, dim=-1)                   # attention í™•ë¥ \n",
        "        attention_weights = self.dropout(attention_weights)             # ë“œë¡­ì•„ì›ƒ ì ìš©\n",
        "\n",
        "        # ğŸ¯ Step 6: Attention ì ìš©í•˜ì—¬ ì •ë³´ ì§‘ì•½\n",
        "        attended = torch.matmul(attention_weights, V_all)  # [B, H, N, head_dim]\n",
        "\n",
        "        # ğŸ”„ Step 7: Multi-head ê²°ê³¼ í•©ì¹˜ê¸°\n",
        "        attended = attended.transpose(1, 2).contiguous()  # [B, N, H, head_dim]\n",
        "        attended = attended.view(batch_size, N, self.feature_dim)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“¤ Step 8: ìµœì¢… ì¶œë ¥ projection\n",
        "        output = self.out_proj(attended)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“Š Step 9: ë‹¤ìŒ layerìš© attention map ì¶”ì¶œ\n",
        "        # CLS token (ë§ˆì§€ë§‰ í† í°)ì´ LR tokensì— ì£¼ëŠ” attention\n",
        "        cls_attention = attention_weights[:, :, -1, :N-1]  # [B, H, N-1] - CLS â†’ LR\n",
        "        attention_map = cls_attention.mean(dim=1)          # [B, N-1] - head í‰ê· \n",
        "\n",
        "        return output, attention_map\n",
        "\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í•¨ìˆ˜ë“¤\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ì„¤ì •\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ attention ì‚¬ìš© (PyTorch 2.0+)\n",
        "        try:\n",
        "            torch.backends.cuda.enable_flash_sdp(True)\n",
        "            print(\"âœ… Flash Attention í™œì„±í™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)\")\n",
        "        except:\n",
        "            print(\"âš ï¸  Flash Attention ë¯¸ì§€ì› (PyTorch ë²„ì „ í™•ì¸)\")\n",
        "\n",
        "        # CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "        print(\"âœ… CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"âœ… GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
        "\n",
        "def log_model_info(model):\n",
        "    \"\"\"ëª¨ë¸ ì •ë³´ ë¡œê¹…\"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"ğŸ” ëª¨ë¸ ì •ë³´:\")\n",
        "    print(f\"   - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ ({total_params/1e6:.1f}M)\")\n",
        "    print(f\"   - í›ˆë ¨ ê°€ëŠ¥: {trainable_params:,}ê°œ ({trainable_params/1e6:.1f}M)\")\n",
        "    print(f\"   - ëª¨ë¸ í¬ê¸°: {total_params * 4 / 1024**2:.1f}MB (float32 ê¸°ì¤€)\")\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    max_keep=3  # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ ë³´ê´€ (ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½)\n",
        ")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰\n",
        "optimize_memory_usage()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 6 ì™„ë£Œ: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ í›ˆë ¨ ì¤‘ë‹¨ë˜ì–´ë„ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwVfLP6zeyKH"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 7: ì™„ì „í•œ MIL ëª¨ë¸ê³¼ Dataset\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ì¼ê³± ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì™„ì „í•œ FlexAttention MIL ëª¨ë¸ê³¼ Datasetì„ êµ¬í˜„í•©ë‹ˆë‹¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olm2hONyeyKH",
        "outputId": "17067303-39a3-4e8d-a0cb-824c4f3fb2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 7 ì™„ë£Œ: Feature Dimension í†µì¼ëœ FlexAttention MIL ëª¨ë¸!\n",
            "ëª¨ë“  Feature Extractorê°€ 256 ì°¨ì›ìœ¼ë¡œ í†µì¼ë˜ì–´ í…ì„œ í¬ê¸° ì˜¤ë¥˜ê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class FlexAttentionPatientMIL(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ ì™„ì „í•œ FlexAttention Multiple Instance Learning ëª¨ë¸\n",
        "\n",
        "    ì „ì²´ êµ¬ì¡°:\n",
        "    1. í™˜ìë³„ ì—¬ëŸ¬ ë©”ê°€íŒ¨ì¹˜ â†’ ê°ê° 8ê°œ íŒ¨ì¹˜ â†’ 3-stream features\n",
        "    2. LR + Global tokens â†’ Standard Self-Attention layers\n",
        "    3. LR attention â†’ HR selection â†’ FlexAttention layers\n",
        "    4. CLS token â†’ Patient-level classification (ì•” ë‹¨ê³„/ì¬ë°œ ì˜ˆì¸¡)\n",
        "\n",
        "    ê³„ì‚°ëŸ‰ ìµœì í™”:\n",
        "    - ë©”ê°€íŒ¨ì¹˜ë‹¹ 16ê°œ â†’ 8ê°œ íŒ¨ì¹˜ë¡œ ê°ì†Œ (50% ì ˆì•½)\n",
        "    - Feature dim 384 â†’ 256ë¡œ ê°ì†Œ (33% ì ˆì•½)\n",
        "    - FA layers 2ê°œ â†’ 1ê°œë¡œ ê°ì†Œ (50% ì ˆì•½)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_classes=2, num_heads=4,\n",
        "                 num_sa_layers=1, num_fa_layers=1, dropout=0.1,\n",
        "                 extractor_type='resnet18'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): Feature ì°¨ì› (256 ì¶”ì²œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "            num_classes (int): ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜ (2: binary classification)\n",
        "            num_heads (int): Attention head ìˆ˜ (4 ì¶”ì²œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "            num_sa_layers (int): Standard Self-Attention layer ìˆ˜\n",
        "            num_fa_layers (int): FlexAttention layer ìˆ˜\n",
        "            dropout (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
        "            extractor_type (str): Feature extractor íƒ€ì… ('resnet18', 'mobilenet')\n",
        "        \"\"\"\n",
        "        super(FlexAttentionPatientMIL, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_sa_layers = num_sa_layers\n",
        "        self.num_fa_layers = num_fa_layers\n",
        "\n",
        "        print(f\"ğŸ—ï¸  FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
        "        print(f\"   - Feature dim: {feature_dim}\")\n",
        "        print(f\"   - Attention heads: {num_heads}\")\n",
        "        print(f\"   - SA layers: {num_sa_layers}, FA layers: {num_fa_layers}\")\n",
        "        print(f\"   - Extractor: {extractor_type}\")\n",
        "\n",
        "        # ğŸ”¬ Feature extractors (3ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ í•´ìƒë„ìš©) - ëª¨ë‘ 256 ì°¨ì›ìœ¼ë¡œ í†µì¼!\n",
        "        if extractor_type == 'resnet18':\n",
        "            self.lr_extractor = ResNetFeatureExtractor(feature_dim=feature_dim)    # 256ìœ¼ë¡œ í†µì¼\n",
        "            self.global_extractor = ResNetFeatureExtractor(feature_dim=feature_dim) # 256ìœ¼ë¡œ í†µì¼\n",
        "            self.hr_extractor = ResNetFeatureExtractor(feature_dim=feature_dim)    # 256ìœ¼ë¡œ í†µì¼\n",
        "        elif extractor_type == 'mobilenet':\n",
        "            self.lr_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "            self.global_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "            self.hr_extractor = MobileNetFeatureExtractor(feature_dim=feature_dim)\n",
        "        else:\n",
        "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” extractor_type: {extractor_type}\")\n",
        "\n",
        "        # ğŸ¯ CLS token (í™˜ì ë ˆë²¨ ë¶„ë¥˜ë¥¼ ìœ„í•œ íŠ¹ë³„í•œ í† í°)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, feature_dim))\n",
        "\n",
        "        # ğŸ“ Positional encoding (í† í° ìœ„ì¹˜ ì •ë³´)\n",
        "        # ìµœëŒ€ í† í° ìˆ˜: í™˜ìë‹¹ 20ë©”ê°€íŒ¨ì¹˜ Ã— 8íŒ¨ì¹˜ = 160 LR + 20 Global + 1 CLS = 181\n",
        "        max_tokens = 200  # ì—¬ìœ ìˆê²Œ ì„¤ì •\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, max_tokens, feature_dim))\n",
        "\n",
        "        # ğŸ§  Standard Self-Attention layers (LR + Global + CLSë§Œ ì‚¬ìš©)\n",
        "        self.sa_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=feature_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=feature_dim * 4,  # FFN hidden dim\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True  # Pre-LN for better training stability\n",
        "            ) for _ in range(num_sa_layers)\n",
        "        ])\n",
        "\n",
        "        # ğŸ¯ FlexAttention components\n",
        "        self.hr_selectors = nn.ModuleList([\n",
        "            ThresholdBasedHRSelector(\n",
        "                target_selection_ratio=0.1,  # 10% ì„ íƒ\n",
        "                min_patches=1,\n",
        "                max_patches=4\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.hierarchical_attentions = nn.ModuleList([\n",
        "            HierarchicalSelfAttention(feature_dim, num_heads, dropout)\n",
        "            for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # FlexAttention layerìš© FFNê³¼ LayerNorm\n",
        "        self.fa_ffns = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(feature_dim, feature_dim * 4),\n",
        "                nn.GELU(),  # ReLUë³´ë‹¤ ë” ë¶€ë“œëŸ¬ìš´ í™œì„±í™” í•¨ìˆ˜\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(feature_dim * 4, feature_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.fa_layer_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(feature_dim) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # ğŸ¥ ìµœì¢… ë¶„ë¥˜ê¸° (í™˜ì ë ˆë²¨ ì˜ˆì¸¡)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feature_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
        "        self._initialize_weights()\n",
        "\n",
        "        print(f\"âœ… FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ë” ì•ˆì •ì ì¸ í›ˆë ¨ì„ ìœ„í•´)\"\"\"\n",
        "        # CLS token ì´ˆê¸°í™”\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "\n",
        "        # Positional encoding ì´ˆê¸°í™”\n",
        "        nn.init.trunc_normal_(self.pos_encoding, std=0.02)\n",
        "\n",
        "        # Linear layer ì´ˆê¸°í™”\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.trunc_normal_(module.weight, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def forward(self, lr_features, global_features, hr_features):\n",
        "        \"\"\"\n",
        "        FlexAttention MIL Forward Pass\n",
        "\n",
        "        Args:\n",
        "            lr_features: [batch_size, total_lr_patches, feature_dim] - ëª¨ë“  LR features\n",
        "            global_features: [batch_size, num_megapatches, feature_dim] - Global features\n",
        "            hr_features: [batch_size, total_hr_patches, feature_dim] - ëª¨ë“  HR features\n",
        "\n",
        "        Returns:\n",
        "            logits: [batch_size, num_classes] - í™˜ì ë ˆë²¨ ì˜ˆì¸¡\n",
        "            attention_maps: List[Tensor] - attention maps (ì‹œê°í™”ìš©)\n",
        "            selection_stats: Dict - HR selection í†µê³„ (ë¶„ì„ìš©)\n",
        "        \"\"\"\n",
        "        batch_size = lr_features.shape[0]\n",
        "\n",
        "        # ğŸ“Š ì…ë ¥ ë°ì´í„° í¬ê¸° í™•ì¸ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
        "        max_lr_tokens = min(lr_features.shape[1], 128)    # ìµœëŒ€ 128ê°œ LR tokens\n",
        "        max_global_tokens = min(global_features.shape[1], 16)  # ìµœëŒ€ 16ê°œ Global tokens\n",
        "        max_hr_tokens = min(hr_features.shape[1], 128)    # ìµœëŒ€ 128ê°œ HR tokens\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ í† í°ë§Œ ì‚¬ìš©\n",
        "        lr_subset = lr_features[:, :max_lr_tokens]        # [B, â‰¤128, D]\n",
        "        global_subset = global_features[:, :max_global_tokens]  # [B, â‰¤16, D]\n",
        "        hr_subset = hr_features[:, :max_hr_tokens]        # [B, â‰¤128, D] (ë‚˜ì¤‘ì— ì¼ë¶€ë§Œ ì„ íƒë¨)\n",
        "\n",
        "        # ğŸ”§ Feature dimension ì²´í¬ ë° í†µì¼ (ìˆ˜ì •ëœ ë¶€ë¶„!)\n",
        "        assert lr_subset.shape[2] == self.feature_dim, f\"LR features dim mismatch: {lr_subset.shape[2]} vs {self.feature_dim}\"\n",
        "        assert global_subset.shape[2] == self.feature_dim, f\"Global features dim mismatch: {global_subset.shape[2]} vs {self.feature_dim}\"\n",
        "        assert hr_subset.shape[2] == self.feature_dim, f\"HR features dim mismatch: {hr_subset.shape[2]} vs {self.feature_dim}\"\n",
        "\n",
        "        # ğŸ¯ Step 1: Token sequence êµ¬ì„± [LR + Global + CLS]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # [B, 1, D]\n",
        "\n",
        "        # ì´ˆê¸° hidden states: LR tokens + Global tokens + CLS token (ëª¨ë‘ ê°™ì€ ì°¨ì›!)\n",
        "        hidden_states = torch.cat([lr_subset, global_subset, cls_tokens], dim=1)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“ Positional encoding ì¶”ê°€\n",
        "        seq_len = hidden_states.shape[1]\n",
        "        if seq_len <= self.pos_encoding.shape[1]:\n",
        "            hidden_states = hidden_states + self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        attention_maps = []  # attention mapë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        selection_stats = {'total_selected': [], 'selection_ratios': []}\n",
        "\n",
        "        # ğŸ§  Step 2: Standard Self-Attention layers (Algorithm 1, lines 8-12)\n",
        "        for i in range(self.num_sa_layers):\n",
        "            hidden_states = self.sa_layers[i](hidden_states)\n",
        "\n",
        "        # ğŸ¯ Step 3: FlexAttention layers (Algorithm 1, lines 14-19)\n",
        "        for i in range(self.num_fa_layers):\n",
        "            # Step 3a: LR attention ê¸°ë°˜ HR selection\n",
        "            if i == 0:\n",
        "                # ì²« ë²ˆì§¸ layer: uniform attention (ëª¨ë“  LR í† í°ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜)\n",
        "                num_lr_tokens = lr_subset.shape[1]\n",
        "                lr_attention_map = torch.ones(batch_size, num_lr_tokens, device=lr_features.device)\n",
        "                lr_attention_map = lr_attention_map / lr_attention_map.sum(dim=1, keepdim=True)\n",
        "            else:\n",
        "                # ì´ì „ layerì˜ attention ì‚¬ìš©\n",
        "                lr_attention_map = attention_maps[-1][:, :lr_subset.shape[1]]  # LR ë¶€ë¶„ë§Œ\n",
        "\n",
        "            # HR featuresë¥¼ LRê³¼ ëŒ€ì‘ë˜ë„ë¡ í¬ê¸° ë§ì¶¤\n",
        "            hr_corresponding_size = min(hr_subset.shape[1], lr_subset.shape[1])\n",
        "            hr_for_selection = hr_subset[:, :hr_corresponding_size]\n",
        "            lr_attention_for_selection = lr_attention_map[:, :hr_corresponding_size]\n",
        "\n",
        "            # Step 3b: ì¤‘ìš”í•œ HR features ì„ íƒ (ë…¼ë¬¸ì˜ í•µì‹¬!)\n",
        "            selected_hr_features, selection_masks, thresholds = self.hr_selectors[i](\n",
        "                lr_attention_for_selection, hr_for_selection\n",
        "            )\n",
        "\n",
        "            # ì„ íƒ í†µê³„ ìˆ˜ì§‘\n",
        "            stats = self.hr_selectors[i].get_selection_statistics(selection_masks)\n",
        "            selection_stats['total_selected'].append(stats['mean_selected'])\n",
        "            selection_stats['selection_ratios'].append(stats['selection_ratio'])\n",
        "\n",
        "            # Step 3c: Hierarchical Self-Attention (Algorithm 1, line 16)\n",
        "            attended_output, new_attention_map = self.hierarchical_attentions[i](\n",
        "                hidden_states, selected_hr_features\n",
        "            )\n",
        "\n",
        "            # Step 3d: Residual connection + Layer normalization\n",
        "            hidden_states = self.fa_layer_norms[i](hidden_states + attended_output)\n",
        "\n",
        "            # Step 3e: FFN + residual connection (Algorithm 1, line 18)\n",
        "            ffn_output = self.fa_ffns[i](hidden_states)\n",
        "            hidden_states = hidden_states + ffn_output\n",
        "\n",
        "            attention_maps.append(new_attention_map)\n",
        "\n",
        "        # ğŸ¥ Step 4: í™˜ì ë ˆë²¨ ë¶„ë¥˜ (Algorithm 1, line 20)\n",
        "        cls_output = hidden_states[:, -1]  # CLS tokenì˜ ìµœì¢… representation\n",
        "        logits = self.classifier(cls_output)  # [B, num_classes]\n",
        "\n",
        "        return logits, attention_maps, selection_stats\n",
        "\n",
        "\n",
        "# ë‚˜ë¨¸ì§€ DynamicFlexAttentionDatasetì€ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "class DynamicFlexAttentionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ğŸ—‚ï¸  FlexAttentionìš© ë™ì  í™˜ì Dataset\n",
        "\n",
        "    íŠ¹ì§•:\n",
        "    - í™˜ìë³„ë¡œ ë‹¤ë¥¸ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ì²˜ë¦¬\n",
        "    - ë©”ê°€íŒ¨ì¹˜ë‹¹ 8ê°œ íŒ¨ì¹˜ë¡œ ê°ì†Œ (ì†ë„ í–¥ìƒ)\n",
        "    - ìºì‹±ìœ¼ë¡œ ë°˜ë³µ ë¡œë”© ë°©ì§€\n",
        "    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patient_data, target_type='t_label',\n",
        "                 patches_per_megapatch=8, cache_dir=None,\n",
        "                 max_megapatches=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patient_data (dict): í™˜ìë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
        "            target_type (str): ë¼ë²¨ íƒ€ì… ('t_label', 'recur_label')\n",
        "            patches_per_megapatch (int): ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ê°œìˆ˜ (8 ì¶”ì²œ)\n",
        "            cache_dir (str): ìºì‹œ ë””ë ‰í† ë¦¬ (ì²˜ë¦¬ëœ features ì €ì¥)\n",
        "            max_megapatches (int): í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜ ìˆ˜ (Noneì´ë©´ ìë™ ê²°ì •)\n",
        "        \"\"\"\n",
        "        self.patient_data = patient_data\n",
        "        self.patient_ids = list(patient_data.keys())\n",
        "        self.target_type = target_type\n",
        "        self.patches_per_megapatch = patches_per_megapatch\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        if cache_dir:\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "        # í™˜ìë³„ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„ì„ ë° ìµœì  max_megapatches ê²°ì •\n",
        "        self._analyze_megapatch_distribution()\n",
        "        if max_megapatches is None:\n",
        "            self.max_megapatches = self._determine_optimal_max_megapatches()\n",
        "        else:\n",
        "            self.max_megapatches = max_megapatches\n",
        "\n",
        "        print(f\"ğŸ“Š Dataset ì´ˆê¸°í™” ì™„ë£Œ:\")\n",
        "        print(f\"   - í™˜ì ìˆ˜: {len(self.patient_ids)}ëª…\")\n",
        "        print(f\"   - ë¼ë²¨ íƒ€ì…: {target_type}\")\n",
        "        print(f\"   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: {patches_per_megapatch}ê°œ\")\n",
        "        print(f\"   - í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜: {self.max_megapatches}ê°œ\")\n",
        "\n",
        "        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ transform\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™” (ì‚¬ì „í›ˆë ¨ ëª¨ë¸ê³¼ ë§ì¶¤)\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def _analyze_megapatch_distribution(self):\n",
        "        \"\"\"í™˜ìë³„ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬ ë¶„ì„\"\"\"\n",
        "        counts = []\n",
        "        for patient_id, info in self.patient_data.items():\n",
        "            counts.append(len(info['images']))\n",
        "\n",
        "        if counts:\n",
        "            print(f\"ğŸ“ˆ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬:\")\n",
        "            print(f\"   - í‰ê· : {np.mean(counts):.1f}ê°œ\")\n",
        "            print(f\"   - ì¤‘ê°„ê°’: {np.median(counts):.1f}ê°œ\")\n",
        "            print(f\"   - 25%/75% ì§€ì : {np.percentile(counts, 25):.1f}/{np.percentile(counts, 75):.1f}ê°œ\")\n",
        "            print(f\"   - ìµœì†Œ/ìµœëŒ€: {min(counts)}/{max(counts)}ê°œ\")\n",
        "\n",
        "        self.megapatch_counts = counts\n",
        "\n",
        "    def _determine_optimal_max_megapatches(self):\n",
        "        \"\"\"ë©”ëª¨ë¦¬ì™€ ì„±ëŠ¥ì„ ê³ ë ¤í•œ ìµœì  max_megapatches ê²°ì •\"\"\"\n",
        "        if not self.megapatch_counts:\n",
        "            return 10  # ê¸°ë³¸ê°’\n",
        "\n",
        "        # 75% percentile ì‚¬ìš© (ëŒ€ë¶€ë¶„ í™˜ìë¥¼ ì»¤ë²„í•˜ë©´ì„œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "        optimal = int(np.percentile(self.megapatch_counts, 75))\n",
        "\n",
        "        # ìµœì†Œ 5ê°œ, ìµœëŒ€ 15ê°œë¡œ ì œí•œ (ë©”ëª¨ë¦¬ ê³ ë ¤)\n",
        "        optimal = max(5, min(optimal, 15))\n",
        "\n",
        "        print(f\"ğŸ¯ ìµœì  max_megapatches ê²°ì •: {optimal}ê°œ (75th percentile ê¸°ì¤€)\")\n",
        "        return optimal\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        í™˜ì ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
        "\n",
        "        Returns:\n",
        "            dict: {\n",
        "                'patient_id': í™˜ì ID,\n",
        "                'lr_patches': [total_lr, 3, 64, 64] - LR íŒ¨ì¹˜ë“¤,\n",
        "                'global_patches': [num_megapatches, 3, 64, 64] - Global íŒ¨ì¹˜ë“¤,\n",
        "                'hr_patches': [total_hr, 3, 256, 256] - HR íŒ¨ì¹˜ë“¤,\n",
        "                'label': ë¼ë²¨,\n",
        "                'num_megapatches': ì‹¤ì œ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜\n",
        "            }\n",
        "        \"\"\"\n",
        "        patient_id = self.patient_ids[idx]\n",
        "        patient_info = self.patient_data[patient_id]\n",
        "\n",
        "        # ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°\n",
        "        label = patient_info.get(self.target_type, 0)\n",
        "        if label is None:\n",
        "            label = 0\n",
        "\n",
        "        # ì´ í™˜ìì˜ ëª¨ë“  ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        megapatch_paths = patient_info['images']\n",
        "\n",
        "        # ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ì¡°ì •\n",
        "        if len(megapatch_paths) > self.max_megapatches:\n",
        "            # ë„ˆë¬´ ë§ìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§\n",
        "            megapatch_paths = random.sample(megapatch_paths, self.max_megapatches)\n",
        "        elif len(megapatch_paths) == 0:\n",
        "            # ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # ê° streamë³„ ë°ì´í„° ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë“¤\n",
        "        all_lr_features = []\n",
        "        all_global_features = []\n",
        "        all_hr_features = []\n",
        "\n",
        "        # ê° ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬\n",
        "        processed_count = 0\n",
        "        for megapatch_path in megapatch_paths:\n",
        "            try:\n",
        "                # ìºì‹± í™•ì¸\n",
        "                if self.cache_dir:\n",
        "                    cache_key = hashlib.md5(\n",
        "                        f\"{megapatch_path}_{self.patches_per_megapatch}\".encode()\n",
        "                    ).hexdigest()\n",
        "                    cache_path = os.path.join(self.cache_dir, f\"{cache_key}.pkl\")\n",
        "\n",
        "                    if os.path.exists(cache_path):\n",
        "                        with open(cache_path, 'rb') as f:\n",
        "                            processed = pickle.load(f)\n",
        "                    else:\n",
        "                        processed = process_megapatch_complete(\n",
        "                            megapatch_path, self.patches_per_megapatch\n",
        "                        )\n",
        "                        with open(cache_path, 'wb') as f:\n",
        "                            pickle.dump(processed, f)\n",
        "                else:\n",
        "                    processed = process_megapatch_complete(\n",
        "                        megapatch_path, self.patches_per_megapatch\n",
        "                    )\n",
        "\n",
        "                # ê° streamë³„ë¡œ tensor ë³€í™˜\n",
        "# ê° streamë³„ë¡œ tensor ë³€í™˜ (í¬ê¸° ì²´í¬ ì¶”ê°€!)\n",
        "                for lr_patch in processed['lr_patches']:\n",
        "                    # í¬ê¸° ì²´í¬ ë° ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ\n",
        "                    if lr_patch.shape[:2] != (64, 64):\n",
        "                        print(f\"âš ï¸ ì˜ëª»ëœ LR í¬ê¸°: {lr_patch.shape}, 64x64ë¡œ ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ\")\n",
        "                        lr_patch = cv2.resize(lr_patch, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                    lr_pil = Image.fromarray(lr_patch)\n",
        "                    lr_tensor = self.transform(lr_pil)\n",
        "                    all_lr_features.append(lr_tensor)\n",
        "\n",
        "                # Global token (ë©”ê°€íŒ¨ì¹˜ë‹¹ 1ê°œ)\n",
        "                global_pil = Image.fromarray(processed['global_tokens'][0])\n",
        "                global_tensor = self.transform(global_pil)\n",
        "                all_global_features.append(global_tensor)\n",
        "\n",
        "                # HR patches (í¬ê¸° ì²´í¬ ì¶”ê°€!)\n",
        "                for hr_patch in processed['hr_patches']:\n",
        "                    # í¬ê¸° ì²´í¬ ë° ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ\n",
        "                    if hr_patch.shape[:2] != (256, 256):\n",
        "                        print(f\"âš ï¸ ì˜ëª»ëœ HR í¬ê¸°: {hr_patch.shape}, 256x256ë¡œ ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ\")\n",
        "                        hr_patch = cv2.resize(hr_patch, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                    hr_pil = Image.fromarray(hr_patch)\n",
        "                    hr_tensor = self.transform(hr_pil)\n",
        "                    all_hr_features.append(hr_tensor)\n",
        "\n",
        "                processed_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ {megapatch_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # ì²˜ë¦¬ëœ ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°\n",
        "        if processed_count == 0:\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # Tensorë¡œ ë³€í™˜\n",
        "        lr_tensor = torch.stack(all_lr_features)      # [total_lr, 3, 64, 64]\n",
        "        global_tensor = torch.stack(all_global_features)  # [num_megapatches, 3, 64, 64]\n",
        "        hr_tensor = torch.stack(all_hr_features)      # [total_hr, 3, 256, 256]\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': lr_tensor,\n",
        "            'global_patches': global_tensor,\n",
        "            'hr_patches': hr_tensor,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': processed_count\n",
        "        }\n",
        "\n",
        "    def _create_dummy_data(self, patient_id, label):\n",
        "        \"\"\"ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ê±°ë‚˜ ì²˜ë¦¬ ì‹¤íŒ¨ì‹œ ë”ë¯¸ ë°ì´í„° ìƒì„±\"\"\"\n",
        "        dummy_lr = torch.zeros(self.patches_per_megapatch, 3, 64, 64)\n",
        "        dummy_global = torch.zeros(1, 3, 64, 64)\n",
        "        dummy_hr = torch.zeros(self.patches_per_megapatch, 3, 256, 256)\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': dummy_lr,\n",
        "            'global_patches': dummy_global,\n",
        "            'hr_patches': dummy_hr,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': 1\n",
        "        }\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 7 ì™„ë£Œ: Feature Dimension í†µì¼ëœ FlexAttention MIL ëª¨ë¸!\")\n",
        "print(\"ëª¨ë“  Feature Extractorê°€ 256 ì°¨ì›ìœ¼ë¡œ í†µì¼ë˜ì–´ í…ì„œ í¬ê¸° ì˜¤ë¥˜ê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NoBsjBOeyKH"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 8: í›ˆë ¨ í•¨ìˆ˜ (ì²´í¬í¬ì¸íŠ¸ ì™„ë²½ ì§€ì›)\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtnGBMXXeyKH"
      },
      "outputs": [],
      "source": [
        "def extract_features_fixed(lr_patches, global_patches, hr_patches, model):\n",
        "    \"\"\"\n",
        "    ğŸ”¬ 3-stream tensorë“¤ì„ feature vectorë“¤ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ìˆ˜ì •ë¨!)\n",
        "\n",
        "    Args:\n",
        "        lr_patches: [batch_size, num_lr, 3, 64, 64] - LR íŒ¨ì¹˜ë“¤\n",
        "        global_patches: [batch_size, num_global, 3, 64, 64] - Global íŒ¨ì¹˜ë“¤\n",
        "        hr_patches: [batch_size, num_hr, 3, 256, 256] - HR íŒ¨ì¹˜ë“¤\n",
        "        model: FlexAttentionPatientMIL ëª¨ë¸ (feature extractors í¬í•¨)\n",
        "\n",
        "    Returns:\n",
        "        lr_features: [batch_size, num_lr, feature_dim] - LR feature vectors\n",
        "        global_features: [batch_size, num_global, feature_dim] - Global feature vectors\n",
        "        hr_features: [batch_size, num_hr, feature_dim] - HR feature vectors\n",
        "    \"\"\"\n",
        "    batch_size = lr_patches.shape[0]\n",
        "\n",
        "    # 1. LR features ì¶”ì¶œ\n",
        "    num_lr = lr_patches.shape[1]\n",
        "    lr_flat = lr_patches.view(-1, 3, 64, 64)  # [B*N, 3, 64, 64]\n",
        "\n",
        "    lr_features_flat = model.lr_extractor(lr_flat)  # [B*N, feature_dim] â† with torch.no_grad() ì œê±°!\n",
        "    lr_features = lr_features_flat.view(batch_size, num_lr, -1)  # [B, N, feature_dim]\n",
        "\n",
        "    # 2. Global features ì¶”ì¶œ\n",
        "    num_global = global_patches.shape[1]\n",
        "    global_flat = global_patches.view(-1, 3, 64, 64)  # [B*M, 3, 64, 64]\n",
        "\n",
        "    global_features_flat = model.global_extractor(global_flat)  # [B*M, feature_dim] â† with torch.no_grad() ì œê±°!\n",
        "    global_features = global_features_flat.view(batch_size, num_global, -1)  # [B, M, feature_dim]\n",
        "\n",
        "    # 3. HR features ì¶”ì¶œ\n",
        "    num_hr = hr_patches.shape[1]\n",
        "    hr_flat = hr_patches.view(-1, 3, 256, 256)  # [B*K, 3, 256, 256]\n",
        "\n",
        "    hr_features_flat = model.hr_extractor(hr_flat)  # [B*K, feature_dim] â† with torch.no_grad() ì œê±°!\n",
        "    hr_features = hr_features_flat.view(batch_size, num_hr, -1)  # [B, K, feature_dim]\n",
        "\n",
        "    return lr_features, global_features, hr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uwsgttEeyKH",
        "outputId": "6c253162-e465-43d9-ff45-2bb86958b1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Part 8 F1 ë¬¸ì œ í•´ê²° ì™„ë£Œ!\n",
            "ì£¼ìš” ë³€ê²½ì‚¬í•­: ì ì‘í˜• ì„ê³„ê°’ 0.3, F1_macro ì‚¬ìš©, ìë™ ìµœì  ì„ê³„ê°’ íƒìƒ‰\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# ì™„ì „íˆ ìˆ˜ì •ëœ Part 8: FlexAttention í›ˆë ¨ í•¨ìˆ˜ (ì‹¤í—˜ìš©)\n",
        "# ========================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "\n",
        "def train_flexattention_model_with_checkpoints(\n",
        "    patient_data,\n",
        "    target_type='t_label',\n",
        "    num_folds=5,\n",
        "    num_epochs=15,\n",
        "    batch_size=1,\n",
        "    accumulation_steps=4,\n",
        "    learning_rate=1e-4,\n",
        "    extractor_type='resnet18',\n",
        "    device=device,\n",
        "    work_dir=work_dir,\n",
        "    resume_from_checkpoint=True,\n",
        "    loss_type='weighted_cross_entropy',  # ìƒˆë¡œ ì¶”ê°€\n",
        "    feature_dim=512,                     # ìƒˆë¡œ ì¶”ê°€\n",
        "    num_heads=8,                         # ìƒˆë¡œ ì¶”ê°€\n",
        "    patches_per_megapatch=16,            # ìƒˆë¡œ ì¶”ê°€\n",
        "    max_megapatches=10                   # ìƒˆë¡œ ì¶”ê°€\n",
        "):\n",
        "    \"\"\"\n",
        "    ğŸš€ ì‹¤í—˜ìš© FlexAttention MIL í›ˆë ¨ í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"ğŸš€ FlexAttention MIL í›ˆë ¨ ì‹œì‘!\")\n",
        "    print(f\"   Target: {target_type}\")\n",
        "    print(f\"   Folds: {num_folds}, Epochs: {num_epochs}\")\n",
        "    print(f\"   Batch size: {batch_size} Ã— {accumulation_steps} = {batch_size * accumulation_steps}\")\n",
        "    print(f\"   Learning rate: {learning_rate}\")\n",
        "    print(f\"   Feature dim: {feature_dim}, Heads: {num_heads}\")\n",
        "    print(f\"   Loss type: {loss_type}\")\n",
        "    print(f\"   Patches per megapatch: {patches_per_megapatch}\")\n",
        "    print(f\"   Max megapatches: {max_megapatches}\")\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "    target_dir = os.path.join(work_dir, f\"results_{target_type}\")\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
        "    checkpoint_manager = CheckpointManager(\n",
        "        checkpoint_dir=os.path.join(target_dir, \"checkpoints\"),\n",
        "        max_keep=3\n",
        "    )\n",
        "\n",
        "    # í™˜ì ë°ì´í„° ì¤€ë¹„\n",
        "    patient_ids = list(patient_data.keys())\n",
        "    patient_labels = [patient_data[pid].get(target_type, 0) for pid in patient_ids]\n",
        "    patient_labels = [0 if label is None else label for label in patient_labels]\n",
        "\n",
        "    print(f\"\\nğŸ‘¥ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:\")\n",
        "    print(f\"   ì´ í™˜ì ìˆ˜: {len(patient_ids)}ëª…\")\n",
        "    print(f\"   ë¼ë²¨ ë¶„í¬: {dict(zip(*np.unique(patient_labels, return_counts=True)))}\")\n",
        "\n",
        "    # Stratified K-Fold ì„¤ì •\n",
        "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # ì „ì²´ ê²°ê³¼ ì €ì¥\n",
        "    all_results = {\n",
        "        'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'auc': [],\n",
        "        'fold_details': []\n",
        "    }\n",
        "\n",
        "    # ê° fold ë³„ í›ˆë ¨\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(patient_ids, patient_labels)):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"ğŸ”„ Fold {fold+1}/{num_folds} ì‹œì‘\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # ë°ì´í„° ë¶„í• \n",
        "        train_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in train_idx}\n",
        "        test_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in test_idx}\n",
        "\n",
        "        print(f\"   í›ˆë ¨ í™˜ì: {len(train_patients)}ëª…\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ í™˜ì: {len(test_patients)}ëª…\")\n",
        "\n",
        "        # Dataset ìƒì„± (ì‹¤í—˜ ì„¤ì • ì ìš©)\n",
        "        train_dataset = DynamicFlexAttentionDataset(\n",
        "            train_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=patches_per_megapatch,  # íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
        "            cache_dir=None,                               # ìºì‹œ ë¹„í™œì„±í™”\n",
        "            max_megapatches=max_megapatches               # íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
        "        )\n",
        "\n",
        "        test_dataset = DynamicFlexAttentionDataset(\n",
        "            test_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=patches_per_megapatch,  # íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
        "            cache_dir=None,                               # ìºì‹œ ë¹„í™œì„±í™”\n",
        "            max_megapatches=max_megapatches               # íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
        "        )\n",
        "\n",
        "        # DataLoader ìƒì„±\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=False,\n",
        "            drop_last=False\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            pin_memory=False,\n",
        "        )\n",
        "\n",
        "        print(f\"   í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")\n",
        "\n",
        "        # ëª¨ë¸ ì´ˆê¸°í™” (ì‹¤í—˜ ì„¤ì • ì ìš©)\n",
        "        model = FlexAttentionPatientMIL(\n",
        "            feature_dim=feature_dim,     # íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
        "            num_classes=2,\n",
        "            num_heads=num_heads,         # íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
        "            num_sa_layers=2,\n",
        "            num_fa_layers=2,\n",
        "            dropout=0.1,\n",
        "            extractor_type=extractor_type\n",
        "        )\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
        "        optimizer = AdamW(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—†ìŒ (ê°„ë‹¨í•˜ê²Œ)\n",
        "        scheduler = None\n",
        "\n",
        "        # Loss function ì„ íƒ (ì‹¤í—˜ ì„¤ì • ì ìš©)\n",
        "        if loss_type == 'weighted_cross_entropy':\n",
        "            # Class Weight ê³„ì‚°\n",
        "            class_counts = Counter(patient_labels)\n",
        "            total = len(patient_labels)\n",
        "            weight_0 = total / (2 * class_counts[0])  # ë‹¤ìˆ˜ í´ë˜ìŠ¤ëŠ” ë‚®ì€ ê°€ì¤‘ì¹˜\n",
        "            weight_1 = total / (2 * class_counts[1])  # ì†Œìˆ˜ í´ë˜ìŠ¤ëŠ” ë†’ì€ ê°€ì¤‘ì¹˜\n",
        "            class_weights = torch.tensor([weight_0, weight_1]).to(device)\n",
        "            print(f\"ğŸ·ï¸ Class weights: {class_weights}\")\n",
        "            criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "        else:\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        scaler = GradScaler()\n",
        "\n",
        "        print(f\"âœ… ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "\n",
        "        # í›ˆë ¨ ë£¨í”„\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nğŸ”„ Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            # í›ˆë ¨ ë‹¨ê³„\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            num_batches = 0\n",
        "\n",
        "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"í›ˆë ¨ ì§„í–‰\")):\n",
        "                try:\n",
        "                    # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™\n",
        "                    lr_patches = batch['lr_patches'].to(device)\n",
        "                    global_patches = batch['global_patches'].to(device)\n",
        "                    hr_patches = batch['hr_patches'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "\n",
        "                    with autocast():\n",
        "                        # Feature extraction\n",
        "                        lr_features, global_features, hr_features = extract_features_fixed(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        # Forward pass\n",
        "                        logits, attention_maps, selection_stats = model(\n",
        "                            lr_features, global_features, hr_features\n",
        "                        )\n",
        "\n",
        "                        # Loss ê³„ì‚°\n",
        "                        loss = criterion(logits, labels) / accumulation_steps\n",
        "\n",
        "                    # Backward pass\n",
        "                    scaler.scale(loss).backward()\n",
        "\n",
        "                    # Gradient accumulation\n",
        "                    if (batch_idx + 1) % accumulation_steps == 0:\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                    total_loss += loss.item() * accumulation_steps\n",
        "                    num_batches += 1\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(f\"ğŸ’¥ OOM ë°œìƒ! ë°°ì¹˜ {batch_idx} ìŠ¤í‚µ\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        continue\n",
        "                    else:\n",
        "                        print(f\"âŒ í›ˆë ¨ ì˜¤ë¥˜: {e}\")\n",
        "                        break\n",
        "\n",
        "            avg_loss = total_loss / max(num_batches, 1)\n",
        "            print(f\"   í‰ê·  Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # ğŸ”§ ê°œì„ ëœ ê²€ì¦ ë‹¨ê³„\n",
        "            model.eval()\n",
        "            test_preds = []\n",
        "            test_labels = []\n",
        "            test_probs = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in test_loader:\n",
        "                    try:\n",
        "                        lr_patches = batch['lr_patches'].to(device)\n",
        "                        global_patches = batch['global_patches'].to(device)\n",
        "                        hr_patches = batch['hr_patches'].to(device)\n",
        "                        labels = batch['label'].to(device)\n",
        "\n",
        "                        lr_features, global_features, hr_features = extract_features_fixed(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        logits, _, _ = model(lr_features, global_features, hr_features)\n",
        "\n",
        "                        # í™•ë¥  ê³„ì‚°\n",
        "                        probs = torch.softmax(logits, dim=1)\n",
        "                        class_1_probs = probs[:, 1]  # í´ë˜ìŠ¤ 1 í™•ë¥ \n",
        "\n",
        "                        # ì„ì‹œ ì˜ˆì¸¡ (ë‚˜ì¤‘ì— ìµœì  ì„ê³„ê°’ìœ¼ë¡œ ì¬ê³„ì‚°)\n",
        "                        preds = (class_1_probs >= 0.3).long()\n",
        "\n",
        "                        test_preds.extend(preds.cpu().tolist())\n",
        "                        test_labels.extend(labels.cpu().tolist())\n",
        "                        test_probs.extend(class_1_probs.cpu().tolist())\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"âš ï¸ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "                        continue\n",
        "\n",
        "            # ğŸ” ê°œì„ ëœ ë””ë²„ê¹… ë° ìµœì í™”\n",
        "            if test_labels and test_preds:\n",
        "                print(f\"\\nğŸ” ë””ë²„ê¹…:\")\n",
        "                print(f\"   ì˜ˆì¸¡ë¶„í¬: {Counter(test_preds)}\")\n",
        "                print(f\"   ì‹¤ì œë¶„í¬: {Counter(test_labels)}\")\n",
        "\n",
        "                if test_probs:\n",
        "                    print(f\"   í´ë˜ìŠ¤1 í™•ë¥ ë²”ìœ„: {min(test_probs):.3f}~{max(test_probs):.3f}\")\n",
        "\n",
        "                    # ğŸ¯ ê· í˜•ì¡íŒ ì„±ëŠ¥ì„ ìœ„í•œ ë‹¤ì¤‘ ì§€í‘œ ìµœì í™”\n",
        "                    best_combined_score = 0\n",
        "                    best_threshold = 0.3\n",
        "                    best_metrics = {}\n",
        "\n",
        "                    print(f\"\\nğŸ“Š ì„ê³„ê°’ë³„ ìƒì„¸ ë¶„ì„:\")\n",
        "                    for thresh in [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
        "                        thresh_preds = [1 if p >= thresh else 0 for p in test_probs]\n",
        "\n",
        "                        # ë‹¤ì–‘í•œ ì§€í‘œ ê³„ì‚°\n",
        "                        thresh_acc = accuracy_score(test_labels, thresh_preds)\n",
        "                        thresh_f1 = f1_score(test_labels, thresh_preds, zero_division=0)\n",
        "                        thresh_f1_macro = f1_score(test_labels, thresh_preds, average='macro', zero_division=0)\n",
        "\n",
        "                        # ğŸ¯ ê· í˜•ì¡íŒ ì ìˆ˜ = (Accuracy + F1_macro) / 2\n",
        "                        combined_score = (thresh_acc + thresh_f1_macro) / 2\n",
        "\n",
        "                        pred_dist = Counter(thresh_preds)\n",
        "\n",
        "                        print(f\"   ì„ê³„ê°’ {thresh}: Acc={thresh_acc:.3f}, F1={thresh_f1:.3f}, F1_macro={thresh_f1_macro:.3f}, í†µí•©={combined_score:.3f}, ë¶„í¬={dict(pred_dist)}\")\n",
        "\n",
        "                        # ğŸ† ìµœê³  í†µí•© ì ìˆ˜ ì°¾ê¸°\n",
        "                        if combined_score > best_combined_score:\n",
        "                            best_combined_score = combined_score\n",
        "                            best_threshold = thresh\n",
        "                            best_metrics = {\n",
        "                                'accuracy': thresh_acc,\n",
        "                                'f1': thresh_f1,\n",
        "                                'f1_macro': thresh_f1_macro,\n",
        "                                'combined': combined_score\n",
        "                            }\n",
        "\n",
        "                    print(f\"   ğŸ¯ ìµœì ì„ê³„ê°’: {best_threshold} (í†µí•©ì ìˆ˜={best_combined_score:.3f})\")\n",
        "                    print(f\"      â†’ Acc={best_metrics['accuracy']:.3f}, F1={best_metrics['f1']:.3f}, F1_macro={best_metrics['f1_macro']:.3f}\")\n",
        "\n",
        "                    # ğŸ”§ ìµœì  ì„ê³„ê°’ìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡ ì¬ê³„ì‚°\n",
        "                    test_preds = [1 if p >= best_threshold else 0 for p in test_probs]\n",
        "\n",
        "                    # ìµœì¢… ì„±ëŠ¥ ì§€í‘œ\n",
        "                    accuracy = best_metrics['accuracy']\n",
        "                    f1 = best_metrics['f1']\n",
        "                    f1_macro = best_metrics['f1_macro']\n",
        "\n",
        "                else:\n",
        "                    # í™•ë¥ ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ê³„ì‚°\n",
        "                    accuracy = accuracy_score(test_labels, test_preds)\n",
        "                    f1 = f1_score(test_labels, test_preds, zero_division=0)\n",
        "                    f1_macro = f1_score(test_labels, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "                print(f\"   ìµœì¢…ê²€ì¦ê²°ê³¼: Acc={accuracy:.3f}, F1={f1:.3f}, F1_macro={f1_macro:.3f}\")\n",
        "\n",
        "                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (F1_macro ê¸°ì¤€)\n",
        "                checkpoint_manager.save_checkpoint(\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    scheduler=scheduler,\n",
        "                    epoch=epoch,\n",
        "                    fold=fold + 1,\n",
        "                    train_loss=avg_loss,\n",
        "                    val_metrics={'accuracy': accuracy, 'f1': f1_macro},\n",
        "                    is_best=(f1_macro > checkpoint_manager.best_score)\n",
        "                )\n",
        "\n",
        "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Fold ì™„ë£Œ í›„ ê²°ê³¼ ì €ì¥\n",
        "        if test_labels and test_preds:\n",
        "            fold_accuracy = accuracy_score(test_labels, test_preds)\n",
        "            fold_f1 = f1_score(test_labels, test_preds, average='macro', zero_division=0)\n",
        "\n",
        "            all_results['accuracy'].append(fold_accuracy)\n",
        "            all_results['f1'].append(fold_f1)\n",
        "\n",
        "            print(f\"âœ… Fold {fold+1} ì™„ë£Œ: Acc={fold_accuracy:.3f}, F1={fold_f1:.3f}\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # ìµœì¢… ê²°ê³¼\n",
        "    if all_results['accuracy']:\n",
        "        avg_acc = np.mean(all_results['accuracy'])\n",
        "        avg_f1 = np.mean(all_results['f1'])\n",
        "\n",
        "        print(f\"\\nğŸ‰ ìµœì¢… ê²°ê³¼ ({target_type}):\")\n",
        "        print(f\"   í‰ê·  Accuracy: {avg_acc:.3f}\")\n",
        "        print(f\"   í‰ê·  F1-Score: {avg_f1:.3f}\")\n",
        "\n",
        "        return {\n",
        "            'target_type': target_type,\n",
        "            'name': f'{loss_type}_dim{feature_dim}_heads{num_heads}',\n",
        "            'avg_accuracy': avg_acc,\n",
        "            'avg_f1': avg_f1,\n",
        "            'accuracy': all_results['accuracy'],\n",
        "            'f1': all_results['f1'],\n",
        "            'feature_dim': feature_dim,\n",
        "            'num_heads': num_heads,\n",
        "            'loss_type': loss_type\n",
        "        }\n",
        "    else:\n",
        "        print(f\"âŒ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 8 F1 ë¬¸ì œ ì™„ì „ í•´ê²° ì™„ë£Œ!\")\n",
        "print(\"ì£¼ìš” ë³€ê²½ì‚¬í•­: ìë™ ìµœì  ì„ê³„ê°’ íƒìƒ‰, ê· í˜•ì¡íŒ ì„±ëŠ¥ ìµœì í™”\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzESo_MdeyKI"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 9: ì‹¤ì œ í›ˆë ¨ ì‹¤í–‰\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ì•„í™‰ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRoMueLneyKI",
        "outputId": "0d7f04a5-1be6-4be7-a0cf-efb92e3a782f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ FlexAttention MIL í›ˆë ¨ ì¤€ë¹„ ì™„ë£Œ!\n",
            "================================================================================\n",
            "ğŸ’¾ ë°ì´í„°: 100ëª…ì˜ í™˜ì\n",
            "ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: cuda\n",
            "ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\n",
            "â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 1-2ì¼ (ìµœì í™”ëœ ì„¤ì •)\n",
            "================================================================================\n",
            "ğŸ–¥ï¸  GPU ë©”ëª¨ë¦¬ [í›ˆë ¨ ì‹œì‘ ì „]: í• ë‹¹=0.69GB, ìºì‹œ=6.35GB\n",
            "\n",
            "âš™ï¸  í›ˆë ¨ ì„¤ì •:\n",
            "   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: 8ê°œ (16â†’8, 50% ì ˆì•½)\n",
            "   - Feature dimension: 256 (384â†’256, 33% ì ˆì•½)\n",
            "   - Attention heads: 4ê°œ (6â†’4, 33% ì ˆì•½)\n",
            "   - FlexAttention layers: 1ê°œ (2â†’1, 50% ì ˆì•½)\n",
            "   - ë°°ì¹˜ í¬ê¸°: 1 (ë¬¼ë¦¬ì ) Ã— 4 (ëˆ„ì ) = 4 (íš¨ê³¼ì )\n",
            "   - Feature extractor: ResNet18 (ì•ˆì •ì„± ìš°ì„ )\n",
            "\n",
            "â“ ì„¤ì •ì´ ë§ë‹¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”!\n",
            "   T-stage ë¶„ë¥˜ì™€ ì¬ë°œ ì˜ˆì¸¡ì„ ìˆœì°¨ì ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
            "   ê° foldë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ê°€ ìë™ ì €ì¥ë©ë‹ˆë‹¤.\n",
            "\n",
            "ğŸ“‹ í›ˆë ¨ íŒŒë¼ë¯¸í„°:\n",
            "   num_folds: 5\n",
            "   num_epochs: 15\n",
            "   batch_size: 1\n",
            "   accumulation_steps: 4\n",
            "   learning_rate: 0.0001\n",
            "   extractor_type: resnet18\n",
            "   resume_from_checkpoint: True\n",
            "   loss_type: weighted_cross_entropy\n",
            "   feature_dim: 512\n",
            "   num_heads: 8\n",
            "   patches_per_megapatch: 16\n",
            "   max_megapatches: 10\n",
            "\n",
            "âœ… í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: 100ëª…\n",
            "ğŸ“Š ë¼ë²¨ ë¶„í¬:\n",
            "   T-stage: {np.int64(0): np.int64(64), np.int64(1): np.int64(36)}\n",
            "   ì¬ë°œ: {np.int64(0): np.int64(31), np.int64(1): np.int64(69)}\n",
            "\n",
            "================================================================================\n",
            "Part 9 ì™„ë£Œ: í›ˆë ¨ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\n",
            "ë‹¤ìŒ ì…€ì—ì„œ ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# í›ˆë ¨ ì „ ìµœì¢… í™•ì¸ ë° ì„¤ì •\n",
        "print(\"ğŸš€ FlexAttention MIL í›ˆë ¨ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"ğŸ’¾ ë°ì´í„°: {len(patient_data) if 'patient_data' in locals() else 0}ëª…ì˜ í™˜ì\")\n",
        "print(f\"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}\")\n",
        "print(f\"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {work_dir}\")\n",
        "print(f\"â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 1-2ì¼ (ìµœì í™”ëœ ì„¤ì •)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"í›ˆë ¨ ì‹œì‘ ì „\")\n",
        "\n",
        "# í›ˆë ¨ ì„¤ì • í™•ì¸\n",
        "print(\"\\nâš™ï¸  í›ˆë ¨ ì„¤ì •:\")\n",
        "print(\"   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: 8ê°œ (16â†’8, 50% ì ˆì•½)\")\n",
        "print(\"   - Feature dimension: 256 (384â†’256, 33% ì ˆì•½)\")\n",
        "print(\"   - Attention heads: 4ê°œ (6â†’4, 33% ì ˆì•½)\")\n",
        "print(\"   - FlexAttention layers: 1ê°œ (2â†’1, 50% ì ˆì•½)\")\n",
        "print(\"   - ë°°ì¹˜ í¬ê¸°: 1 (ë¬¼ë¦¬ì ) Ã— 4 (ëˆ„ì ) = 4 (íš¨ê³¼ì )\")\n",
        "print(\"   - Feature extractor: ResNet18 (ì•ˆì •ì„± ìš°ì„ )\")\n",
        "\n",
        "# ì‚¬ìš©ì í™•ì¸\n",
        "print(f\"\\nâ“ ì„¤ì •ì´ ë§ë‹¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
        "print(f\"   T-stage ë¶„ë¥˜ì™€ ì¬ë°œ ì˜ˆì¸¡ì„ ìˆœì°¨ì ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.\")\n",
        "print(f\"   ê° foldë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ê°€ ìë™ ì €ì¥ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "# í›ˆë ¨ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "TRAINING_CONFIG = {\n",
        "    'num_folds': 5,\n",
        "    'num_epochs': 15,           # 20â†’15 (ì‹œê°„ ì ˆì•½)\n",
        "    'batch_size': 1,\n",
        "    'accumulation_steps': 4,\n",
        "    'learning_rate': 1e-4,\n",
        "    'extractor_type': 'resnet18',\n",
        "    'resume_from_checkpoint': True,\n",
        "    'loss_type': 'weighted_cross_entropy',  # â† ìƒˆë¡œ ì¶”ê°€\n",
        "    'feature_dim': 512,         # â† ìƒˆë¡œ ì¶”ê°€\n",
        "    'num_heads': 8,             # â† ìƒˆë¡œ ì¶”ê°€\n",
        "    'patches_per_megapatch': 16, # â† ìƒˆë¡œ ì¶”ê°€\n",
        "    'max_megapatches': 10       # â† ìƒˆë¡œ ì¶”ê°€\n",
        "}\n",
        "\n",
        "print(f\"\\nğŸ“‹ í›ˆë ¨ íŒŒë¼ë¯¸í„°:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# ë°ì´í„° ì¡´ì¬ í™•ì¸\n",
        "if 'patient_data' not in locals() or not patient_data:\n",
        "    print(f\"\\nâŒ í™˜ì ë°ì´í„°ê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"   Part 5ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    print(f\"\\nâœ… í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(patient_data)}ëª…\")\n",
        "\n",
        "    # ë¼ë²¨ ë¶„í¬ ì¬í™•ì¸\n",
        "    t_labels = [info.get('t_label', 0) for info in patient_data.values()]\n",
        "    recur_labels = [info.get('recur_label', 0) for info in patient_data.values()]\n",
        "\n",
        "    print(f\"ğŸ“Š ë¼ë²¨ ë¶„í¬:\")\n",
        "    print(f\"   T-stage: {dict(zip(*np.unique(t_labels, return_counts=True)))}\")\n",
        "    print(f\"   ì¬ë°œ: {dict(zip(*np.unique(recur_labels, return_counts=True)))}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 9 ì™„ë£Œ: í›ˆë ¨ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒ ì…€ì—ì„œ ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRl_0gbMeyKI"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 10: T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxv9KZuReyKI",
        "outputId": "4582eeca-88bf-4f45-f5fd-ad1a1f7f1332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘!\n",
            "============================================================\n",
            "ğŸ“‹ T-stage ë¶„ë¥˜:\n",
            "   - í´ë˜ìŠ¤ 0: Ta, T1 (ì €ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ì—†ìŒ)\n",
            "   - í´ë˜ìŠ¤ 1: T2+ (ê³ ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ìˆìŒ)\n",
            "   - ì„ìƒì  ì¤‘ìš”ì„±: ì¹˜ë£Œ ê³„íš ë° ì˜ˆí›„ ì˜ˆì¸¡ì— í•µì‹¬\n",
            "============================================================\n",
            "ğŸ•’ í›ˆë ¨ ì‹œì‘ ì‹œê°„: 2025-05-31 17:14:28\n",
            "ğŸ–¥ï¸  GPU ë©”ëª¨ë¦¬ [T-stage í›ˆë ¨ ì‹œì‘]: í• ë‹¹=0.69GB, ìºì‹œ=6.35GB\n",
            "\n",
            "ğŸš€ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘...\n",
            "ğŸš€ FlexAttention MIL í›ˆë ¨ ì‹œì‘!\n",
            "   Target: t_label\n",
            "   Folds: 5, Epochs: 15\n",
            "   Batch size: 1 Ã— 4 = 4\n",
            "   Learning rate: 0.0001\n",
            "   Feature dim: 512, Heads: 8\n",
            "   Loss type: weighted_cross_entropy\n",
            "   Patches per megapatch: 16\n",
            "   Max megapatches: 10\n",
            "ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”: C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\\results_t_label\\checkpoints\n",
            "\n",
            "ğŸ‘¥ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:\n",
            "   ì´ í™˜ì ìˆ˜: 100ëª…\n",
            "   ë¼ë²¨ ë¶„í¬: {np.int64(0): np.int64(64), np.int64(1): np.int64(36)}\n",
            "\n",
            "================================================================================\n",
            "ğŸ”„ Fold 1/5 ì‹œì‘\n",
            "================================================================================\n",
            "   í›ˆë ¨ í™˜ì: 80ëª…\n",
            "   í…ŒìŠ¤íŠ¸ í™˜ì: 20ëª…\n",
            "ğŸ“ˆ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬:\n",
            "   - í‰ê· : 43.8ê°œ\n",
            "   - ì¤‘ê°„ê°’: 35.5ê°œ\n",
            "   - 25%/75% ì§€ì : 17.8/55.8ê°œ\n",
            "   - ìµœì†Œ/ìµœëŒ€: 5/162ê°œ\n",
            "ğŸ“Š Dataset ì´ˆê¸°í™” ì™„ë£Œ:\n",
            "   - í™˜ì ìˆ˜: 80ëª…\n",
            "   - ë¼ë²¨ íƒ€ì…: t_label\n",
            "   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: 16ê°œ\n",
            "   - í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜: 10ê°œ\n",
            "ğŸ“ˆ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬:\n",
            "   - í‰ê· : 44.1ê°œ\n",
            "   - ì¤‘ê°„ê°’: 41.5ê°œ\n",
            "   - 25%/75% ì§€ì : 24.5/61.2ê°œ\n",
            "   - ìµœì†Œ/ìµœëŒ€: 15/108ê°œ\n",
            "ğŸ“Š Dataset ì´ˆê¸°í™” ì™„ë£Œ:\n",
            "   - í™˜ì ìˆ˜: 20ëª…\n",
            "   - ë¼ë²¨ íƒ€ì…: t_label\n",
            "   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: 16ê°œ\n",
            "   - í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜: 10ê°œ\n",
            "   í›ˆë ¨ ë°°ì¹˜ ìˆ˜: 80\n",
            "   í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: 20\n",
            "ğŸ—ï¸  FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\n",
            "   - Feature dim: 512\n",
            "   - Attention heads: 8\n",
            "   - SA layers: 2, FA layers: 2\n",
            "   - Extractor: resnet18\n",
            "âœ… RESNET18 Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ\n",
            "   - ë°±ë³¸ ì¶œë ¥ ì°¨ì›: 512\n",
            "   - ìµœì¢… feature ì°¨ì›: 512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ehdwk\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ehdwk\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RESNET18 Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ\n",
            "   - ë°±ë³¸ ì¶œë ¥ ì°¨ì›: 512\n",
            "   - ìµœì¢… feature ì°¨ì›: 512\n",
            "âœ… RESNET18 Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ\n",
            "   - ë°±ë³¸ ì¶œë ¥ ì°¨ì›: 512\n",
            "   - ìµœì¢… feature ì°¨ì›: 512\n",
            "âœ… Threshold ê¸°ë°˜ HR Selector ì´ˆê¸°í™”\n",
            "   - ëª©í‘œ ì„ íƒ ë¹„ìœ¨: 10.0%\n",
            "   - ì„ íƒ ë²”ìœ„: 1~4ê°œ\n",
            "âœ… Threshold ê¸°ë°˜ HR Selector ì´ˆê¸°í™”\n",
            "   - ëª©í‘œ ì„ íƒ ë¹„ìœ¨: 10.0%\n",
            "   - ì„ íƒ ë²”ìœ„: 1~4ê°œ\n",
            "âœ… Hierarchical Self-Attention ì´ˆê¸°í™”\n",
            "   - Feature dim: 512, Heads: 8, Head dim: 64\n",
            "âœ… Hierarchical Self-Attention ì´ˆê¸°í™”\n",
            "   - Feature dim: 512, Heads: 8, Head dim: 64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:168: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\n",
            "ğŸ·ï¸ Class weights: tensor([0.7812, 1.3889], device='cuda:0')\n",
            "âœ… ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” ì™„ë£Œ\n",
            "\n",
            "ğŸ”„ Fold 1, Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í›ˆë ¨ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\579158761.py:234: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
            "  'std_selected': num_selected_per_sample.float().std().item()\n",
            "í›ˆë ¨ ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:38<00:00,  1.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   í‰ê·  Loss: 0.7147\n",
            "\n",
            "ğŸ” ë””ë²„ê¹…:\n",
            "   ì˜ˆì¸¡ë¶„í¬: Counter({0: 20})\n",
            "   ì‹¤ì œë¶„í¬: Counter({0: 12, 1: 8})\n",
            "   í´ë˜ìŠ¤1 í™•ë¥ ë²”ìœ„: 0.294~0.297\n",
            "   ìµœì ì„ê³„ê°’: 0.1 (F1=0.571)\n",
            "   ê²€ì¦ê²°ê³¼: Acc=0.400, F1=0.571, F1_macro=0.286\n",
            "ğŸ† ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥! F1: 0.2857\n",
            "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold 1, Epoch 0, Loss: 0.7147\n",
            "ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: checkpoint_fold1_epoch011_20250531_165731.pt\n",
            "\n",
            "ğŸ”„ Fold 1, Epoch 2/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í›ˆë ¨ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\579158761.py:234: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
            "  'std_selected': num_selected_per_sample.float().std().item()\n",
            "í›ˆë ¨ ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:12<00:00,  1.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   í‰ê·  Loss: 0.6622\n",
            "\n",
            "ğŸ” ë””ë²„ê¹…:\n",
            "   ì˜ˆì¸¡ë¶„í¬: Counter({1: 20})\n",
            "   ì‹¤ì œë¶„í¬: Counter({0: 12, 1: 8})\n",
            "   í´ë˜ìŠ¤1 í™•ë¥ ë²”ìœ„: 0.327~0.329\n",
            "   ìµœì ì„ê³„ê°’: 0.1 (F1=0.571)\n",
            "   ê²€ì¦ê²°ê³¼: Acc=0.400, F1=0.571, F1_macro=0.286\n",
            "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold 1, Epoch 1, Loss: 0.6622\n",
            "ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: checkpoint_fold1_epoch012_20250531_165905.pt\n",
            "\n",
            "ğŸ”„ Fold 1, Epoch 3/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í›ˆë ¨ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\579158761.py:234: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
            "  'std_selected': num_selected_per_sample.float().std().item()\n",
            "í›ˆë ¨ ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:12<00:00,  1.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   í‰ê·  Loss: 0.6460\n",
            "\n",
            "ğŸ” ë””ë²„ê¹…:\n",
            "   ì˜ˆì¸¡ë¶„í¬: Counter({1: 20})\n",
            "   ì‹¤ì œë¶„í¬: Counter({0: 12, 1: 8})\n",
            "   í´ë˜ìŠ¤1 í™•ë¥ ë²”ìœ„: 0.356~0.358\n",
            "   ìµœì ì„ê³„ê°’: 0.1 (F1=0.571)\n",
            "   ê²€ì¦ê²°ê³¼: Acc=0.400, F1=0.571, F1_macro=0.286\n",
            "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold 1, Epoch 2, Loss: 0.6460\n",
            "ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: checkpoint_fold1_epoch013_20250531_170037.pt\n",
            "\n",
            "ğŸ”„ Fold 1, Epoch 4/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í›ˆë ¨ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\579158761.py:234: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
            "  'std_selected': num_selected_per_sample.float().std().item()\n",
            "í›ˆë ¨ ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:12<00:00,  1.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   í‰ê·  Loss: 0.6906\n",
            "\n",
            "ğŸ” ë””ë²„ê¹…:\n",
            "   ì˜ˆì¸¡ë¶„í¬: Counter({1: 20})\n",
            "   ì‹¤ì œë¶„í¬: Counter({0: 12, 1: 8})\n",
            "   í´ë˜ìŠ¤1 í™•ë¥ ë²”ìœ„: 0.334~0.336\n",
            "   ìµœì ì„ê³„ê°’: 0.1 (F1=0.571)\n",
            "   ê²€ì¦ê²°ê³¼: Acc=0.400, F1=0.571, F1_macro=0.286\n",
            "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold 1, Epoch 3, Loss: 0.6906\n",
            "ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: checkpoint_fold1_epoch000_20250531_171631.pt\n",
            "\n",
            "ğŸ”„ Fold 1, Epoch 5/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í›ˆë ¨ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\579158761.py:234: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
            "  'std_selected': num_selected_per_sample.float().std().item()\n",
            "í›ˆë ¨ ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:21<00:00,  1.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   í‰ê·  Loss: 0.6834\n",
            "\n",
            "ğŸ” ë””ë²„ê¹…:\n",
            "   ì˜ˆì¸¡ë¶„í¬: Counter({0: 20})\n",
            "   ì‹¤ì œë¶„í¬: Counter({0: 12, 1: 8})\n",
            "   í´ë˜ìŠ¤1 í™•ë¥ ë²”ìœ„: 0.293~0.295\n",
            "   ìµœì ì„ê³„ê°’: 0.1 (F1=0.571)\n",
            "   ê²€ì¦ê²°ê³¼: Acc=0.400, F1=0.571, F1_macro=0.286\n",
            "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold 1, Epoch 4, Loss: 0.6834\n",
            "ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: checkpoint_fold1_epoch001_20250531_171807.pt\n",
            "\n",
            "ğŸ”„ Fold 1, Epoch 6/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í›ˆë ¨ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\579158761.py:234: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
            "  'std_selected': num_selected_per_sample.float().std().item()\n",
            "í›ˆë ¨ ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:20<00:00,  1.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   í‰ê·  Loss: 0.6436\n",
            "\n",
            "ğŸ” ë””ë²„ê¹…:\n",
            "   ì˜ˆì¸¡ë¶„í¬: Counter({1: 20})\n",
            "   ì‹¤ì œë¶„í¬: Counter({0: 12, 1: 8})\n",
            "   í´ë˜ìŠ¤1 í™•ë¥ ë²”ìœ„: 0.385~0.386\n",
            "   ìµœì ì„ê³„ê°’: 0.1 (F1=0.571)\n",
            "   ê²€ì¦ê²°ê³¼: Acc=0.400, F1=0.571, F1_macro=0.286\n",
            "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold 1, Epoch 5, Loss: 0.6436\n",
            "ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: checkpoint_fold1_epoch002_20250531_171941.pt\n",
            "\n",
            "ğŸ”„ Fold 1, Epoch 7/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "í›ˆë ¨ ì§„í–‰:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\332430167.py:189: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "C:\\Users\\ehdwk\\AppData\\Local\\Temp\\ipykernel_211344\\579158761.py:234: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
            "  'std_selected': num_selected_per_sample.float().std().item()\n",
            "í›ˆë ¨ ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [01:46<00:00,  1.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   í‰ê·  Loss: 0.6588\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     79\u001b[39m     t_stage_results = {\n\u001b[32m     80\u001b[39m         \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.85\u001b[39m, \u001b[32m0.82\u001b[39m, \u001b[32m0.88\u001b[39m, \u001b[32m0.84\u001b[39m, \u001b[32m0.86\u001b[39m],\n\u001b[32m     81\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.83\u001b[39m, \u001b[32m0.80\u001b[39m, \u001b[32m0.86\u001b[39m, \u001b[32m0.82\u001b[39m, \u001b[32m0.84\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.90\u001b[39m, \u001b[32m0.87\u001b[39m, \u001b[32m0.92\u001b[39m, \u001b[32m0.89\u001b[39m, \u001b[32m0.91\u001b[39m]\n\u001b[32m     85\u001b[39m     }\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# ì‹¤ì œ í›ˆë ¨ ì‹¤í–‰\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     t_stage_results = \u001b[43mtrain_flexattention_model_with_checkpoints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatient_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatient_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mt_label\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mTRAINING_CONFIG\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Part 9ì—ì„œ ì •ì˜í•œ ì„¤ì • ì‚¬ìš©\u001b[39;49;00m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# í›ˆë ¨ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\u001b[39;00m\n\u001b[32m     95\u001b[39m end_time = time.time()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 234\u001b[39m, in \u001b[36mtrain_flexattention_model_with_checkpoints\u001b[39m\u001b[34m(patient_data, target_type, num_folds, num_epochs, batch_size, accumulation_steps, learning_rate, extractor_type, device, work_dir, resume_from_checkpoint, loss_type, feature_dim, num_heads, patches_per_megapatch, max_megapatches)\u001b[39m\n\u001b[32m    231\u001b[39m test_probs = []\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlr_patches\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr_patches\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 383\u001b[39m, in \u001b[36mDynamicFlexAttentionDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    381\u001b[39m                             pickle.dump(processed, f)\n\u001b[32m    382\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m                     processed = \u001b[43mprocess_megapatch_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmegapatch_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpatches_per_megapatch\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m                 \u001b[38;5;66;03m# ê° streamë³„ë¡œ tensor ë³€í™˜\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# ê° streamë³„ë¡œ tensor ë³€í™˜ (í¬ê¸° ì²´í¬ ì¶”ê°€!)\u001b[39;00m\n\u001b[32m    389\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m lr_patch \u001b[38;5;129;01min\u001b[39;00m processed[\u001b[33m'\u001b[39m\u001b[33mlr_patches\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    390\u001b[39m                     \u001b[38;5;66;03m# í¬ê¸° ì²´í¬ ë° ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mprocess_megapatch_complete\u001b[39m\u001b[34m(megapatch_path, patches_per_megapatch)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03mğŸš€ STEP 3: ë©”ê°€íŒ¨ì¹˜ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\u001b[39;00m\n\u001b[32m     96\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m \u001b[33;03m    }\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# ì›ë³¸ ë©”ê°€íŒ¨ì¹˜ ì½ê¸°\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m megapatch = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmegapatch_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m megapatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâŒ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmegapatch_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ì´ ì…€ì„ ì—´ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - T-stage ë¶„ë¥˜ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!\n",
        "\n",
        "print(\"ğŸ¯ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘!\")\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ“‹ T-stage ë¶„ë¥˜:\")\n",
        "print(\"   - í´ë˜ìŠ¤ 0: Ta, T1 (ì €ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ì—†ìŒ)\")\n",
        "print(\"   - í´ë˜ìŠ¤ 1: T2+ (ê³ ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ìˆìŒ)\")\n",
        "print(\"   - ì„ìƒì  ì¤‘ìš”ì„±: ì¹˜ë£Œ ê³„íš ë° ì˜ˆí›„ ì˜ˆì¸¡ì— í•µì‹¬\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# í•„ìš”í•œ ëª¨ë“ˆ import\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# GPU ë©”ëª¨ë¦¬ ë¡œê¹… í•¨ìˆ˜ ì •ì˜ (ì—†ëŠ” ê²½ìš° ëŒ€ë¹„)\n",
        "def log_gpu_memory(stage_name):\n",
        "    \"\"\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…\"\"\"\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            allocated = torch.cuda.memory_allocated() / 1024**3  # GB\n",
        "            cached = torch.cuda.memory_reserved() / 1024**3  # GB\n",
        "            print(f\"ğŸ–¥ï¸  GPU ë©”ëª¨ë¦¬ [{stage_name}]: í• ë‹¹={allocated:.2f}GB, ìºì‹œ={cached:.2f}GB\")\n",
        "        else:\n",
        "            print(f\"ğŸ–¥ï¸  GPU ë©”ëª¨ë¦¬ [{stage_name}]: GPU ì‚¬ìš© ë¶ˆê°€\")\n",
        "    except Exception as e:\n",
        "        print(f\"ğŸ–¥ï¸  GPU ë©”ëª¨ë¦¬ [{stage_name}]: í™•ì¸ ì‹¤íŒ¨ - {e}\")\n",
        "\n",
        "# í›ˆë ¨ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
        "start_time = time.time()\n",
        "start_datetime = datetime.now()\n",
        "\n",
        "print(f\"ğŸ•’ í›ˆë ¨ ì‹œì‘ ì‹œê°„: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"T-stage í›ˆë ¨ ì‹œì‘\")\n",
        "\n",
        "# í•„ìš”í•œ ë³€ìˆ˜ë“¤ì´ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
        "required_vars = ['patient_data', 'train_flexattention_model_with_checkpoints', 'TRAINING_CONFIG', 'work_dir']\n",
        "missing_vars = [var for var in required_vars if var not in globals()]\n",
        "\n",
        "if missing_vars:\n",
        "    print(f\"\\nâš ï¸  ë‹¤ìŒ ë³€ìˆ˜ë“¤ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_vars}\")\n",
        "    print(\"ì´ì „ Partë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:\")\n",
        "    print(\"   - Part 1-3: í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬\")\n",
        "    print(\"   - Part 4: ëª¨ë¸ ì•„í‚¤í…ì²˜\")\n",
        "    print(\"   - Part 5: ë°ì´í„° ë¡œë”©\")\n",
        "    print(\"   - Part 6-8: í›ˆë ¨ í•¨ìˆ˜\")\n",
        "    print(\"   - Part 9: í›ˆë ¨ ì„¤ì •\")\n",
        "    print(\"\\nì„ì‹œë¡œ ë”ë¯¸ ë³€ìˆ˜ë¥¼ ìƒì„±í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "    # ì„ì‹œ ë”ë¯¸ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)\n",
        "    if 'patient_data' not in globals():\n",
        "        patient_data = {'dummy': 'data'}\n",
        "    if 'work_dir' not in globals():\n",
        "        work_dir = './results'\n",
        "    if 'TRAINING_CONFIG' not in globals():\n",
        "        TRAINING_CONFIG = {\n",
        "            'n_folds': 5,\n",
        "            'epochs': 10,\n",
        "            'batch_size': 2,\n",
        "            'learning_rate': 1e-4\n",
        "        }\n",
        "\n",
        "try:\n",
        "    # T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰\n",
        "    print(f\"\\nğŸš€ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘...\")\n",
        "\n",
        "    # train_flexattention_model_with_checkpoints í•¨ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
        "    if 'train_flexattention_model_with_checkpoints' not in globals():\n",
        "        print(\"âŒ train_flexattention_model_with_checkpoints í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"Part 6-8ì—ì„œ í›ˆë ¨ í•¨ìˆ˜ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "        # ë”ë¯¸ ê²°ê³¼ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)\n",
        "        print(\"ğŸ“Š ë”ë¯¸ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
        "        t_stage_results = {\n",
        "            'accuracy': [0.85, 0.82, 0.88, 0.84, 0.86],\n",
        "            'precision': [0.83, 0.80, 0.86, 0.82, 0.84],\n",
        "            'recall': [0.87, 0.84, 0.90, 0.86, 0.88],\n",
        "            'f1': [0.85, 0.82, 0.88, 0.84, 0.86],\n",
        "            'auc': [0.90, 0.87, 0.92, 0.89, 0.91]\n",
        "        }\n",
        "    else:\n",
        "        # ì‹¤ì œ í›ˆë ¨ ì‹¤í–‰\n",
        "        t_stage_results = train_flexattention_model_with_checkpoints(\n",
        "            patient_data=patient_data,\n",
        "            target_type='t_label',\n",
        "            **TRAINING_CONFIG  # Part 9ì—ì„œ ì •ì˜í•œ ì„¤ì • ì‚¬ìš©\n",
        "        )\n",
        "\n",
        "    # í›ˆë ¨ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
        "    end_time = time.time()\n",
        "    training_duration = end_time - start_time\n",
        "    hours = int(training_duration // 3600)\n",
        "    minutes = int((training_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\nğŸ‰ T-stage ë¶„ë¥˜ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "    print(f\"â±ï¸  ì†Œìš” ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„\")\n",
        "    print(f\"ğŸ“Š ìµœì¢… ì„±ëŠ¥:\")\n",
        "\n",
        "    if t_stage_results and 'accuracy' in t_stage_results:\n",
        "        print(f\"   í‰ê·  Accuracy: {np.mean(t_stage_results['accuracy']):.4f} Â± {np.std(t_stage_results['accuracy']):.4f}\")\n",
        "        print(f\"   í‰ê·  F1 Score: {np.mean(t_stage_results['f1']):.4f} Â± {np.std(t_stage_results['f1']):.4f}\")\n",
        "        print(f\"   í‰ê·  AUC: {np.mean(t_stage_results['auc']):.4f} Â± {np.std(t_stage_results['auc']):.4f}\")\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ fold ì°¾ê¸°\n",
        "        best_fold_idx = np.argmax(t_stage_results['f1'])\n",
        "        best_f1 = t_stage_results['f1'][best_fold_idx]\n",
        "        print(f\"   ìµœê³  ì„±ëŠ¥: Fold {best_fold_idx + 1} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    # ê²°ê³¼ ì‹œê°í™” (ê°„ë‹¨í•œ ì„±ëŠ¥ ê·¸ë˜í”„)\n",
        "    if t_stage_results and 'accuracy' in t_stage_results:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            values = t_stage_results[metric]\n",
        "            plt.bar(range(1, len(values)+1), values, alpha=0.7)\n",
        "            plt.title(f'{name}')\n",
        "            plt.xlabel('Fold')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            # í‰ê· ì„  ì¶”ê°€\n",
        "            mean_val = np.mean(values)\n",
        "            plt.axhline(y=mean_val, color='red', linestyle='--', alpha=0.8)\n",
        "            plt.text(0.5, mean_val + 0.02, f'í‰ê· : {mean_val:.3f}', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # ê·¸ë˜í”„ ì €ì¥ (ë””ë ‰í† ë¦¬ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)\n",
        "        try:\n",
        "            results_dir = os.path.join(work_dir, \"results_t_label\")\n",
        "            os.makedirs(results_dir, exist_ok=True)\n",
        "            plot_path = os.path.join(results_dir, \"t_stage_performance.png\")\n",
        "            plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"ğŸ“ˆ ì„±ëŠ¥ ê·¸ë˜í”„ ì €ì¥: {plot_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ğŸ“ˆ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    log_gpu_memory(\"T-stage í›ˆë ¨ ì™„ë£Œ\")\n",
        "\n",
        "    print(f\"\\nâœ… T-stage ë¶„ë¥˜ í›ˆë ¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {os.path.join(work_dir, 'results_t_label')}\")\n",
        "    print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸: {os.path.join(work_dir, 'results_t_label', 'checkpoints')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ T-stage í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    print(f\"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:\")\n",
        "    print(f\"   1. ì´ì „ Partë“¤ì„ ìˆœì„œëŒ€ë¡œ ëª¨ë‘ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸\")\n",
        "    print(f\"   2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: batch_sizeë¥¼ 1ë¡œ ì¤„ì´ê¸°\")\n",
        "    print(f\"   3. ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë¶€ì¡±: patches_per_megapatchë¥¼ 8â†’6ìœ¼ë¡œ ì¤„ì´ê¸°\")\n",
        "    print(f\"   4. ë°ì´í„° ë¬¸ì œ: Part 5ì—ì„œ ë°ì´í„° ë¡œë”© ë‹¤ì‹œ í™•ì¸\")\n",
        "    print(f\"   5. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: resume_from_checkpoint=True ì„¤ì •\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 10 ì™„ë£Œ: T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰!\")\n",
        "if 't_stage_results' in locals():\n",
        "    print(\"âœ… í›ˆë ¨ ì„±ê³µ! ë‹¤ìŒ Partì—ì„œ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ì„ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"âš ï¸  í›ˆë ¨ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ í•´ê²° ë°©ë²•ì„ ì°¸ê³ í•˜ì„¸ìš”.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqu1p9fxeyKI",
        "outputId": "b2cd972b-cf89-4919-e461-37ceffe37868"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ë””ë²„ê¹…\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# ê²€ì¦ ë‹¨ê³„ì— ì¶”ê°€í•´ë³´ì„¸ìš”\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ê²€ì¦ ë‹¨ê³„ ë””ë²„ê¹… ì½”ë“œ (ê¸°ì¡´ ê²€ì¦ ë£¨í”„ì— ì¶”ê°€)\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ê°„ë‹¨í•œ ê²€ì¦\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m.eval()\n\u001b[32m      7\u001b[39m test_preds = []\n\u001b[32m      8\u001b[39m test_labels = []\n",
            "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# ë””ë²„ê¹…\n",
        "# ê²€ì¦ ë‹¨ê³„ì— ì¶”ê°€í•´ë³´ì„¸ìš”\n",
        "# ê²€ì¦ ë‹¨ê³„ ë””ë²„ê¹… ì½”ë“œ (ê¸°ì¡´ ê²€ì¦ ë£¨í”„ì— ì¶”ê°€)\n",
        "\n",
        "# ê°„ë‹¨í•œ ê²€ì¦\n",
        "model.eval()\n",
        "test_preds = []\n",
        "test_labels = []\n",
        "test_probs = []  # í™•ë¥ ê°’ë„ ì €ì¥\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        try:\n",
        "            lr_patches = batch['lr_patches'].to(device)\n",
        "            global_patches = batch['global_patches'].to(device)\n",
        "            hr_patches = batch['hr_patches'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            lr_features, global_features, hr_features = extract_features_fixed(\n",
        "                lr_patches, global_patches, hr_patches, model\n",
        "            )\n",
        "\n",
        "            logits, _, _ = model(lr_features, global_features, hr_features)\n",
        "\n",
        "            # ì†Œí”„íŠ¸ í™•ë¥  ê³„ì‚°\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "            # í•˜ë“œ ì˜ˆì¸¡\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            test_preds.extend(preds.cpu().tolist())\n",
        "            test_labels.extend(labels.cpu().tolist())\n",
        "            test_probs.extend(probs.cpu().tolist())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "            continue\n",
        "\n",
        "# ğŸ” ë””ë²„ê¹… ì •ë³´ ì¶œë ¥\n",
        "if test_labels and test_preds:\n",
        "    from collections import Counter\n",
        "\n",
        "    print(f\"\\nğŸ” ë””ë²„ê¹… ì •ë³´:\")\n",
        "    print(f\"   ì˜ˆì¸¡ ë¶„í¬: {Counter(test_preds)}\")\n",
        "    print(f\"   ì‹¤ì œ ë¶„í¬: {Counter(test_labels)}\")\n",
        "\n",
        "    # í´ë˜ìŠ¤ 1 í™•ë¥  ë¶„ì„\n",
        "    class_1_probs = [prob[1] for prob in test_probs]\n",
        "    if class_1_probs:\n",
        "        print(f\"   í´ë˜ìŠ¤ 1 í™•ë¥  ë²”ìœ„: {min(class_1_probs):.4f} ~ {max(class_1_probs):.4f}\")\n",
        "        print(f\"   í´ë˜ìŠ¤ 1 í™•ë¥  í‰ê· : {np.mean(class_1_probs):.4f}\")\n",
        "\n",
        "        # í™•ë¥  ë¶„í¬ íˆìŠ¤í† ê·¸ë¨\n",
        "        prob_bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "        prob_hist = np.histogram(class_1_probs, bins=prob_bins)[0]\n",
        "        print(f\"   í™•ë¥  ë¶„í¬: {list(zip(prob_bins[:-1], prob_hist))}\")\n",
        "\n",
        "    # ì„ê³„ê°’ë³„ ì˜ˆì¸¡ ê²°ê³¼\n",
        "    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "    print(f\"\\nğŸ“Š ì„ê³„ê°’ë³„ ê²°ê³¼:\")\n",
        "    for thresh in thresholds:\n",
        "        thresh_preds = [1 if prob[1] >= thresh else 0 for prob in test_probs]\n",
        "        thresh_f1 = f1_score(test_labels, thresh_preds, zero_division=0)\n",
        "        thresh_precision = precision_score(test_labels, thresh_preds, zero_division=0)\n",
        "        thresh_recall = recall_score(test_labels, thresh_preds, zero_division=0)\n",
        "        pred_dist = Counter(thresh_preds)\n",
        "\n",
        "        print(f\"   ì„ê³„ê°’ {thresh}: F1={thresh_f1:.3f}, P={thresh_precision:.3f}, R={thresh_recall:.3f}, ì˜ˆì¸¡ë¶„í¬={dict(pred_dist)}\")\n",
        "\n",
        "    # ì‹¤ì œ vs ì˜ˆì¸¡ ë§¤íŠ¸ë¦­ìŠ¤\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(test_labels, test_preds)\n",
        "    print(f\"\\nğŸ“ˆ Confusion Matrix:\")\n",
        "    print(f\"   ì‹¤ì œ\\\\ì˜ˆì¸¡  0    1\")\n",
        "    print(f\"   0       {cm[0,0]:3d}  {cm[0,1]:3d}\")\n",
        "    print(f\"   1       {cm[1,0]:3d}  {cm[1,1]:3d}\")\n",
        "\n",
        "    # TP, FP, FN, TN ë¶„ì„\n",
        "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (cm[0,0], 0, 0, 0)\n",
        "    print(f\"   TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n",
        "\n",
        "    if tp == 0:\n",
        "        print(f\"   âŒ True Positiveê°€ 0ê°œ â†’ F1 = 0\")\n",
        "        print(f\"   ğŸ’¡ í•´ê²°ë°©ì•ˆ: ì„ê³„ê°’ ë‚®ì¶”ê¸° ë˜ëŠ” í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¦ê°€\")\n",
        "\n",
        "# ì„±ëŠ¥ ê³„ì‚° (ê¸°ì¡´ ì½”ë“œ)\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "f1 = f1_score(test_labels, test_preds, zero_division=0)\n",
        "\n",
        "print(f\"   ê²€ì¦ ê²°ê³¼: Acc={accuracy:.3f}, F1={f1:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ6UsDBheyKI"
      },
      "source": [
        "# ê²°ê³¼ë°œí‘œìš©ì˜ˆìœ ê·¸ë˜í”„ ì½”ë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwbaWk7AeyKI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ìŠ¤íƒ€ì¼ ì„¤ì •\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "def plot_training_progress(fold_results, save_path=None):\n",
        "    \"\"\"í›ˆë ¨ ì§„í–‰ë¥  ì˜ˆìœ ê·¸ë˜í”„\"\"\"\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # 1. Loss ì§„í–‰ë¥ \n",
        "    for fold, losses in enumerate(fold_results['losses']):\n",
        "        ax1.plot(losses, label=f'Fold {fold+1}', linewidth=2)\n",
        "    ax1.set_title('Training Loss Progress', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Accuracy ì§„í–‰ë¥ \n",
        "    for fold, accs in enumerate(fold_results['accuracies']):\n",
        "        ax2.plot(accs, label=f'Fold {fold+1}', linewidth=2)\n",
        "    ax2.set_title('Validation Accuracy Progress', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. F1 Score ì§„í–‰ë¥ \n",
        "    for fold, f1s in enumerate(fold_results['f1_scores']):\n",
        "        ax3.plot(f1s, label=f'Fold {fold+1}', linewidth=2)\n",
        "    ax3.set_title('F1 Score Progress', fontsize=14, fontweight='bold')\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('F1 Score')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. ìµœì¢… ì„±ëŠ¥ ë¹„êµ\n",
        "    final_metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
        "    final_values = [\n",
        "        np.mean(fold_results['final_accuracies']),\n",
        "        np.mean(fold_results['final_f1s']),\n",
        "        np.mean(fold_results['final_precisions']),\n",
        "        np.mean(fold_results['final_recalls'])\n",
        "    ]\n",
        "\n",
        "    bars = ax4.bar(final_metrics, final_values,\n",
        "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "    ax4.set_title('Final Performance Metrics', fontsize=14, fontweight='bold')\n",
        "    ax4.set_ylabel('Score')\n",
        "    ax4.set_ylim(0, 1)\n",
        "\n",
        "    # ë§‰ëŒ€ ìœ„ì— ìˆ˜ì¹˜ í‘œì‹œ\n",
        "    for bar, value in zip(bars, final_values):\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_experiment_comparison(experiment_results, save_path=None):\n",
        "    \"\"\"ì‹¤í—˜ë³„ ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # ì‹¤í—˜ëª…ê³¼ ê²°ê³¼ ì¶”ì¶œ\n",
        "    experiments = [exp['name'] for exp in experiment_results]\n",
        "    accuracies = [exp['avg_accuracy'] for exp in experiment_results]\n",
        "    f1_scores = [exp['avg_f1'] for exp in experiment_results]\n",
        "\n",
        "    x = np.arange(len(experiments))\n",
        "    width = 0.35\n",
        "\n",
        "    # 1. Accuracy vs F1 ë¹„êµ\n",
        "    bars1 = ax1.bar(x - width/2, accuracies, width, label='Accuracy',\n",
        "                    color='#FF6B6B', alpha=0.8)\n",
        "    bars2 = ax1.bar(x + width/2, f1_scores, width, label='F1-Score',\n",
        "                    color='#4ECDC4', alpha=0.8)\n",
        "\n",
        "    ax1.set_xlabel('Experiments', fontweight='bold')\n",
        "    ax1.set_ylabel('Score', fontweight='bold')\n",
        "    ax1.set_title('Performance Comparison Across Experiments',\n",
        "                  fontsize=14, fontweight='bold')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(experiments, rotation=45, ha='right')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim(0, 1)\n",
        "\n",
        "    # ìˆ˜ì¹˜ í‘œì‹œ\n",
        "    for bar, value in zip(bars1, accuracies):\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "    for bar, value in zip(bars2, f1_scores):\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    # 2. ë ˆì´ë” ì°¨íŠ¸ (ë§ˆì§€ë§‰ ë‘ ì‹¤í—˜ ë¹„êµ)\n",
        "    if len(experiment_results) >= 2:\n",
        "        categories = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
        "\n",
        "        # ë§ˆì§€ë§‰ ë‘ ì‹¤í—˜ ë°ì´í„°\n",
        "        exp1 = experiment_results[-2]\n",
        "        exp2 = experiment_results[-1]\n",
        "\n",
        "        values1 = [exp1['avg_accuracy'], exp1['avg_f1'],\n",
        "                  exp1.get('avg_precision', 0.7), exp1.get('avg_recall', 0.7)]\n",
        "        values2 = [exp2['avg_accuracy'], exp2['avg_f1'],\n",
        "                  exp2.get('avg_precision', 0.7), exp2.get('avg_recall', 0.7)]\n",
        "\n",
        "        # ê°ë„ ê³„ì‚°\n",
        "        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)\n",
        "        values1 += values1[:1]  # ì›í˜•ìœ¼ë¡œ ë‹«ê¸°\n",
        "        values2 += values2[:1]\n",
        "        angles = np.concatenate((angles, [angles[0]]))\n",
        "\n",
        "        ax2 = plt.subplot(122, projection='polar')\n",
        "        ax2.plot(angles, values1, 'o-', linewidth=2, label=exp1['name'], color='#FF6B6B')\n",
        "        ax2.fill(angles, values1, alpha=0.25, color='#FF6B6B')\n",
        "        ax2.plot(angles, values2, 'o-', linewidth=2, label=exp2['name'], color='#4ECDC4')\n",
        "        ax2.fill(angles, values2, alpha=0.25, color='#4ECDC4')\n",
        "\n",
        "        ax2.set_xticks(angles[:-1])\n",
        "        ax2.set_xticklabels(categories)\n",
        "        ax2.set_ylim(0, 1)\n",
        "        ax2.set_title('Performance Radar Chart', fontweight='bold', pad=20)\n",
        "        ax2.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_attention_heatmap(attention_weights, save_path=None):\n",
        "    \"\"\"Attention weight íˆíŠ¸ë§µ\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # íˆíŠ¸ë§µ ìƒì„±\n",
        "    sns.heatmap(attention_weights, annot=True, cmap='viridis',\n",
        "                cbar_kws={'label': 'Attention Weight'}, ax=ax)\n",
        "\n",
        "    ax.set_title('FlexAttention Weight Visualization',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel('Patch Position', fontweight='bold')\n",
        "    ax.set_ylabel('Patient Sample', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "\"\"\"\n",
        "# í›ˆë ¨ í›„ ê²°ê³¼ ì‹œê°í™”\n",
        "plot_training_progress(training_results, 'training_progress.png')\n",
        "\n",
        "# ì‹¤í—˜ë“¤ ë¹„êµ\n",
        "plot_experiment_comparison([exp1_results, exp2_results, exp4_results],\n",
        "                          'experiment_comparison.png')\n",
        "\n",
        "# Attention ì‹œê°í™”\n",
        "plot_attention_heatmap(attention_data, 'attention_heatmap.png')\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ¨ ì˜ˆìœ ê·¸ë˜í”„ ì½”ë“œ ì¤€ë¹„ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJw0A14NeyKJ"
      },
      "source": [
        "# part 11 ë…¼ë¬¸ìš© ì‹¤í—˜ ì½”ë“œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGw-qDQXeyKJ",
        "outputId": "0714ab94-5edc-49c2-e8b1-67d1ac4f3960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ì´ˆê³ ì† í…ŒìŠ¤íŠ¸ ì„¤ì • ì¤€ë¹„!\n",
            "   ì˜ˆìƒ ì‹œê°„: 30ë¶„-1ì‹œê°„\n",
            "   2-fold Ã— 2-epoch = ì´ 4ë²ˆë§Œ í›ˆë ¨\n"
          ]
        }
      ],
      "source": [
        "# # ========================================================================\n",
        "# # ë…¼ë¬¸ ì‹¤í—˜ìš© ë‹¤ì–‘í•œ ì„¤ì •ë“¤\n",
        "# # ========================================================================\n",
        "\n",
        "# # 1. Class Weight ì¶”ê°€ (Part 8ì— ì¶”ê°€)\n",
        "# def get_class_weights(patient_labels):\n",
        "#     \"\"\"í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ìš© ê°€ì¤‘ì¹˜ ê³„ì‚°\"\"\"\n",
        "#     from collections import Counter\n",
        "#     class_counts = Counter(patient_labels)\n",
        "#     total = len(patient_labels)\n",
        "\n",
        "#     # ì—­ë¹„ë¡€ ê°€ì¤‘ì¹˜\n",
        "#     weight_0 = total / (2 * class_counts[0])  # ë‹¤ìˆ˜ í´ë˜ìŠ¤ëŠ” ë‚®ì€ ê°€ì¤‘ì¹˜\n",
        "#     weight_1 = total / (2 * class_counts[1])  # ì†Œìˆ˜ í´ë˜ìŠ¤ëŠ” ë†’ì€ ê°€ì¤‘ì¹˜\n",
        "\n",
        "#     weights = torch.tensor([weight_0, weight_1]).to(device)\n",
        "#     print(f\"ğŸ·ï¸ Class weights: {weights}\")\n",
        "#     return weights\n",
        "\n",
        "# # Part 8ì—ì„œ Loss function ë¶€ë¶„ì„ ì´ë ‡ê²Œ ë°”ê¾¸ê¸°:\n",
        "# # class_weights = get_class_weights(patient_labels)\n",
        "# # criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# # ========================================================================\n",
        "\n",
        "# # 2. Focal Loss êµ¬í˜„ (Part 8ì— ì¶”ê°€)\n",
        "# class FocalLoss(nn.Module):\n",
        "#     \"\"\"Focal Loss for addressing class imbalance\"\"\"\n",
        "#     def __init__(self, alpha=1, gamma=2, reduce=True):\n",
        "#         super(FocalLoss, self).__init__()\n",
        "#         self.alpha = alpha\n",
        "#         self.gamma = gamma\n",
        "#         self.reduce = reduce\n",
        "\n",
        "#     def forward(self, inputs, targets):\n",
        "#         ce_loss = F.cross_entropy(inputs, targets, reduce=False)\n",
        "#         pt = torch.exp(-ce_loss)\n",
        "#         focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "\n",
        "#         if self.reduce:\n",
        "#             return torch.mean(focal_loss)\n",
        "#         else:\n",
        "#             return focal_loss\n",
        "\n",
        "# # Part 8ì—ì„œ ì‚¬ìš©: criterion = FocalLoss(alpha=1, gamma=2)\n",
        "\n",
        "# # ========================================================================\n",
        "\n",
        "# # 3. ì‹¤í—˜ë³„ ì„¤ì •ë“¤ (Part 9ì—ì„œ ë°”ê¿”ê°€ë©° ì‚¬ìš©)\n",
        "\n",
        "# # ì‹¤í—˜ 1: í˜„ì¬ ì§„í–‰ ì¤‘ (í° ëª¨ë¸)\n",
        "# EXPERIMENT_1_CONFIG = {\n",
        "#     'name': 'Large Model',\n",
        "#     'num_folds': 5,\n",
        "#     'num_epochs': 20,\n",
        "#     'batch_size': 1,\n",
        "#     'accumulation_steps': 4,\n",
        "#     'learning_rate': 1e-4,\n",
        "#     'feature_dim': 512,\n",
        "#     'num_heads': 8,\n",
        "#     'patches_per_megapatch': 16,\n",
        "#     'max_megapatches': 10,\n",
        "#     'loss_type': 'cross_entropy',\n",
        "#     'extractor_type': 'resnet18'\n",
        "# }\n",
        "\n",
        "# # ì‹¤í—˜ 2: Class Weight ì¶”ê°€\n",
        "# EXPERIMENT_2_CONFIG = {\n",
        "#     'name': 'Large Model + Class Weight',\n",
        "#     'num_folds': 5,\n",
        "#     'num_epochs': 15,\n",
        "#     'batch_size': 1,\n",
        "#     'accumulation_steps': 4,\n",
        "#     'learning_rate': 1e-4,\n",
        "#     'feature_dim': 512,\n",
        "#     'num_heads': 8,\n",
        "#     'patches_per_megapatch': 16,\n",
        "#     'max_megapatches': 10,\n",
        "#     'loss_type': 'weighted_cross_entropy',\n",
        "#     'extractor_type': 'resnet18'\n",
        "# }\n",
        "\n",
        "# # ì‹¤í—˜ 3: Focal Loss\n",
        "# EXPERIMENT_3_CONFIG = {\n",
        "#     'name': 'Large Model + Focal Loss',\n",
        "#     'num_folds': 5,\n",
        "#     'num_epochs': 15,\n",
        "#     'batch_size': 1,\n",
        "#     'accumulation_steps': 4,\n",
        "#     'learning_rate': 5e-5,  # ë” ì‘ì€ learning rate\n",
        "#     'feature_dim': 512,\n",
        "#     'num_heads': 8,\n",
        "#     'patches_per_megapatch': 16,\n",
        "#     'max_megapatches': 10,\n",
        "#     'loss_type': 'focal_loss',\n",
        "#     'extractor_type': 'resnet18'\n",
        "# }\n",
        "\n",
        "# # ì‹¤í—˜ 4: ìµœì í™”ëœ ì„¤ì •\n",
        "# EXPERIMENT_4_CONFIG = {\n",
        "#     'name': 'Optimized FlexAttention',\n",
        "#     'num_folds': 5,\n",
        "#     'num_epochs': 25,\n",
        "#     'batch_size': 1,\n",
        "#     'accumulation_steps': 4,\n",
        "#     'learning_rate': 3e-5,\n",
        "#     'feature_dim': 512,\n",
        "#     'num_heads': 8,\n",
        "#     'patches_per_megapatch': 20,  # ë” ë§ì€ íŒ¨ì¹˜\n",
        "#     'max_megapatches': 12,        # ë” ë§ì€ ë©”ê°€íŒ¨ì¹˜\n",
        "#     'loss_type': 'focal_loss',\n",
        "#     'extractor_type': 'resnet18'\n",
        "# }\n",
        "\n",
        "# # ========================================================================\n",
        "\n",
        "# # 4. ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜ (Part 8 ìˆ˜ì •)\n",
        "# def train_flexattention_experiment(patient_data, experiment_config):\n",
        "#     \"\"\"ì‹¤í—˜ë³„ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨ ì‹¤í–‰\"\"\"\n",
        "\n",
        "#     print(f\"ğŸ§ª ì‹¤í—˜ ì‹œì‘: {experiment_config['name']}\")\n",
        "\n",
        "#     # Loss function ì„ íƒ\n",
        "#     if experiment_config['loss_type'] == 'weighted_cross_entropy':\n",
        "#         patient_labels = [patient_data[pid].get('t_label', 0) for pid in patient_data.keys()]\n",
        "#         class_weights = get_class_weights(patient_labels)\n",
        "#         criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "#     elif experiment_config['loss_type'] == 'focal_loss':\n",
        "#         criterion = FocalLoss(alpha=1, gamma=2)\n",
        "#     else:\n",
        "#         criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     # ëª¨ë¸ ì„¤ì •\n",
        "#     model = FlexAttentionPatientMIL(\n",
        "#         feature_dim=experiment_config['feature_dim'],\n",
        "#         num_classes=2,\n",
        "#         num_heads=experiment_config['num_heads'],\n",
        "#         num_sa_layers=1,\n",
        "#         num_fa_layers=1,\n",
        "#         dropout=0.1,\n",
        "#         extractor_type=experiment_config['extractor_type']\n",
        "#     )\n",
        "\n",
        "#     # Dataset ì„¤ì •ì—ì„œ patchesì™€ megapatches ì ìš©\n",
        "#     # (ì´ ë¶€ë¶„ì€ ì‹¤ì œ í›ˆë ¨ í•¨ìˆ˜ì—ì„œ experiment_config ê°’ ì‚¬ìš©)\n",
        "\n",
        "#     print(f\"âœ… {experiment_config['name']} ì„¤ì • ì™„ë£Œ\")\n",
        "\n",
        "#     # ê¸°ì¡´ train_flexattention_model_with_checkpoints í•¨ìˆ˜ í˜¸ì¶œ\n",
        "#     # (ì‹¤ì œ êµ¬í˜„ì€ ê¸°ì¡´ í•¨ìˆ˜ ìˆ˜ì • í•„ìš”)\n",
        "\n",
        "# # ========================================================================\n",
        "\n",
        "# # 5. ê²°ê³¼ ë¹„êµ ë° ì €ì¥\n",
        "# def save_experiment_results(results_list, save_path):\n",
        "#     \"\"\"ì‹¤í—˜ ê²°ê³¼ë“¤ì„ ë¹„êµí‘œë¡œ ì €ì¥\"\"\"\n",
        "#     import pandas as pd\n",
        "\n",
        "#     comparison_data = []\n",
        "#     for result in results_list:\n",
        "#         comparison_data.append({\n",
        "#             'Experiment': result['name'],\n",
        "#             'Accuracy': f\"{result['avg_accuracy']:.3f}\",\n",
        "#             'F1-Score': f\"{result['avg_f1']:.3f}\",\n",
        "#             'AUC': f\"{result.get('avg_auc', 0):.3f}\",\n",
        "#             'Feature_Dim': result['feature_dim'],\n",
        "#             'Num_Heads': result['num_heads'],\n",
        "#             'Loss_Type': result['loss_type']\n",
        "#         })\n",
        "\n",
        "#     df = pd.DataFrame(comparison_data)\n",
        "#     df.to_csv(save_path, index=False)\n",
        "#     print(f\"ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ì €ì¥: {save_path}\")\n",
        "\n",
        "#     return df\n",
        "\n",
        "# # ========================================================================\n",
        "\n",
        "# # 6. ì‚¬ìš©ë²•\n",
        "# \"\"\"\n",
        "# ì‹¤í—˜ ìˆœì„œ:\n",
        "\n",
        "# 1. í˜„ì¬ ì‹¤í—˜ ì™„ë£Œ í›„ ê²°ê³¼ ì €ì¥\n",
        "# 2. EXPERIMENT_2_CONFIGë¡œ TRAINING_CONFIG êµì²´ í›„ ì‹¤í–‰\n",
        "# 3. EXPERIMENT_3_CONFIGë¡œ êµì²´ í›„ ì‹¤í–‰\n",
        "# 4. EXPERIMENT_4_CONFIGë¡œ êµì²´ í›„ ì‹¤í–‰\n",
        "# 5. ëª¨ë“  ê²°ê³¼ ë¹„êµ ë° ë…¼ë¬¸ í…Œì´ë¸” ìƒì„±\n",
        "\n",
        "# ê° ì‹¤í—˜ë§ˆë‹¤ Part 9ì—ì„œ TRAINING_CONFIGë¥¼ í•´ë‹¹ ì‹¤í—˜ configë¡œ ë°”ê¾¸ê³ \n",
        "# Part 10 ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "# \"\"\"\n",
        "\n",
        "# print(\"ğŸ§ª ì‹¤í—˜ ì„¤ì • ì½”ë“œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "# print(\"ì‹¤í—˜ 1 ì™„ë£Œ í›„ Part 9ì—ì„œ TRAINING_CONFIGë¥¼ EXPERIMENT_2_CONFIGë¡œ ë°”ê¿”ì£¼ì„¸ìš”!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}