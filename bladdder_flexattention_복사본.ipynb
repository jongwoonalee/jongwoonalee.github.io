{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongwoonalee/jongwoonalee.github.io/blob/main/bladdder_flexattention_%EB%B3%B5%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SQZtrFEUJ3I"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 1: 라이브러리 및 기본 설정\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5NDXfQWUJ3J"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 이 셀을 먼저 실행하세요 - 필요한 모든 라이브러리를 import 합니다\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from skimage.filters import threshold_otsu\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "print(\"✅ 모든 라이브러리 import 완료!\")\n",
        "\n",
        "# GPU 설정 및 확인 - RTX 6000 Ada x2 최적화\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"🚀 {num_gpus}개의 GPU 발견!\")\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "        print(f\"   GPU {i}: {gpu_name} ({memory_gb:.1f}GB)\")\n",
        "\n",
        "    # CUDA 최적화 설정\n",
        "    torch.backends.cudnn.benchmark = True  # 동일한 입력 크기에 대해 최적화\n",
        "    torch.cuda.empty_cache()               # GPU 메모리 정리\n",
        "\n",
        "    print(f\"✅ 주 디바이스: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"⚠️  GPU를 찾을 수 없습니다. CPU 모드로 실행됩니다.\")\n",
        "\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "\n",
        "# 재현 가능한 결과를 위한 시드 설정\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    모든 랜덤 시드를 고정하여 재현 가능한 결과를 얻습니다.\n",
        "\n",
        "    Args:\n",
        "        seed (int): 고정할 시드 값 (기본값: 42)\n",
        "    \"\"\"\n",
        "    random.seed(seed)              # Python 기본 random\n",
        "    np.random.seed(seed)           # NumPy random\n",
        "    torch.manual_seed(seed)        # PyTorch CPU random\n",
        "    torch.cuda.manual_seed(seed)   # PyTorch GPU random (현재 디바이스)\n",
        "    torch.cuda.manual_seed_all(seed)  # PyTorch 모든 GPU random\n",
        "\n",
        "    # 완전한 재현성을 위한 설정 (속도가 약간 느려질 수 있음)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # 환경 변수로도 시드 설정\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    print(f\"✅ 모든 랜덤 시드를 {seed}로 고정했습니다.\")\n",
        "\n",
        "# 시드 고정 실행\n",
        "set_seed(42)\n",
        "\n",
        "# 메모리 사용량 모니터링 함수\n",
        "def log_gpu_memory(step_name=\"\"):\n",
        "    \"\"\"\n",
        "    현재 GPU 메모리 사용량을 출력합니다.\n",
        "\n",
        "    Args:\n",
        "        step_name (str): 현재 단계 이름 (로그 구분용)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3  # GB 단위\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3    # GB 단위\n",
        "        max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
        "\n",
        "        print(f\"🔍 [{step_name}] GPU 메모리 - \"\n",
        "              f\"사용중: {allocated:.2f}GB, \"\n",
        "              f\"예약됨: {reserved:.2f}GB, \"\n",
        "              f\"최대사용: {max_allocated:.2f}GB\")\n",
        "    else:\n",
        "        print(f\"🔍 [{step_name}] CPU 모드 실행 중\")\n",
        "\n",
        "# 초기 메모리 상태 확인\n",
        "log_gpu_memory(\"초기 상태\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 1 완료: 기본 설정 및 라이브러리 준비 완료!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuLEAIHJUJ3K"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 2: 데이터 로딩 및 전처리 함수\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP3m7VdkUJ3K"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 두 번째로 실행하세요 - 데이터 처리에 필요한 모든 함수들을 정의합니다\n",
        "\n",
        "def extract_identifier(filename):\n",
        "    \"\"\"\n",
        "    파일명에서 환자 ID를 추출하는 함수\n",
        "\n",
        "    Args:\n",
        "        filename (str): 이미지 파일명 (예: \"S123-456.jpg\")\n",
        "\n",
        "    Returns:\n",
        "        str or None: 추출된 환자 ID (예: \"S123000456\")\n",
        "        str: 파일 확장자\n",
        "\n",
        "    Example:\n",
        "        extract_identifier(\"S123-456.jpg\") → (\"S123000456\", \".jpg\")\n",
        "    \"\"\"\n",
        "    # 파일명과 확장자 분리\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # 대괄호가 있으면 제거 (예: \"[comment]\" 부분)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # 패턴 1: S숫자-숫자 형태 (예: S123-456)\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)      # \"123\"\n",
        "        patch = m1.group(2)      # \"456\"\n",
        "\n",
        "        # 패치 번호를 6자리로 패딩 (앞에 0 추가)\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch    # 456 → 000456\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch     # 1456 → 001456\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch      # 12456 → 012456\n",
        "        else:\n",
        "            patch_padded = patch            # 이미 6자리면 그대로\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # 패턴 2: S숫자, 형태 (예: S123,)\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # 패턴 3: S + 6-8자리 숫자 (예: S12345678)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # 매칭되지 않으면 None 반환\n",
        "    return None, ext\n",
        "\n",
        "def convert_file_id_to_excel_format(file_id):\n",
        "    \"\"\"\n",
        "    파일 ID를 Excel에서 사용하는 형태로 변환\n",
        "\n",
        "    Args:\n",
        "        file_id (str): 파일에서 추출한 ID\n",
        "\n",
        "    Returns:\n",
        "        str or None: Excel 형태로 변환된 ID\n",
        "\n",
        "    Example:\n",
        "        convert_file_id_to_excel_format(\"S123-456\") → \"S123000456\"\n",
        "    \"\"\"\n",
        "    if file_id is None:\n",
        "        return None\n",
        "\n",
        "    file_id = str(file_id).strip()\n",
        "\n",
        "    # \"-\"가 포함된 경우 (예: S123-456)\n",
        "    if \"-\" in file_id:\n",
        "        parts = file_id.split(\"-\")\n",
        "        if len(parts) == 2 and parts[1].isdigit():\n",
        "            patch = parts[1]\n",
        "\n",
        "            # 패치 번호를 6자리로 패딩\n",
        "            if len(patch) == 3:\n",
        "                padded_number = \"000\" + patch\n",
        "            elif len(patch) == 4:\n",
        "                padded_number = \"00\" + patch\n",
        "            elif len(patch) == 5:\n",
        "                padded_number = \"0\" + patch\n",
        "            else:\n",
        "                padded_number = patch\n",
        "\n",
        "            return f\"{parts[0]}{padded_number}\"\n",
        "\n",
        "    # 이미 S로 시작하는 긴 형태면 그대로 반환\n",
        "    elif len(file_id) > 3 and file_id.startswith(\"S\"):\n",
        "        return file_id\n",
        "\n",
        "    return None\n",
        "\n",
        "# 데이터 로딩 및 매칭 함수 (여기서는 함수만 정의, 실제 로딩은 다음 셀에서)\n",
        "def load_and_match_data(zip_path, excel_path, base_dir=None):\n",
        "    \"\"\"\n",
        "    ZIP 파일과 Excel 파일을 매칭하여 환자별 데이터를 구성하는 함수\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): 이미지가 들어있는 ZIP 파일 경로\n",
        "        excel_path (str): 라벨 정보가 들어있는 Excel 파일 경로\n",
        "        base_dir (str, optional): ZIP 압축 해제할 디렉토리\n",
        "\n",
        "    Returns:\n",
        "        dict: 환자별로 구성된 데이터 딕셔너리\n",
        "        {\n",
        "            \"patient_id\": {\n",
        "                \"images\": [이미지파일경로들],\n",
        "                \"t_label\": T-stage 라벨,\n",
        "                \"recur_label\": 재발 라벨,\n",
        "                \"grade\": 등급 정보,\n",
        "                ... 기타 정보\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    print(\"🚀 데이터 로딩 및 매칭 시작...\")\n",
        "\n",
        "    # Excel 파일 읽기\n",
        "    print(\"📊 Excel 파일 읽는 중...\")\n",
        "    try:\n",
        "        df = pd.read_excel(excel_path)\n",
        "        print(f\"   ✅ Excel 파일 로드 완료: {len(df)}개 행\")\n",
        "        print(f\"   📋 컬럼들: {list(df.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Excel 파일 읽기 실패: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # T-stage와 재발 라벨 생성\n",
        "    print(\"🏷️  라벨 변환 중...\")\n",
        "\n",
        "        # T-stage 라벨: 1 → 0 (저위험), 2 → 1 (고위험)\n",
        "        second_column = df.columns[1]  # 두 번째 컬럼 (Subtype)\n",
        "        df['t_label'] = df[second_column].apply(\n",
        "            lambda x: 0 if str(x) == '1' else 1\n",
        "        )\n",
        "        t_counts = df['t_label'].value_counts()\n",
        "        print(f\"   📈 T-stage 분포: 저위험(0): {t_counts.get(0, 0)}개, 고위험(1): {t_counts.get(1, 0)}개\")\n",
        "\n",
        "    # 재발 라벨: No → 0, Yes → 1\n",
        "    #if 'Recurrence' in df.columns:\n",
        "        #df['recur_label'] = df['Recurrence'].apply(\n",
        "           # lambda x: 0 if str(x).lower() == 'no' else 1\n",
        "        #)\n",
        "       # recur_counts = df['recur_label'].value_counts()\n",
        "      #  print(f\"   🔄 재발 분포: 없음(0): {recur_counts.get(0, 0)}개, 있음(1): {recur_counts.get(1, 0)}개\")\n",
        "\n",
        "    # ZIP 파일 처리\n",
        "    if base_dir is None:\n",
        "        base_dir = zip_path.replace('.zip', '')\n",
        "\n",
        "    print(f\"📦 ZIP 파일 처리 중: {zip_path}\")\n",
        "\n",
        "    # ZIP 파일이 이미 압축 해제되어 있는지 확인\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(\"   🔄 ZIP 파일 압축 해제 중...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(os.path.dirname(base_dir))\n",
        "        print(\"   ✅ ZIP 파일 압축 해제 완료\")\n",
        "    else:\n",
        "        print(\"   ✅ 이미 압축 해제된 폴더 발견\")\n",
        "\n",
        "    # 이미지 파일들 찾기\n",
        "    print(\"🔍 이미지 파일들 탐색 중...\")\n",
        "    image_files = []\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                full_path = os.path.join(root, file)\n",
        "                image_files.append(full_path)\n",
        "\n",
        "    print(f\"   📷 총 {len(image_files)}개의 이미지 파일 발견\")\n",
        "\n",
        "    # 파일명에서 환자 ID 추출 및 매칭\n",
        "    print(\"🔗 환자 ID 매칭 중...\")\n",
        "    patient_data = {}\n",
        "    matched_count = 0\n",
        "    unmatched_files = []\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"이미지 파일 처리\"):\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        # 파일명에서 환자 ID 추출\n",
        "        file_id, _ = extract_identifier(filename)\n",
        "        if file_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excel 형태로 변환\n",
        "        excel_id = convert_file_id_to_excel_format(file_id)\n",
        "        if excel_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excel에서 해당 환자 찾기\n",
        "        patient_row = df[df.iloc[:, 0].astype(str).str.contains(excel_id, na=False)]\n",
        "\n",
        "        if len(patient_row) > 0:\n",
        "            patient_info = patient_row.iloc[0]\n",
        "            patient_id = str(patient_info.iloc[0])\n",
        "\n",
        "            # 환자 데이터 초기화 (처음 발견된 경우)\n",
        "            if patient_id not in patient_data:\n",
        "                patient_data[patient_id] = {\n",
        "                    'images': [],\n",
        "                    't_label': patient_info.get('t_label', 0),\n",
        "                    'recur_label': patient_info.get('recur_label', 0),\n",
        "                    'grade': patient_info.get('Grade', 'Unknown'),\n",
        "                    't_stage': patient_info.get('T-stage', 'Unknown'),\n",
        "                    'recurrence': patient_info.get('Recurrence', 'Unknown')\n",
        "                }\n",
        "\n",
        "            # 이미지 경로 추가\n",
        "            patient_data[patient_id]['images'].append(img_path)\n",
        "            matched_count += 1\n",
        "        else:\n",
        "            unmatched_files.append(filename)\n",
        "\n",
        "    print(f\"   ✅ 매칭 완료: {matched_count}개 파일 매칭\")\n",
        "    print(f\"   ⚠️  매칭 실패: {len(unmatched_files)}개 파일\")\n",
        "    print(f\"   👥 총 환자 수: {len(patient_data)}명\")\n",
        "\n",
        "    # 환자별 이미지 개수 통계\n",
        "    image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "    if image_counts:\n",
        "        print(f\"   📊 환자별 이미지 개수 - 평균: {np.mean(image_counts):.1f}개, \"\n",
        "              f\"최소: {min(image_counts)}개, 최대: {max(image_counts)}개\")\n",
        "\n",
        "    # 매칭되지 않은 파일 일부 출력 (디버깅용)\n",
        "    if unmatched_files:\n",
        "        print(f\"   📝 매칭 실패 파일 예시 (처음 5개):\")\n",
        "        for file in unmatched_files[:5]:\n",
        "            print(f\"      - {file}\")\n",
        "\n",
        "    print(\"✅ 데이터 로딩 및 매칭 완료!\")\n",
        "    return patient_data\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 2 완료: 데이터 처리 함수들 정의 완료!\")\n",
        "print(\"다음으로 Part 3에서 실제 데이터를 로딩합니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNOP6sVNUJ3L"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 3: 메가패치 처리 핵심 함수들\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsZVwwPtUJ3L"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 세 번째로 실행하세요 - FlexAttention의 핵심인 메가패치 처리 함수들을 정의합니다\n",
        "\n",
        "def split_megapatch_to_patches(megapatch_path, grid_size=4):\n",
        "    \"\"\"\n",
        "    🔪 STEP 1: 1024x1024 메가패치를 4x4=16개의 256x256 패치로 분할\n",
        "\n",
        "    FlexAttention 논문의 핵심 아이디어:\n",
        "    - 큰 이미지를 작은 패치들로 나누어 처리\n",
        "    - 각 패치는 동일한 크기로 정규화\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 메가패치 이미지 경로\n",
        "        grid_size (int): 그리드 크기 (4x4 = 16개 패치, 3x3 = 9개 패치 등)\n",
        "\n",
        "    Returns:\n",
        "        list: 16개의 256x256 패치들 (numpy arrays)\n",
        "        list: 각 패치의 위치 정보 [(i, j), ...]\n",
        "\n",
        "    Example:\n",
        "        patches, positions = split_megapatch_to_patches(\"image.jpg\", 4)\n",
        "        # patches[0]: 좌상단 패치, patches[15]: 우하단 패치\n",
        "        # positions[0]: (0, 0), positions[15]: (3, 3)\n",
        "    \"\"\"\n",
        "    # 1024x1024 메가패치 읽기\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"❌ 메가패치를 읽을 수 없습니다: {megapatch_path}\")\n",
        "\n",
        "    # BGR → RGB 변환 (OpenCV는 BGR, 우리는 RGB 사용)\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "    h, w = megapatch.shape[:2]\n",
        "\n",
        "    # 각 패치 크기 계산: 1024/4 = 256\n",
        "    patch_size = h // grid_size  # 256x256\n",
        "\n",
        "    patches = []      # 분할된 패치들을 저장할 리스트\n",
        "    positions = []    # 각 패치의 위치 정보를 저장할 리스트\n",
        "\n",
        "    # 4x4 그리드로 분할 (왼쪽 위부터 오른쪽 아래로)\n",
        "    for i in range(grid_size):        # 세로 방향 (행)\n",
        "        for j in range(grid_size):    # 가로 방향 (열)\n",
        "            # 패치의 시작점과 끝점 계산\n",
        "            y_start = i * patch_size      # 세로 시작 위치\n",
        "            x_start = j * patch_size      # 가로 시작 위치\n",
        "            y_end = y_start + patch_size  # 세로 끝 위치\n",
        "            x_end = x_start + patch_size  # 가로 끝 위치\n",
        "\n",
        "            # 256x256 패치 추출\n",
        "            patch = megapatch[y_start:y_end, x_start:x_end]\n",
        "            patches.append(patch)\n",
        "            positions.append((i, j))  # (행, 열) 위치 저장\n",
        "\n",
        "    return patches, positions\n",
        "\n",
        "def create_three_streams_from_patch(patch_256, megapatch_1024):\n",
        "    \"\"\"\n",
        "    🎯 STEP 2: 각 256x256 패치로부터 3-stream 생성\n",
        "\n",
        "    FlexAttention의 3-stream 구조:\n",
        "    1. LR (Low Resolution): 빠른 처리를 위한 64x64 저해상도\n",
        "    2. HR (High Resolution): 세밀한 분석을 위한 256x256 고해상도\n",
        "    3. Global: 전체 맥락을 위한 64x64 글로벌 컨텍스트\n",
        "\n",
        "    Args:\n",
        "        patch_256 (numpy.ndarray): 256x256 패치 (numpy array)\n",
        "        megapatch_1024 (numpy.ndarray): 전체 1024x1024 메가패치 (Global 생성용)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr': 64x64 LR 패치,\n",
        "            'hr': 256x256 HR 패치 (원본),\n",
        "            'global': 64x64 Global 컨텍스트\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 1. LR 스트림: 256x256 → 64x64 다운샘플링\n",
        "    # INTER_AREA: 축소시 품질이 좋은 보간법\n",
        "    lr_patch =  patch_256.copy()  # 256x256 그대로\n",
        "\n",
        "    # 2. HR 스트림: 256x256 원본 그대로 사용\n",
        "    # 세밀한 특징을 분석하기 위해 원본 해상도 유지\n",
        "    hr_patch = patch_256.copy()\n",
        "\n",
        "    # 3. Global 스트림: 전체 1024x1024 → 64x64 (매우 작은 overview)\n",
        "    # 전체적인 구조와 맥락 정보를 제공\n",
        "    global_context = cv2.resize(megapatch_1024, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return {\n",
        "        'lr': lr_patch,         # 64x64 LR (빠른 처리용)\n",
        "        'hr': hr_patch,         # 256x256 HR (세밀한 분석용)\n",
        "        'global': global_context # 64x64 Global (맥락 정보용)\n",
        "    }\n",
        "\n",
        "def process_megapatch_complete(megapatch_path, patches_per_megapatch=16):\n",
        "    \"\"\"\n",
        "    🚀 STEP 3: 메가패치 전체 처리 파이프라인\n",
        "\n",
        "    전체 과정:\n",
        "    1024x1024 메가패치 → 16개 패치로 분할 → 각각 3-stream 생성\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 메가패치 경로\n",
        "        patches_per_megapatch (int): 메가패치당 패치 개수 (16 or 8 등)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr_patches': 16개의 64x64 LR 패치들,\n",
        "            'hr_patches': 16개의 256x256 HR 패치들,\n",
        "            'global_tokens': 16개의 64x64 Global 토큰들 (모두 동일),\n",
        "            'positions': 패치 위치 정보 [(i,j), ...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 원본 메가패치 읽기\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"❌ 메가패치를 읽을 수 없습니다: {megapatch_path}\")\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # patches_per_megapatch에 따라 grid_size 결정\n",
        "    if patches_per_megapatch == 16:\n",
        "        grid_size = 4    # 4x4 = 16\n",
        "    elif patches_per_megapatch == 9:\n",
        "        grid_size = 3    # 3x3 = 9\n",
        "    elif patches_per_megapatch == 8:\n",
        "        # 8개는 특별 처리: 4x4에서 8개만 선택\n",
        "        grid_size = 4\n",
        "        use_subset = True\n",
        "    else:\n",
        "        grid_size = int(math.sqrt(patches_per_megapatch))\n",
        "        use_subset = False\n",
        "\n",
        "    # STEP 1: 1024x1024 → 여러개 256x256 패치로 분할\n",
        "    patches_256, positions = split_megapatch_to_patches(megapatch_path, grid_size)\n",
        "\n",
        "    # 8개만 사용하는 경우: 체스판 패턴으로 선택 (균등 분포)\n",
        "    if patches_per_megapatch == 8 and len(patches_256) == 16:\n",
        "        # 체스판 패턴: (0,0), (0,2), (1,1), (1,3), (2,0), (2,2), (3,1), (3,3)\n",
        "        selected_indices = []\n",
        "        for i, (row, col) in enumerate(positions):\n",
        "            if (row + col) % 2 == 0:  # 체스판 패턴\n",
        "                selected_indices.append(i)\n",
        "\n",
        "        # 8개만 선택\n",
        "        selected_indices = selected_indices[:patches_per_megapatch]\n",
        "        patches_256 = [patches_256[i] for i in selected_indices]\n",
        "        positions = [positions[i] for i in selected_indices]\n",
        "\n",
        "    # STEP 2: 각 패치별로 3-stream 생성\n",
        "    lr_patches = []       # LR 패치들을 저장할 리스트\n",
        "    hr_patches = []       # HR 패치들을 저장할 리스트\n",
        "    global_tokens = []    # Global 토큰들을 저장할 리스트\n",
        "\n",
        "    for patch_256 in patches_256:\n",
        "        # 각 패치에 대해 3-stream 생성\n",
        "        streams = create_three_streams_from_patch(patch_256, megapatch)\n",
        "\n",
        "        lr_patches.append(streams['lr'])        # 64x64 LR\n",
        "        hr_patches.append(streams['hr'])        # 256x256 HR\n",
        "        global_tokens.append(streams['global']) # 64x64 Global\n",
        "\n",
        "        # 참고: global_tokens는 모두 동일한 전체 이미지의 축소본입니다\n",
        "\n",
        "    return {\n",
        "        'lr_patches': lr_patches,     # patches_per_megapatch개 × 64x64\n",
        "        'hr_patches': hr_patches,     # patches_per_megapatch개 × 256x256\n",
        "        'global_tokens': global_tokens, # patches_per_megapatch개 × 64x64 (모두 동일)\n",
        "        'positions': positions        # patches_per_megapatch개 위치 정보\n",
        "    }\n",
        "\n",
        "# 테스트 및 시각화 함수\n",
        "def visualize_patch_splitting(megapatch_path, save_path=None):\n",
        "    \"\"\"\n",
        "    📊 메가패치 분할 과정을 시각화하는 함수 (디버깅 및 확인용)\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 시각화할 메가패치 경로\n",
        "        save_path (str, optional): 결과 이미지 저장 경로\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 메가패치 처리\n",
        "        processed = process_megapatch_complete(megapatch_path)\n",
        "\n",
        "        # 시각화 설정\n",
        "        fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
        "        fig.suptitle(f'메가패치 분할 결과: {os.path.basename(megapatch_path)}', fontsize=16)\n",
        "\n",
        "        # 원본 메가패치 표시\n",
        "        megapatch = cv2.imread(megapatch_path)\n",
        "        megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "        axes[0, 0].imshow(megapatch)\n",
        "        axes[0, 0].set_title('원본 메가패치\\n(1024x1024)', fontsize=10)\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # 처음 5개 패치의 3-stream 표시\n",
        "        for i in range(min(5, len(processed['lr_patches']))):\n",
        "            row = i // 5 + 1\n",
        "            col_start = (i % 5) + 1\n",
        "\n",
        "            # LR 패치 (64x64)\n",
        "            axes[0, col_start].imshow(processed['lr_patches'][i])\n",
        "            axes[0, col_start].set_title(f'LR {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[0, col_start].axis('off')\n",
        "\n",
        "            # HR 패치 (256x256)\n",
        "            axes[1, col_start].imshow(processed['hr_patches'][i])\n",
        "            axes[1, col_start].set_title(f'HR {i+1}\\n(256x256)', fontsize=8)\n",
        "            axes[1, col_start].axis('off')\n",
        "\n",
        "            # Global 토큰 (64x64)\n",
        "            axes[2, col_start].imshow(processed['global_tokens'][i])\n",
        "            axes[2, col_start].set_title(f'Global {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[2, col_start].axis('off')\n",
        "\n",
        "        # 빈 subplot들 숨기기\n",
        "        for i in range(4):\n",
        "            for j in range(6):\n",
        "                if i > 2 or (i == 0 and j == 0) or (i > 0 and j == 0):\n",
        "                    continue\n",
        "                if not axes[i, j].has_data():\n",
        "                    axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"✅ 시각화 결과 저장: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # 통계 정보 출력\n",
        "        print(f\"📊 메가패치 처리 결과:\")\n",
        "        print(f\"   - LR 패치 개수: {len(processed['lr_patches'])}개 (각 64x64)\")\n",
        "        print(f\"   - HR 패치 개수: {len(processed['hr_patches'])}개 (각 256x256)\")\n",
        "        print(f\"   - Global 토큰 개수: {len(processed['global_tokens'])}개 (각 64x64)\")\n",
        "        print(f\"   - 위치 정보: {processed['positions'][:5]}... (처음 5개)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 시각화 중 오류 발생: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 3 완료: 메가패치 처리 핵심 함수들 정의 완료!\")\n",
        "print(\"이제 1024x1024 이미지를 16개의 3-stream 패치로 분할할 수 있습니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS5SQBHRUJ3L"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 4: Feature Extractor와 HR Selection\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5-YAFexUJ3L"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 네 번째로 실행하세요 - ResNet 기반 feature extractor와 논문의 threshold 방식 HR selection을 구현합니다\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    🔬 ResNet18 기반 Feature Extractor\n",
        "\n",
        "    역할:\n",
        "    - 64x64 이미지용 (LR, Global streams)\n",
        "    - 256x256 이미지용 (HR stream)\n",
        "    - 이미지를 고정 크기 feature vector로 변환\n",
        "\n",
        "    선택지:\n",
        "    - ResNet18: 안정적이고 검증된 성능 (추천)\n",
        "    - MobileNetV3: 더 빠르지만 성능 약간 낮음\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, model_type='resnet18', pretrained=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): 출력 feature 차원 (256 or 384)\n",
        "            model_type (str): 사용할 백본 모델 ('resnet18', 'mobilenet', 'efficientnet')\n",
        "            pretrained (bool): ImageNet 사전훈련 가중치 사용 여부\n",
        "        \"\"\"\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.model_type = model_type\n",
        "\n",
        "        # 백본 모델 선택 및 설정\n",
        "        if model_type == 'resnet18':\n",
        "            # ResNet18: 안정적이고 널리 사용됨 (11M parameters)\n",
        "            resnet = models.resnet18(pretrained=pretrained)\n",
        "            self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # avgpool, fc 제거\n",
        "            backbone_out_dim = 512\n",
        "\n",
        "        elif model_type == 'mobilenet':\n",
        "            # MobileNetV3-Small: 빠르고 경량 (2.5M parameters)\n",
        "            from torchvision.models import mobilenet_v3_small\n",
        "            mobilenet = mobilenet_v3_small(pretrained=pretrained)\n",
        "            self.backbone = mobilenet.features\n",
        "            backbone_out_dim = 576\n",
        "\n",
        "        elif model_type == 'efficientnet':\n",
        "            # EfficientNet-B0: 효율적이고 성능 좋음 (5.3M parameters)\n",
        "            from torchvision.models import efficientnet_b0\n",
        "            efficientnet = efficientnet_b0(pretrained=pretrained)\n",
        "            self.backbone = efficientnet.features\n",
        "            backbone_out_dim = 1280\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"지원하지 않는 모델 타입: {model_type}\")\n",
        "\n",
        "        # Global Average Pooling: spatial dimensions를 1x1로 축소\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Feature projection: backbone output → 원하는 feature dimension\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(backbone_out_dim, feature_dim),\n",
        "            nn.LayerNorm(feature_dim),  # Layer Normalization으로 안정성 향상\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1)             # 10% 드롭아웃으로 overfitting 방지\n",
        "        )\n",
        "\n",
        "        print(f\"✅ {model_type.upper()} Feature Extractor 초기화 완료\")\n",
        "        print(f\"   - 백본 출력 차원: {backbone_out_dim}\")\n",
        "        print(f\"   - 최종 feature 차원: {feature_dim}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: 이미지 배치를 feature vectors로 변환\n",
        "\n",
        "        Args:\n",
        "            x: [batch_size, 3, H, W] - RGB 이미지 배치\n",
        "               H, W는 64 (LR, Global) 또는 256 (HR)\n",
        "\n",
        "        Returns:\n",
        "            [batch_size, feature_dim] - 추출된 feature vectors\n",
        "        \"\"\"\n",
        "        # 1. 백본 네트워크를 통한 feature map 추출\n",
        "        features = self.backbone(x)      # [B, C, H', W'] - 예: [B, 512, H'/32, W'/32]\n",
        "\n",
        "        # 2. Global Average Pooling으로 spatial dimensions 축소\n",
        "        pooled = self.avgpool(features)  # [B, C, 1, 1]\n",
        "\n",
        "        # 3. Flatten: [B, C, 1, 1] → [B, C]\n",
        "        flattened = pooled.view(pooled.size(0), -1)  # [B, backbone_out_dim]\n",
        "\n",
        "        # 4. Projection을 통해 원하는 차원으로 변환\n",
        "        projected = self.projection(flattened)       # [B, feature_dim]\n",
        "\n",
        "        return projected\n",
        "\n",
        "\n",
        "class ThresholdBasedHRSelector(nn.Module):\n",
        "    \"\"\"\n",
        "    🎯 논문의 정확한 방식: Threshold 기반 HR Feature Selection\n",
        "\n",
        "    FlexAttention 논문의 핵심 아이디어:\n",
        "    - LR attention scores에서 threshold를 계산\n",
        "    - Threshold 이상인 패치들만 HR로 선택\n",
        "    - 약 10% 정도가 선택되도록 동적 조정\n",
        "    - Top-K 고정 선택이 아닌 실제 중요도 기반 선택\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target_selection_ratio=0.1, min_patches=1, max_patches=4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            target_selection_ratio (float): 목표 선택 비율 (0.1 = 약 10%)\n",
        "            min_patches (int): 최소 선택 패치 개수 (너무 적으면 강제 선택)\n",
        "            max_patches (int): 최대 선택 패치 개수 (너무 많으면 제한)\n",
        "        \"\"\"\n",
        "        super(ThresholdBasedHRSelector, self).__init__()\n",
        "        self.target_selection_ratio = target_selection_ratio\n",
        "        self.min_patches = min_patches\n",
        "        self.max_patches = max_patches\n",
        "\n",
        "        print(f\"✅ Threshold 기반 HR Selector 초기화\")\n",
        "        print(f\"   - 목표 선택 비율: {target_selection_ratio*100:.1f}%\")\n",
        "        print(f\"   - 선택 범위: {min_patches}~{max_patches}개\")\n",
        "\n",
        "    def forward(self, lr_attention_scores, hr_features):\n",
        "        \"\"\"\n",
        "        Threshold 기반으로 중요한 HR features만 선택\n",
        "\n",
        "        Args:\n",
        "            lr_attention_scores: [batch_size, 16] - LR patches의 attention scores\n",
        "            hr_features: [batch_size, 16, feature_dim] - HR patch features\n",
        "\n",
        "        Returns:\n",
        "            selected_hr_features: [batch_size, max_patches, feature_dim] - 선택된 HR features\n",
        "            selection_masks: [batch_size, 16] - binary selection mask (시각화용)\n",
        "            thresholds: [batch_size] - 사용된 threshold 값들 (분석용)\n",
        "        \"\"\"\n",
        "        batch_size, num_patches, feature_dim = hr_features.shape\n",
        "\n",
        "        selected_hr_features = []  # 선택된 HR features를 저장할 리스트\n",
        "        selection_masks = []       # 선택 마스크를 저장할 리스트\n",
        "        thresholds = []           # 사용된 threshold들을 저장할 리스트\n",
        "\n",
        "        # 배치의 각 샘플에 대해 개별 처리\n",
        "        for b in range(batch_size):\n",
        "            att_scores = lr_attention_scores[b]  # [16] - 이 샘플의 attention scores\n",
        "\n",
        "            # Step 1: Adaptive threshold 계산\n",
        "            threshold = self._compute_adaptive_threshold(att_scores)\n",
        "\n",
        "            # Step 2: Threshold 적용하여 패치 선택\n",
        "            mask = att_scores > threshold\n",
        "            selected_indices = torch.where(mask)[0]  # threshold 이상인 패치들의 인덱스\n",
        "\n",
        "            num_selected = len(selected_indices)\n",
        "\n",
        "            # Step 3: 선택된 패치 수 검증 및 조정\n",
        "            if num_selected < self.min_patches:\n",
        "                # 너무 적게 선택된 경우: 강제로 최소 개수만큼 선택\n",
        "                _, top_indices = torch.topk(att_scores, self.min_patches)\n",
        "                selected_indices = top_indices\n",
        "                threshold = att_scores[top_indices[-1]]  # 새로운 threshold\n",
        "\n",
        "            elif num_selected > self.max_patches:\n",
        "                # 너무 많이 선택된 경우: 상위 max_patches개만 선택\n",
        "                selected_scores = att_scores[selected_indices]\n",
        "                _, top_within_selected = torch.topk(selected_scores, self.max_patches)\n",
        "                selected_indices = selected_indices[top_within_selected]\n",
        "                threshold = att_scores[selected_indices[-1]]  # 새로운 threshold\n",
        "\n",
        "            # Step 4: 선택된 HR features 추출\n",
        "            selected_features = hr_features[b, selected_indices]  # [num_selected, feature_dim]\n",
        "\n",
        "            # Step 5: 고정 크기로 패딩 (배치 처리를 위해)\n",
        "            if len(selected_indices) < self.max_patches:\n",
        "                padding_size = self.max_patches - len(selected_indices)\n",
        "                padding = torch.zeros(padding_size, feature_dim, device=hr_features.device)\n",
        "                selected_features = torch.cat([selected_features, padding], dim=0)\n",
        "\n",
        "            selected_hr_features.append(selected_features)\n",
        "\n",
        "            # Step 6: Binary mask 생성 (시각화 및 분석용)\n",
        "            binary_mask = torch.zeros_like(att_scores)\n",
        "            if len(selected_indices) > 0:\n",
        "                binary_mask[selected_indices] = 1.0\n",
        "            selection_masks.append(binary_mask)\n",
        "\n",
        "            thresholds.append(threshold)\n",
        "\n",
        "        # 리스트들을 텐서로 변환\n",
        "        selected_hr_features = torch.stack(selected_hr_features)  # [B, max_patches, feature_dim]\n",
        "        selection_masks = torch.stack(selection_masks)            # [B, 16]\n",
        "        thresholds = torch.stack(thresholds)                      # [B]\n",
        "\n",
        "        return selected_hr_features, selection_masks, thresholds\n",
        "\n",
        "    def _compute_adaptive_threshold(self, attention_scores):\n",
        "        \"\"\"\n",
        "        적응적 threshold 계산 - 여러 방법 중 가장 적절한 것 선택\n",
        "\n",
        "        Args:\n",
        "            attention_scores: [16] - 하나의 샘플에 대한 attention scores\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 계산된 threshold 값\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Method 1: Otsu threshold (이진화에서 사용하는 최적 분할점)\n",
        "            # 가장 좋은 방법이지만 sklearn 필요\n",
        "            scores_np = attention_scores.detach().cpu().numpy()\n",
        "            threshold_val = threshold_otsu(scores_np)\n",
        "            return torch.tensor(threshold_val, device=attention_scores.device)\n",
        "\n",
        "        except:\n",
        "            # Method 2: Percentile-based threshold (Fallback)\n",
        "            # 상위 target_selection_ratio*2 정도가 선택되도록\n",
        "            percentile = 1.0 - (self.target_selection_ratio * 2)  # 80th percentile for 10% target\n",
        "            threshold_val = torch.quantile(attention_scores, percentile)\n",
        "            return threshold_val\n",
        "\n",
        "    def get_selection_statistics(self, selection_masks):\n",
        "        \"\"\"\n",
        "        선택 통계 정보 반환 (디버깅 및 모니터링용)\n",
        "\n",
        "        Args:\n",
        "            selection_masks: [batch_size, 16] - binary selection masks\n",
        "\n",
        "        Returns:\n",
        "            dict: 선택 통계 정보\n",
        "        \"\"\"\n",
        "        num_selected_per_sample = selection_masks.sum(dim=1)  # [batch_size]\n",
        "\n",
        "        stats = {\n",
        "            'mean_selected': num_selected_per_sample.float().mean().item(),\n",
        "            'min_selected': num_selected_per_sample.min().item(),\n",
        "            'max_selected': num_selected_per_sample.max().item(),\n",
        "            'selection_ratio': (num_selected_per_sample.float() / selection_masks.shape[1]).mean().item(),\n",
        "            'std_selected': num_selected_per_sample.float().std().item()\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "\n",
        "# Feature Extractor 성능 비교 함수\n",
        "def compare_feature_extractors():\n",
        "    \"\"\"\n",
        "    🔬 다양한 Feature Extractor들의 성능과 속도 비교\n",
        "    실제 선택에 도움을 주는 벤치마크\n",
        "    \"\"\"\n",
        "    print(\"🔬 Feature Extractor 성능 비교\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 테스트용 가상 데이터\n",
        "    dummy_lr = torch.randn(4, 3, 64, 64)    # LR 패치들\n",
        "    dummy_hr = torch.randn(4, 3, 256, 256)  # HR 패치들\n",
        "\n",
        "    extractors = {\n",
        "        'ResNet18': ResNetFeatureExtractor(feature_dim=256, model_type='resnet18'),\n",
        "        'MobileNetV3': ResNetFeatureExtractor(feature_dim=256, model_type='mobilenet'),\n",
        "        'EfficientNet-B0': ResNetFeatureExtractor(feature_dim=256, model_type='efficientnet')\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, extractor in extractors.items():\n",
        "        print(f\"\\n📊 {name} 테스트 중...\")\n",
        "\n",
        "        # 파라미터 수 계산\n",
        "        total_params = sum(p.numel() for p in extractor.parameters())\n",
        "        trainable_params = sum(p.numel() for p in extractor.parameters() if p.requires_grad)\n",
        "\n",
        "        # 속도 측정 (LR 패치)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10번 반복 측정\n",
        "                _ = extractor(dummy_lr)\n",
        "        lr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        # 속도 측정 (HR 패치)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10번 반복 측정\n",
        "                _ = extractor(dummy_hr)\n",
        "        hr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        results[name] = {\n",
        "            'total_params': total_params,\n",
        "            'trainable_params': trainable_params,\n",
        "            'lr_time_ms': lr_time * 1000,\n",
        "            'hr_time_ms': hr_time * 1000\n",
        "        }\n",
        "\n",
        "        print(f\"   파라미터 수: {total_params/1e6:.1f}M\")\n",
        "        print(f\"   LR 처리 속도: {lr_time*1000:.1f}ms\")\n",
        "        print(f\"   HR 처리 속도: {hr_time*1000:.1f}ms\")\n",
        "\n",
        "    # 추천 출력\n",
        "    print(f\"\\n🎯 추천:\")\n",
        "    print(f\"   - 안정성 우선: ResNet18 (검증된 성능)\")\n",
        "    print(f\"   - 속도 우선: MobileNetV3 (가장 빠름)\")\n",
        "    print(f\"   - 밸런스: EfficientNet-B0 (성능-속도 절충)\")\n",
        "    print(f\"   - 2일 안에 완주: ResNet18 또는 MobileNetV3\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# 사용법 예시\n",
        "def example_usage():\n",
        "    \"\"\"Feature Extractor와 HR Selector 사용 예시\"\"\"\n",
        "    print(\"💡 사용 예시:\")\n",
        "\n",
        "    # Feature Extractor 생성\n",
        "    feature_extractor = ResNetFeatureExtractor(\n",
        "        feature_dim=256,\n",
        "        model_type='resnet18',  # 'resnet18', 'mobilenet', 'efficientnet' 중 선택\n",
        "        pretrained=True\n",
        "    )\n",
        "\n",
        "    # HR Selector 생성\n",
        "    hr_selector = ThresholdBasedHRSelector(\n",
        "        target_selection_ratio=0.1,  # 10% 선택 목표\n",
        "        min_patches=1,               # 최소 1개\n",
        "        max_patches=4                # 최대 4개\n",
        "    )\n",
        "\n",
        "    print(\"✅ 모델 컴포넌트들이 준비되었습니다!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 4 완료: Feature Extractor와 HR Selector 정의 완료!\")\n",
        "print(\"ResNet18 vs MobileNet vs EfficientNet 중 선택 가능합니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4jZt1HEUJ3M"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 5: 실제 데이터 로딩 (로컬 경로)\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaS2aMbTUJ3M"
      },
      "outputs": [],
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 5: 실제 데이터 로딩 (로컬 경로)\n",
        "# ========================================================================\n",
        "\n",
        "# 이 셀을 다섯 번째로 실행하세요 - 실제 데이터를 로딩하고 환자별로 구성합니다\n",
        "\n",
        "# 🏠 로컬 경로 설정 (집 컴퓨터용) - 이미 압축 해제됨\n",
        "zip_path = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710.zip\"  # 원본 ZIP (참조용)\n",
        "excel_path = r\"C:\\Users\\ehdwk\\Downloads\\MIL_TURB_240918_Modified.xlsx\"\n",
        "base_dir = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\"  # 이미 압축 해제된 폴더\n",
        "\n",
        "# 📁 작업 디렉토리 설정 (체크포인트, 로그, 결과 저장용)\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "checkpoint_dir = os.path.join(work_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(work_dir, \"logs\")\n",
        "cache_dir = os.path.join(work_dir, \"cache\")\n",
        "result_dir = os.path.join(work_dir, \"results\")\n",
        "\n",
        "# 필요한 디렉토리들 생성\n",
        "for directory in [work_dir, checkpoint_dir, log_dir, cache_dir, result_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    print(f\"📁 디렉토리 준비: {directory}\")\n",
        "\n",
        "print(f\"\\n🏠 로컬 환경 설정 완료!\")\n",
        "print(f\"   ZIP 파일: {zip_path}\")\n",
        "print(f\"   Excel 파일: {excel_path}\")\n",
        "print(f\"   작업 디렉토리: {work_dir}\")\n",
        "\n",
        "# 파일 존재 확인\n",
        "print(f\"\\n🔍 파일/폴더 존재 확인:\")\n",
        "print(f\"   압축 해제된 폴더 존재: {os.path.exists(base_dir)}\")\n",
        "print(f\"   Excel 파일 존재: {os.path.exists(excel_path)}\")\n",
        "\n",
        "if not os.path.exists(base_dir):\n",
        "    print(f\"❌ 압축 해제된 폴더를 찾을 수 없습니다: {base_dir}\")\n",
        "    print(f\"   경로를 확인해주세요!\")\n",
        "\n",
        "if not os.path.exists(excel_path):\n",
        "    print(f\"❌ Excel 파일을 찾을 수 없습니다: {excel_path}\")\n",
        "    print(f\"   경로를 확인해주세요!\")\n",
        "\n",
        "# 압축 해제된 폴더의 내용 확인\n",
        "if os.path.exists(base_dir):\n",
        "    folder_contents = os.listdir(base_dir)\n",
        "    print(f\"📁 폴더 내용 (처음 10개): {folder_contents[:10]}\")\n",
        "    print(f\"📂 총 파일/폴더 개수: {len(folder_contents)}개\")\n",
        "\n",
        "# 실제 데이터 로딩 실행\n",
        "print(f\"\\n🚀 데이터 로딩 시작...\")\n",
        "log_gpu_memory(\"데이터 로딩 전\")\n",
        "\n",
        "try:\n",
        "    # Part 2에서 정의한 함수 사용\n",
        "    patient_data = load_and_match_data(\n",
        "        zip_path=zip_path,\n",
        "        excel_path=excel_path,\n",
        "        base_dir=base_dir\n",
        "    )\n",
        "\n",
        "    print(f\"\\n✅ 데이터 로딩 완료!\")\n",
        "    print(f\"   총 환자 수: {len(patient_data)}명\")\n",
        "\n",
        "    # 환자별 이미지 개수 통계\n",
        "    image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "    if image_counts:\n",
        "        print(f\"   환자별 이미지 개수:\")\n",
        "        print(f\"     - 평균: {np.mean(image_counts):.1f}개\")\n",
        "        print(f\"     - 중간값: {np.median(image_counts):.1f}개\")\n",
        "        print(f\"     - 최소: {min(image_counts)}개\")\n",
        "        print(f\"     - 최대: {max(image_counts)}개\")\n",
        "        print(f\"     - 75% 지점: {np.percentile(image_counts, 75):.1f}개\")\n",
        "\n",
        "    # 라벨 분포 확인\n",
        "    t_labels = [info.get('t_label', 0) for info in patient_data.values()]\n",
        "    recur_labels = [info.get('recur_label', 0) for info in patient_data.values()]\n",
        "\n",
        "    print(f\"\\n📊 라벨 분포:\")\n",
        "    print(f\"   T-stage - 저위험(0): {t_labels.count(0)}명, 고위험(1): {t_labels.count(1)}명\")\n",
        "    print(f\"   재발 - 없음(0): {recur_labels.count(0)}명, 있음(1): {recur_labels.count(1)}명\")\n",
        "\n",
        "    # 샘플 환자 정보 출력\n",
        "    sample_patient_id = list(patient_data.keys())[0]\n",
        "    sample_info = patient_data[sample_patient_id]\n",
        "    print(f\"\\n👤 샘플 환자 정보 ({sample_patient_id}):\")\n",
        "    print(f\"   이미지 개수: {len(sample_info['images'])}개\")\n",
        "    print(f\"   T-stage: {sample_info.get('t_stage', 'Unknown')}\")\n",
        "    print(f\"   재발: {sample_info.get('recurrence', 'Unknown')}\")\n",
        "    print(f\"   첫 번째 이미지: {sample_info['images'][0] if sample_info['images'] else 'None'}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 데이터 로딩 중 오류 발생: {e}\")\n",
        "    patient_data = {}\n",
        "\n",
        "log_gpu_memory(\"데이터 로딩 후\")\n",
        "\n",
        "# 데이터 저장 (나중에 빠르게 로딩하기 위해)\n",
        "if patient_data:\n",
        "    data_save_path = os.path.join(cache_dir, \"patient_data.pkl\")\n",
        "    try:\n",
        "        with open(data_save_path, 'wb') as f:\n",
        "            pickle.dump(patient_data, f)\n",
        "        print(f\"\\n💾 환자 데이터 저장 완료: {data_save_path}\")\n",
        "        print(f\"   다음에는 이 파일로 빠르게 로딩 가능!\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  데이터 저장 실패: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 5 완료: 실제 데이터 로딩 및 전처리 완료!\")\n",
        "print(f\"환자 데이터가 준비되었습니다: {len(patient_data) if patient_data else 0}명\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# Part 5에 추가\n",
        "patient_ids = list(patient_data.keys())[:20]  # 처음 20명만\n",
        "patient_data = {pid: patient_data[pid] for pid in patient_ids}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiBUd9i7UJ3M"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 6: 체크포인트 시스템 & Hierarchical Self-Attention\n",
        "# ========================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P56JKxAdUJ3M"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class CheckpointManager:\n",
        "    \"\"\"\n",
        "    🔄 체크포인트 관리 시스템\n",
        "\n",
        "    기능:\n",
        "    - 매 epoch마다 모델 상태 자동 저장\n",
        "    - 훈련 중단시 마지막 지점부터 재시작 가능\n",
        "    - 최고 성능 모델 별도 저장\n",
        "    - 훈련 로그 및 통계 저장\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir, max_keep=5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            checkpoint_dir (str): 체크포인트 저장 디렉토리\n",
        "            max_keep (int): 최대 보관할 체크포인트 개수 (오래된 것부터 삭제)\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.max_keep = max_keep\n",
        "        self.best_score = 0.0\n",
        "        self.training_log = []\n",
        "\n",
        "        # 디렉토리 생성\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        print(f\"📁 체크포인트 매니저 초기화: {checkpoint_dir}\")\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, fold,\n",
        "                       train_loss, val_metrics=None, is_best=False):\n",
        "        \"\"\"\n",
        "        체크포인트 저장 (매 epoch마다 호출)\n",
        "\n",
        "        Args:\n",
        "            model: 훈련 중인 모델\n",
        "            optimizer: 옵티마이저\n",
        "            scheduler: 스케줄러\n",
        "            epoch: 현재 epoch\n",
        "            fold: 현재 fold 번호\n",
        "            train_loss: 훈련 loss\n",
        "            val_metrics: 검증 메트릭들 (dict)\n",
        "            is_best: 최고 성능 모델인지 여부\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # 체크포인트 정보\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.module.state_dict() if hasattr(model, 'module') else model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp,\n",
        "            'best_score': self.best_score\n",
        "        }\n",
        "\n",
        "        # 정규 체크포인트 저장\n",
        "        checkpoint_path = os.path.join(\n",
        "            self.checkpoint_dir,\n",
        "            f\"checkpoint_fold{fold}_epoch{epoch:03d}_{timestamp}.pt\"\n",
        "        )\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "        # 최신 체크포인트로 링크 (재시작 시 사용)\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        # 최고 성능 모델 별도 저장\n",
        "        if is_best:\n",
        "            best_path = os.path.join(self.checkpoint_dir, f\"best_model_fold{fold}.pt\")\n",
        "            torch.save(checkpoint, best_path)\n",
        "            self.best_score = val_metrics.get('f1', 0.0) if val_metrics else 0.0\n",
        "            print(f\"🏆 새로운 최고 성능 모델 저장! F1: {self.best_score:.4f}\")\n",
        "\n",
        "        # 훈련 로그 업데이트\n",
        "        log_entry = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "        self.training_log.append(log_entry)\n",
        "\n",
        "        # 로그 파일 저장\n",
        "        log_path = os.path.join(self.checkpoint_dir, f\"training_log_fold{fold}.json\")\n",
        "        with open(log_path, 'w') as f:\n",
        "            json.dump(self.training_log, f, indent=2)\n",
        "\n",
        "        print(f\"💾 체크포인트 저장: Fold {fold}, Epoch {epoch}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # 오래된 체크포인트 정리\n",
        "        self._cleanup_old_checkpoints(fold)\n",
        "\n",
        "    def _cleanup_old_checkpoints(self, fold):\n",
        "        \"\"\"오래된 체크포인트 파일들 정리\"\"\"\n",
        "        import glob\n",
        "\n",
        "        # 해당 fold의 체크포인트 파일들 찾기\n",
        "        pattern = os.path.join(self.checkpoint_dir, f\"checkpoint_fold{fold}_*.pt\")\n",
        "        checkpoints = glob.glob(pattern)\n",
        "\n",
        "        # 생성 시간 순으로 정렬\n",
        "        checkpoints.sort(key=os.path.getctime)\n",
        "\n",
        "        # max_keep 개수를 초과하면 오래된 것부터 삭제\n",
        "        while len(checkpoints) > self.max_keep:\n",
        "            old_checkpoint = checkpoints.pop(0)\n",
        "            try:\n",
        "                os.remove(old_checkpoint)\n",
        "                print(f\"🗑️  오래된 체크포인트 삭제: {os.path.basename(old_checkpoint)}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    def load_latest_checkpoint(self, fold):\n",
        "        \"\"\"\n",
        "        최신 체크포인트 로딩 (재시작 시 사용)\n",
        "\n",
        "        Args:\n",
        "            fold: 로딩할 fold 번호\n",
        "\n",
        "        Returns:\n",
        "            dict or None: 체크포인트 데이터, 없으면 None\n",
        "        \"\"\"\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "\n",
        "        if os.path.exists(latest_path):\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            print(f\"📂 체크포인트 로딩: Fold {fold}, Epoch {checkpoint['epoch']}\")\n",
        "            return checkpoint\n",
        "        else:\n",
        "            print(f\"📂 체크포인트 없음: Fold {fold} (처음부터 시작)\")\n",
        "            return None\n",
        "\n",
        "\n",
        "class HierarchicalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    🎯 FlexAttention 논문의 핵심: Hierarchical Self-Attention\n",
        "\n",
        "    핵심 아이디어:\n",
        "    - 일반 Self-Attention: O(n²) - 모든 토큰이 모든 토큰과 상호작용\n",
        "    - Hierarchical: O(n×M) - 선택된 HR 토큰만 상호작용 (M << n)\n",
        "    - 계산량 대폭 감소하면서 성능 유지!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_heads=4, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): feature 차원 (256 추천, 384는 메모리 많이 사용)\n",
        "            num_heads (int): attention head 개수 (4 추천, 6은 메모리 많이 사용)\n",
        "            dropout (float): 드롭아웃 비율\n",
        "        \"\"\"\n",
        "        super(HierarchicalSelfAttention, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = feature_dim // num_heads\n",
        "\n",
        "        # feature_dim이 num_heads로 나누어떨어지는지 확인\n",
        "        assert feature_dim % num_heads == 0, f\"feature_dim({feature_dim})이 num_heads({num_heads})로 나누어떨어지지 않습니다!\"\n",
        "\n",
        "        # 🔵 일반 hidden states용 projections (LR + Global + CLS tokens)\n",
        "        self.q_proj = nn.Linear(feature_dim, feature_dim)  # Query projection\n",
        "        self.k_proj = nn.Linear(feature_dim, feature_dim)  # Key projection\n",
        "        self.v_proj = nn.Linear(feature_dim, feature_dim)  # Value projection\n",
        "\n",
        "        # 🔴 HR features 전용 projections (논문의 W'_K, W'_V)\n",
        "        # 중요: HR features는 별도의 projection을 사용!\n",
        "        self.k_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_K for HR\n",
        "        self.v_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_V for HR\n",
        "\n",
        "        # 출력 projection\n",
        "        self.out_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = math.sqrt(self.head_dim)  # attention scaling factor\n",
        "\n",
        "        print(f\"✅ Hierarchical Self-Attention 초기화\")\n",
        "        print(f\"   - Feature dim: {feature_dim}, Heads: {num_heads}, Head dim: {self.head_dim}\")\n",
        "\n",
        "    def forward(self, hidden_states, selected_hr_features):\n",
        "        \"\"\"\n",
        "        Hierarchical Self-Attention 계산 (논문의 핵심 알고리즘)\n",
        "\n",
        "        Args:\n",
        "            hidden_states: [batch_size, N, feature_dim]\n",
        "                          N = LR tokens + Global tokens + CLS token\n",
        "            selected_hr_features: [batch_size, M, feature_dim]\n",
        "                                M = 선택된 HR tokens (보통 1~4개)\n",
        "\n",
        "        Returns:\n",
        "            output: [batch_size, N, feature_dim] - 업데이트된 hidden states\n",
        "            attention_map: [batch_size, N-1] - CLS token의 attention (다음 layer용)\n",
        "        \"\"\"\n",
        "        batch_size, N, _ = hidden_states.shape          # N: LR + Global + CLS 개수\n",
        "        _, M, _ = selected_hr_features.shape            # M: 선택된 HR 개수\n",
        "\n",
        "        # 🔵 Step 1: 일반 hidden states에 대한 Q, K, V 계산\n",
        "        Q = self.q_proj(hidden_states)      # [B, N, D] - Query (어디에 집중할지?)\n",
        "        K_h = self.k_proj(hidden_states)    # [B, N, D] - Key (나는 이런 정보야)\n",
        "        V_h = self.v_proj(hidden_states)    # [B, N, D] - Value (실제 전달할 정보)\n",
        "\n",
        "        # 🔴 Step 2: HR features에 대한 별도 K, V 계산 (논문의 핵심!)\n",
        "        K_hr = self.k_proj_hr(selected_hr_features)  # [B, M, D] - HR용 Key\n",
        "        V_hr = self.v_proj_hr(selected_hr_features)  # [B, M, D] - HR용 Value\n",
        "\n",
        "        # 🔗 Step 3: Key와 Value를 연결 [일반 tokens + HR tokens]\n",
        "        K_all = torch.cat([K_h, K_hr], dim=1)  # [B, N+M, D] - 모든 Keys\n",
        "        V_all = torch.cat([V_h, V_hr], dim=1)  # [B, N+M, D] - 모든 Values\n",
        "\n",
        "        # 🧠 Step 4: Multi-head attention을 위한 reshape\n",
        "        # [B, seq_len, D] → [B, num_heads, seq_len, head_dim]\n",
        "        Q = Q.view(batch_size, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K_all = K_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V_all = V_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # ⚡ Step 5: Attention 계산 - 여기서 계산량 O(N×(N+M))\n",
        "        # 일반 Self-Attention이라면 O((N+M)²)이지만,\n",
        "        # Query는 N개뿐이므로 O(N×(N+M)) = O(N²+NM)\n",
        "        scores = torch.matmul(Q, K_all.transpose(-2, -1)) / self.scale  # [B, H, N, N+M]\n",
        "        attention_weights = F.softmax(scores, dim=-1)                   # attention 확률\n",
        "        attention_weights = self.dropout(attention_weights)             # 드롭아웃 적용\n",
        "\n",
        "        # 🎯 Step 6: Attention 적용하여 정보 집약\n",
        "        attended = torch.matmul(attention_weights, V_all)  # [B, H, N, head_dim]\n",
        "\n",
        "        # 🔄 Step 7: Multi-head 결과 합치기\n",
        "        attended = attended.transpose(1, 2).contiguous()  # [B, N, H, head_dim]\n",
        "        attended = attended.view(batch_size, N, self.feature_dim)  # [B, N, D]\n",
        "\n",
        "        # 📤 Step 8: 최종 출력 projection\n",
        "        output = self.out_proj(attended)  # [B, N, D]\n",
        "\n",
        "        # 📊 Step 9: 다음 layer용 attention map 추출\n",
        "        # CLS token (마지막 토큰)이 LR tokens에 주는 attention\n",
        "        cls_attention = attention_weights[:, :, -1, :N-1]  # [B, H, N-1] - CLS → LR\n",
        "        attention_map = cls_attention.mean(dim=1)          # [B, N-1] - head 평균\n",
        "\n",
        "        return output, attention_map\n",
        "\n",
        "\n",
        "# 메모리 사용량 최적화 함수들\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"메모리 사용량 최적화 설정\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # 메모리 효율적인 attention 사용 (PyTorch 2.0+)\n",
        "        try:\n",
        "            torch.backends.cuda.enable_flash_sdp(True)\n",
        "            print(\"✅ Flash Attention 활성화 (메모리 효율성 향상)\")\n",
        "        except:\n",
        "            print(\"⚠️  Flash Attention 미지원 (PyTorch 버전 확인)\")\n",
        "\n",
        "        # CUDA 메모리 할당 최적화\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "        print(\"✅ CUDA 메모리 할당 최적화\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"✅ GPU 메모리 정리 완료\")\n",
        "\n",
        "def log_model_info(model):\n",
        "    \"\"\"모델 정보 로깅\"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"🔍 모델 정보:\")\n",
        "    print(f\"   - 총 파라미터: {total_params:,}개 ({total_params/1e6:.1f}M)\")\n",
        "    print(f\"   - 훈련 가능: {trainable_params:,}개 ({trainable_params/1e6:.1f}M)\")\n",
        "    print(f\"   - 모델 크기: {total_params * 4 / 1024**2:.1f}MB (float32 기준)\")\n",
        "\n",
        "# 체크포인트 매니저 초기화\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    max_keep=3  # 최대 3개 체크포인트 보관 (디스크 공간 절약)\n",
        ")\n",
        "\n",
        "# 메모리 최적화 실행\n",
        "optimize_memory_usage()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 6 완료: 체크포인트 시스템 & Hierarchical Self-Attention 준비 완료!\")\n",
        "print(\"이제 훈련 중단되어도 마지막 지점부터 재시작 가능합니다!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnefL1TYUJ3N"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 7: 완전한 MIL 모델과 Dataset\n",
        "# ========================================================================\n",
        "\n",
        "# 이 셀을 일곱 번째로 실행하세요 - 완전한 FlexAttention MIL 모델과 Dataset을 구현합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf7PtQ41UJ3N"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FlexAttentionPatientMIL(nn.Module):\n",
        "    \"\"\"\n",
        "    🎯 완전한 FlexAttention Multiple Instance Learning 모델\n",
        "\n",
        "    전체 구조:\n",
        "    1. 환자별 여러 메가패치 → 각각 8개 패치 → 3-stream features\n",
        "    2. LR + Global tokens → Standard Self-Attention layers\n",
        "    3. LR attention → HR selection → FlexAttention layers\n",
        "    4. CLS token → Patient-level classification (암 단계/재발 예측)\n",
        "\n",
        "    계산량 최적화:\n",
        "    - 메가패치당 16개 → 8개 패치로 감소 (50% 절약)\n",
        "    - Feature dim 384 → 256로 감소 (33% 절약)\n",
        "    - FA layers 2개 → 1개로 감소 (50% 절약)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_classes=2, num_heads=4,\n",
        "                 num_sa_layers=1, num_fa_layers=1, dropout=0.1,\n",
        "                 extractor_type='resnet18'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): Feature 차원 (256 추천, 메모리 효율적)\n",
        "            num_classes (int): 분류 클래스 수 (2: binary classification)\n",
        "            num_heads (int): Attention head 수 (4 추천, 메모리 효율적)\n",
        "            num_sa_layers (int): Standard Self-Attention layer 수\n",
        "            num_fa_layers (int): FlexAttention layer 수\n",
        "            dropout (float): 드롭아웃 비율\n",
        "            extractor_type (str): Feature extractor 타입 ('resnet18', 'mobilenet')\n",
        "        \"\"\"\n",
        "        super(FlexAttentionPatientMIL, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_sa_layers = num_sa_layers\n",
        "        self.num_fa_layers = num_fa_layers\n",
        "\n",
        "        print(f\"🏗️  FlexAttention MIL 모델 초기화 중...\")\n",
        "        print(f\"   - Feature dim: {feature_dim}\")\n",
        "        print(f\"   - Attention heads: {num_heads}\")\n",
        "        print(f\"   - SA layers: {num_sa_layers}, FA layers: {num_fa_layers}\")\n",
        "        print(f\"   - Extractor: {extractor_type}\")\n",
        "\n",
        "        # 🔬 Feature extractors (3개의 서로 다른 해상도용)\n",
        "        self.lr_extractor =  ResNetFeatureExtractor()\n",
        "        self.global_extractor =  ResNetFeatureExtractor()\n",
        "        self.hr_extractor =  ResNetFeatureExtractor()    # 256x256용 (HR)\n",
        "\n",
        "        # 🎯 CLS token (환자 레벨 분류를 위한 특별한 토큰)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, feature_dim))\n",
        "\n",
        "        # 📍 Positional encoding (토큰 위치 정보)\n",
        "        # 최대 토큰 수: 환자당 20메가패치 × 8패치 = 160 LR + 20 Global + 1 CLS = 181\n",
        "        max_tokens = 200  # 여유있게 설정\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, max_tokens, feature_dim))\n",
        "\n",
        "        # 🧠 Standard Self-Attention layers (LR + Global + CLS만 사용)\n",
        "        self.sa_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=feature_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=feature_dim * 4,  # FFN hidden dim\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True  # Pre-LN for better training stability\n",
        "            ) for _ in range(num_sa_layers)\n",
        "        ])\n",
        "\n",
        "        # 🎯 FlexAttention components\n",
        "        self.hr_selectors = nn.ModuleList([\n",
        "            ThresholdBasedHRSelector(\n",
        "                target_selection_ratio=0.1,  # 10% 선택\n",
        "                min_patches=1,\n",
        "                max_patches=4\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.hierarchical_attentions = nn.ModuleList([\n",
        "            HierarchicalSelfAttention(feature_dim, num_heads, dropout)\n",
        "            for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # FlexAttention layer용 FFN과 LayerNorm\n",
        "        self.fa_ffns = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(feature_dim, feature_dim * 4),\n",
        "                nn.GELU(),  # ReLU보다 더 부드러운 활성화 함수\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(feature_dim * 4, feature_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.fa_layer_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(feature_dim) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # 🏥 최종 분류기 (환자 레벨 예측)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feature_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # 가중치 초기화\n",
        "        self._initialize_weights()\n",
        "\n",
        "        print(f\"✅ FlexAttention MIL 모델 초기화 완료!\")\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"가중치 초기화 (더 안정적인 훈련을 위해)\"\"\"\n",
        "        # CLS token 초기화\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "\n",
        "        # Positional encoding 초기화\n",
        "        nn.init.trunc_normal_(self.pos_encoding, std=0.02)\n",
        "\n",
        "        # Linear layer 초기화\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.trunc_normal_(module.weight, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def forward(self, lr_features, global_features, hr_features):\n",
        "        \"\"\"\n",
        "        FlexAttention MIL Forward Pass\n",
        "\n",
        "        Args:\n",
        "            lr_features: [batch_size, total_lr_patches, feature_dim] - 모든 LR features\n",
        "            global_features: [batch_size, num_megapatches, feature_dim] - Global features\n",
        "            hr_features: [batch_size, total_hr_patches, feature_dim] - 모든 HR features\n",
        "\n",
        "        Returns:\n",
        "            logits: [batch_size, num_classes] - 환자 레벨 예측\n",
        "            attention_maps: List[Tensor] - attention maps (시각화용)\n",
        "            selection_stats: Dict - HR selection 통계 (분석용)\n",
        "        \"\"\"\n",
        "        batch_size = lr_features.shape[0]\n",
        "\n",
        "        # 📊 입력 데이터 크기 확인 및 메모리 효율적 처리\n",
        "        max_lr_tokens = min(lr_features.shape[1], 128)    # 최대 128개 LR tokens\n",
        "        max_global_tokens = min(global_features.shape[1], 16)  # 최대 16개 Global tokens\n",
        "        max_hr_tokens = min(hr_features.shape[1], 128)    # 최대 128개 HR tokens\n",
        "\n",
        "        # 메모리 절약을 위해 일부 토큰만 사용\n",
        "        lr_subset = lr_features[:, :max_lr_tokens]        # [B, ≤128, D]\n",
        "        global_subset = global_features[:, :max_global_tokens]  # [B, ≤16, D]\n",
        "        hr_subset = hr_features[:, :max_hr_tokens]        # [B, ≤128, D] (나중에 일부만 선택됨)\n",
        "\n",
        "        # 🎯 Step 1: Token sequence 구성 [LR + Global + CLS]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # [B, 1, D]\n",
        "\n",
        "        # 초기 hidden states: LR tokens + Global tokens + CLS token\n",
        "        hidden_states = torch.cat([lr_subset, global_subset, cls_tokens], dim=1)  # [B, N, D]\n",
        "\n",
        "        # 📍 Positional encoding 추가\n",
        "        seq_len = hidden_states.shape[1]\n",
        "        if seq_len <= self.pos_encoding.shape[1]:\n",
        "            hidden_states = hidden_states + self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        attention_maps = []  # attention map들을 저장할 리스트\n",
        "        selection_stats = {'total_selected': [], 'selection_ratios': []}\n",
        "\n",
        "        # 🧠 Step 2: Standard Self-Attention layers (Algorithm 1, lines 8-12)\n",
        "        for i in range(self.num_sa_layers):\n",
        "            hidden_states = self.sa_layers[i](hidden_states)\n",
        "\n",
        "        # 🎯 Step 3: FlexAttention layers (Algorithm 1, lines 14-19)\n",
        "        for i in range(self.num_fa_layers):\n",
        "            # Step 3a: LR attention 기반 HR selection\n",
        "            if i == 0:\n",
        "                # 첫 번째 layer: uniform attention (모든 LR 토큰에 동일한 가중치)\n",
        "                num_lr_tokens = lr_subset.shape[1]\n",
        "                lr_attention_map = torch.ones(batch_size, num_lr_tokens, device=lr_features.device)\n",
        "                lr_attention_map = lr_attention_map / lr_attention_map.sum(dim=1, keepdim=True)\n",
        "            else:\n",
        "                # 이전 layer의 attention 사용\n",
        "                lr_attention_map = attention_maps[-1][:, :lr_subset.shape[1]]  # LR 부분만\n",
        "\n",
        "            # HR features를 LR과 대응되도록 크기 맞춤\n",
        "            hr_corresponding_size = min(hr_subset.shape[1], lr_subset.shape[1])\n",
        "            hr_for_selection = hr_subset[:, :hr_corresponding_size]\n",
        "            lr_attention_for_selection = lr_attention_map[:, :hr_corresponding_size]\n",
        "\n",
        "            # Step 3b: 중요한 HR features 선택 (논문의 핵심!)\n",
        "            selected_hr_features, selection_masks, thresholds = self.hr_selectors[i](\n",
        "                lr_attention_for_selection, hr_for_selection\n",
        "            )\n",
        "\n",
        "            # 선택 통계 수집\n",
        "            stats = self.hr_selectors[i].get_selection_statistics(selection_masks)\n",
        "            selection_stats['total_selected'].append(stats['mean_selected'])\n",
        "            selection_stats['selection_ratios'].append(stats['selection_ratio'])\n",
        "\n",
        "            # Step 3c: Hierarchical Self-Attention (Algorithm 1, line 16)\n",
        "            attended_output, new_attention_map = self.hierarchical_attentions[i](\n",
        "                hidden_states, selected_hr_features\n",
        "            )\n",
        "\n",
        "            # Step 3d: Residual connection + Layer normalization\n",
        "            hidden_states = self.fa_layer_norms[i](hidden_states + attended_output)\n",
        "\n",
        "            # Step 3e: FFN + residual connection (Algorithm 1, line 18)\n",
        "            ffn_output = self.fa_ffns[i](hidden_states)\n",
        "            hidden_states = hidden_states + ffn_output\n",
        "\n",
        "            attention_maps.append(new_attention_map)\n",
        "\n",
        "        # 🏥 Step 4: 환자 레벨 분류 (Algorithm 1, line 20)\n",
        "        cls_output = hidden_states[:, -1]  # CLS token의 최종 representation\n",
        "        logits = self.classifier(cls_output)  # [B, num_classes]\n",
        "\n",
        "        return logits, attention_maps, selection_stats\n",
        "\n",
        "\n",
        "class DynamicFlexAttentionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    🗂️  FlexAttention용 동적 환자 Dataset\n",
        "\n",
        "    특징:\n",
        "    - 환자별로 다른 메가패치 개수 처리\n",
        "    - 메가패치당 8개 패치로 감소 (속도 향상)\n",
        "    - 캐싱으로 반복 로딩 방지\n",
        "    - 메모리 효율적 처리\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patient_data, target_type='t_label',\n",
        "                 patches_per_megapatch=8, cache_dir=None,\n",
        "                 max_megapatches=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patient_data (dict): 환자별 데이터 딕셔너리\n",
        "            target_type (str): 라벨 타입 ('t_label', 'recur_label')\n",
        "            patches_per_megapatch (int): 메가패치당 패치 개수 (8 추천)\n",
        "            cache_dir (str): 캐시 디렉토리 (처리된 features 저장)\n",
        "            max_megapatches (int): 환자당 최대 메가패치 수 (None이면 자동 결정)\n",
        "        \"\"\"\n",
        "        self.patient_data = patient_data\n",
        "        self.patient_ids = list(patient_data.keys())\n",
        "        self.target_type = target_type\n",
        "        self.patches_per_megapatch = patches_per_megapatch\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        if cache_dir:\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "        # 환자별 메가패치 개수 분석 및 최적 max_megapatches 결정\n",
        "        self._analyze_megapatch_distribution()\n",
        "        if max_megapatches is None:\n",
        "            self.max_megapatches = self._determine_optimal_max_megapatches()\n",
        "        else:\n",
        "            self.max_megapatches = max_megapatches\n",
        "\n",
        "        print(f\"📊 Dataset 초기화 완료:\")\n",
        "        print(f\"   - 환자 수: {len(self.patient_ids)}명\")\n",
        "        print(f\"   - 라벨 타입: {target_type}\")\n",
        "        print(f\"   - 메가패치당 패치 수: {patches_per_megapatch}개\")\n",
        "        print(f\"   - 환자당 최대 메가패치: {self.max_megapatches}개\")\n",
        "\n",
        "        # 이미지 전처리 transform\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # ImageNet 평균/표준편차로 정규화 (사전훈련 모델과 맞춤)\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def _analyze_megapatch_distribution(self):\n",
        "        \"\"\"환자별 메가패치 개수 분포 분석\"\"\"\n",
        "        counts = []\n",
        "        for patient_id, info in self.patient_data.items():\n",
        "            counts.append(len(info['images']))\n",
        "\n",
        "        if counts:\n",
        "            print(f\"📈 메가패치 개수 분포:\")\n",
        "            print(f\"   - 평균: {np.mean(counts):.1f}개\")\n",
        "            print(f\"   - 중간값: {np.median(counts):.1f}개\")\n",
        "            print(f\"   - 25%/75% 지점: {np.percentile(counts, 25):.1f}/{np.percentile(counts, 75):.1f}개\")\n",
        "            print(f\"   - 최소/최대: {min(counts)}/{max(counts)}개\")\n",
        "\n",
        "        self.megapatch_counts = counts\n",
        "\n",
        "    def _determine_optimal_max_megapatches(self):\n",
        "        \"\"\"메모리와 성능을 고려한 최적 max_megapatches 결정\"\"\"\n",
        "        if not self.megapatch_counts:\n",
        "            return 10  # 기본값\n",
        "\n",
        "        # 75% percentile 사용 (대부분 환자를 커버하면서 메모리 효율적)\n",
        "        optimal = int(np.percentile(self.megapatch_counts, 75))\n",
        "\n",
        "        # 최소 5개, 최대 15개로 제한 (메모리 고려)\n",
        "        optimal = max(5, min(optimal, 15))\n",
        "\n",
        "        print(f\"🎯 최적 max_megapatches 결정: {optimal}개 (75th percentile 기준)\")\n",
        "        return optimal\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        환자 데이터 로딩 및 전처리\n",
        "\n",
        "        Returns:\n",
        "            dict: {\n",
        "                'patient_id': 환자 ID,\n",
        "                'lr_patches': [total_lr, 3, 64, 64] - LR 패치들,\n",
        "                'global_patches': [num_megapatches, 3, 64, 64] - Global 패치들,\n",
        "                'hr_patches': [total_hr, 3, 256, 256] - HR 패치들,\n",
        "                'label': 라벨,\n",
        "                'num_megapatches': 실제 메가패치 개수\n",
        "            }\n",
        "        \"\"\"\n",
        "        patient_id = self.patient_ids[idx]\n",
        "        patient_info = self.patient_data[patient_id]\n",
        "\n",
        "        # 라벨 가져오기\n",
        "        label = patient_info.get(self.target_type, 0)\n",
        "        if label is None:\n",
        "            label = 0\n",
        "\n",
        "        # 이 환자의 모든 메가패치 경로\n",
        "        megapatch_paths = patient_info['images']\n",
        "\n",
        "        # 메가패치 개수 조정\n",
        "        if len(megapatch_paths) > self.max_megapatches:\n",
        "            # 너무 많으면 랜덤 샘플링\n",
        "            megapatch_paths = random.sample(megapatch_paths, self.max_megapatches)\n",
        "        elif len(megapatch_paths) == 0:\n",
        "            # 메가패치가 없으면 더미 데이터\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # 각 stream별 데이터 저장할 리스트들\n",
        "        all_lr_features = []\n",
        "        all_global_features = []\n",
        "        all_hr_features = []\n",
        "\n",
        "        # 각 메가패치 처리\n",
        "        processed_count = 0\n",
        "        for megapatch_path in megapatch_paths:\n",
        "            try:\n",
        "                # 캐싱 확인\n",
        "                if self.cache_dir:\n",
        "                    cache_key = hashlib.md5(\n",
        "                        f\"{megapatch_path}_{self.patches_per_megapatch}\".encode()\n",
        "                    ).hexdigest()\n",
        "                    cache_path = os.path.join(self.cache_dir, f\"{cache_key}.pkl\")\n",
        "\n",
        "                    if os.path.exists(cache_path):\n",
        "                        with open(cache_path, 'rb') as f:\n",
        "                            processed = pickle.load(f)\n",
        "                    else:\n",
        "                        processed = process_megapatch_complete(\n",
        "                            megapatch_path, self.patches_per_megapatch\n",
        "                        )\n",
        "                        with open(cache_path, 'wb') as f:\n",
        "                            pickle.dump(processed, f)\n",
        "                else:\n",
        "                    processed = process_megapatch_complete(\n",
        "                        megapatch_path, self.patches_per_megapatch\n",
        "                    )\n",
        "\n",
        "                # 각 stream별로 tensor 변환\n",
        "                for lr_patch in processed['lr_patches']:\n",
        "                    lr_pil = Image.fromarray(lr_patch)\n",
        "                    lr_tensor = self.transform(lr_pil)\n",
        "                    all_lr_features.append(lr_tensor)\n",
        "\n",
        "                # Global token (메가패치당 1개)\n",
        "                global_pil = Image.fromarray(processed['global_tokens'][0])\n",
        "                global_tensor = self.transform(global_pil)\n",
        "                all_global_features.append(global_tensor)\n",
        "\n",
        "                # HR patches\n",
        "                for hr_patch in processed['hr_patches']:\n",
        "                    hr_pil = Image.fromarray(hr_patch)\n",
        "                    hr_tensor = self.transform(hr_pil)\n",
        "                    all_hr_features.append(hr_tensor)\n",
        "\n",
        "                processed_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  메가패치 처리 실패 {megapatch_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # 처리된 메가패치가 없으면 더미 데이터\n",
        "        if processed_count == 0:\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # Tensor로 변환\n",
        "        lr_tensor = torch.stack(all_lr_features)      # [total_lr, 3, 64, 64]\n",
        "        global_tensor = torch.stack(all_global_features)  # [num_megapatches, 3, 64, 64]\n",
        "        hr_tensor = torch.stack(all_hr_features)      # [total_hr, 3, 256, 256]\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': lr_tensor,\n",
        "            'global_patches': global_tensor,\n",
        "            'hr_patches': hr_tensor,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': processed_count\n",
        "        }\n",
        "\n",
        "    def _create_dummy_data(self, patient_id, label):\n",
        "        \"\"\"메가패치가 없거나 처리 실패시 더미 데이터 생성\"\"\"\n",
        "        dummy_lr = torch.zeros(self.patches_per_megapatch, 3, 64, 64)\n",
        "        dummy_global = torch.zeros(1, 3, 64, 64)\n",
        "        dummy_hr = torch.zeros(self.patches_per_megapatch, 3, 256, 256)\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': dummy_lr,\n",
        "            'global_patches': dummy_global,\n",
        "            'hr_patches': dummy_hr,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': 1\n",
        "        }\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 7 완료: 완전한 FlexAttention MIL 모델과 Dataset 준비 완료!\")\n",
        "print(\"이제 환자별 다중 메가패치를 처리하여 암 단계/재발을 예측할 수 있습니다!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64mZpB_ZUJ3O"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 8: 훈련 함수 (체크포인트 완벽 지원)\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shhotdosUJ3O"
      },
      "outputs": [],
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 8: 훈련 함수 (체크포인트 완벽 지원)\n",
        "# ========================================================================\n",
        "\n",
        "# 이 셀을 여덟 번째로 실행하세요 - 체크포인트를 완벽 지원하는 훈련 함수를 구현합니다\n",
        "\n",
        "def train_flexattention_model_with_checkpoints(\n",
        "    patient_data,\n",
        "    target_type='t_label',\n",
        "    num_folds=3,\n",
        "    num_epochs=12,\n",
        "    batch_size=1,              # 메모리 절약\n",
        "    accumulation_steps=4,      # effective batch_size = 4\n",
        "    learning_rate=3e-4,\n",
        "    extractor_type='resnet18', # 'resnet18' or 'mobilenet'\n",
        "    device=device,\n",
        "    work_dir=work_dir,\n",
        "    resume_from_checkpoint=True\n",
        "):\n",
        "    \"\"\"\n",
        "    🚀 체크포인트를 완벽 지원하는 FlexAttention MIL 훈련 함수\n",
        "\n",
        "    주요 특징:\n",
        "    - 매 epoch마다 자동 저장\n",
        "    - 훈련 중단시 마지막 지점부터 재시작 가능\n",
        "    - Gradient accumulation으로 안정적인 훈련\n",
        "    - 실시간 로깅 및 모니터링\n",
        "    - 메모리 효율적 처리\n",
        "\n",
        "    Args:\n",
        "        patient_data (dict): 환자별 데이터\n",
        "        target_type (str): 라벨 타입 ('t_label' 또는 'recur_label')\n",
        "        num_folds (int): K-fold 개수\n",
        "        num_epochs (int): epoch 수\n",
        "        batch_size (int): 물리적 배치 크기 (GPU 메모리에 맞춰 조정)\n",
        "        accumulation_steps (int): gradient accumulation 단계 수\n",
        "        learning_rate (float): 학습률\n",
        "        extractor_type (str): feature extractor 타입\n",
        "        device: 훈련 디바이스\n",
        "        work_dir (str): 작업 디렉토리\n",
        "        resume_from_checkpoint (bool): 체크포인트에서 재시작 여부\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"🚀 FlexAttention MIL 훈련 시작!\")\n",
        "    print(f\"   Target: {target_type}\")\n",
        "    print(f\"   Folds: {num_folds}, Epochs: {num_epochs}\")\n",
        "    print(f\"   Batch size: {batch_size} (물리적) × {accumulation_steps} (누적) = {batch_size * accumulation_steps} (효과적)\")\n",
        "    print(f\"   Learning rate: {learning_rate}\")\n",
        "    print(f\"   Extractor: {extractor_type}\")\n",
        "    print(f\"   작업 디렉토리: {work_dir}\")\n",
        "\n",
        "    # 결과 저장 디렉토리 생성\n",
        "    target_dir = os.path.join(work_dir, f\"results_{target_type}\")\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    # 체크포인트 매니저 초기화\n",
        "    checkpoint_manager = CheckpointManager(\n",
        "        checkpoint_dir=os.path.join(target_dir, \"checkpoints\"),\n",
        "        max_keep=3\n",
        "    )\n",
        "\n",
        "    # 환자 데이터 준비\n",
        "    patient_ids = list(patient_data.keys())\n",
        "    patient_labels = [patient_data[pid].get(target_type, 0) for pid in patient_ids]\n",
        "    patient_labels = [0 if label is None else label for label in patient_labels]\n",
        "\n",
        "    print(f\"\\n👥 환자 데이터 준비 완료:\")\n",
        "    print(f\"   총 환자 수: {len(patient_ids)}명\")\n",
        "    print(f\"   라벨 분포: {dict(zip(*np.unique(patient_labels, return_counts=True)))}\")\n",
        "\n",
        "    # Stratified K-Fold 설정\n",
        "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # 전체 결과 저장\n",
        "    all_results = {\n",
        "        'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'auc': [],\n",
        "        'fold_details': []\n",
        "    }\n",
        "\n",
        "    # 각 fold 별 훈련\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(patient_ids, patient_labels)):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"🔄 Fold {fold+1}/{num_folds} 시작\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # 데이터 분할\n",
        "        train_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in train_idx}\n",
        "        test_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in test_idx}\n",
        "\n",
        "        print(f\"   훈련 환자: {len(train_patients)}명\")\n",
        "        print(f\"   테스트 환자: {len(test_patients)}명\")\n",
        "\n",
        "        # Dataset 생성\n",
        "        train_dataset = DynamicFlexAttentionDataset(\n",
        "            train_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=8,  # 메모리 절약\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=12        # 메모리 절약\n",
        "        )\n",
        "\n",
        "        test_dataset = DynamicFlexAttentionDataset(\n",
        "            test_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=8,\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=12\n",
        "        )\n",
        "\n",
        "        # DataLoader 생성\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2,              # Windows에서 안정적인 값\n",
        "            pin_memory=True,\n",
        "            persistent_workers=True,\n",
        "            drop_last=False\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        print(f\"   훈련 배치 수: {len(train_loader)}\")\n",
        "        print(f\"   테스트 배치 수: {len(test_loader)}\")\n",
        "\n",
        "        # 모델 초기화\n",
        "        model = FlexAttentionPatientMIL(\n",
        "            feature_dim=256,           # 메모리 효율적\n",
        "            num_classes=2,\n",
        "            num_heads=4,               # 메모리 효율적\n",
        "            num_sa_layers=1,\n",
        "            num_fa_layers=1,           # 메모리 절약\n",
        "            dropout=0.1,\n",
        "            extractor_type=extractor_type\n",
        "        )\n",
        "\n",
        "        # GPU 설정\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            print(f\"   🔗 {torch.cuda.device_count()}개 GPU로 DataParallel 설정\")\n",
        "            model = nn.DataParallel(model)\n",
        "\n",
        "        model = model.to(device)\n",
        "        log_model_info(model)\n",
        "\n",
        "        # 옵티마이저 및 스케줄러 설정\n",
        "        # Effective batch size에 맞춰 learning rate 조정\n",
        "        effective_batch_size = batch_size * accumulation_steps\n",
        "        adjusted_lr = learning_rate * (effective_batch_size / 4)  # base는 4\n",
        "\n",
        "        optimizer = AdamW(\n",
        "            model.parameters(),\n",
        "            lr=adjusted_lr,\n",
        "            weight_decay=1e-4,\n",
        "            betas=(0.9, 0.999),\n",
        "            eps=1e-8\n",
        "        )\\n        \\n        # 실제 업데이트 횟수 기준으로 스케줄러 설정\\n        total_updates = (len(train_loader) // accumulation_steps) * num_epochs\\n        scheduler = OneCycleLR(\\n            optimizer, \\n            max_lr=adjusted_lr, \\n            total_steps=total_updates,\\n            pct_start=0.1,  # 10%는 warm-up\\n            anneal_strategy='cos'\\n        )\\n        \\n        # Loss function & Scaler\\n        criterion = nn.CrossEntropyLoss()\\n        scaler = GradScaler()\\n        \\n        # 체크포인트에서 재시작 확인\\n        start_epoch = 0\\n        if resume_from_checkpoint:\\n            checkpoint = checkpoint_manager.load_latest_checkpoint(fold + 1)\\n            if checkpoint:\\n                # 모델 상태 복원\\n                if hasattr(model, 'module'):\\n                    model.module.load_state_dict(checkpoint['model_state_dict'])\\n                else:\\n                    model.load_state_dict(checkpoint['model_state_dict'])\\n                \\n                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\\n                \\n                if checkpoint['scheduler_state_dict'] and scheduler:\\n                    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\\n                \\n                start_epoch = checkpoint['epoch'] + 1\\n                checkpoint_manager.best_score = checkpoint.get('best_score', 0.0)\\n                \\n                print(f\\\"   📂 체크포인트에서 재시작: Epoch {start_epoch}부터\\\")\\n                print(f\\\"   🏆 이전 최고 성능: {checkpoint_manager.best_score:.4f}\\\")\\n        \\n        # 훈련 루프\\n        for epoch in range(start_epoch, num_epochs):\\n            print(f\\\"\\\\n🔄 Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\\\")\\n            log_gpu_memory(f\\\"Epoch {epoch+1} 시작\\\")\\n            \\n            # 훈련 단계\\n            model.train()\\n            total_loss = 0\\n            num_updates = 0\\n            optimizer.zero_grad()  # accumulation 시작\\n            \\n            progress_bar = tqdm(train_loader, desc=f\\\"훈련 진행\\\")\\n            \\n            for batch_idx, batch in enumerate(progress_bar):\\n                try:\\n                    # Backward pass\n",
        "                    scaler.scale(loss).backward()\n",
        "\n",
        "                    # Gradient accumulation 체크\n",
        "                    if (batch_idx + 1) % accumulation_steps == 0:\n",
        "                        # 실제 parameter 업데이트\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                        scheduler.step()\n",
        "                        optimizer.zero_grad()\n",
        "                        num_updates += 1\n",
        "\n",
        "                        # 메모리 정리 (주기적으로)\n",
        "                        if num_updates % 10 == 0:\n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "                    total_loss += loss.item() * accumulation_steps  # 원래 loss로 복원\n",
        "\n",
        "                    # Progress bar 업데이트\n",
        "                    current_lr = scheduler.get_last_lr()[0] if scheduler else adjusted_lr\n",
        "                    progress_bar.set_postfix({\n",
        "                        'Loss': f'{loss.item() * accumulation_steps:.4f}',\n",
        "                        'LR': f'{current_lr:.2e}',\n",
        "                        'Updates': num_updates\n",
        "                    })\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(f\"💥 OOM 발생! 배치 {batch_idx} 스킵\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        continue\n",
        "                    else:\n",
        "                        raise e\n",
        "\n",
        "            # 마지막 배치 처리 (accumulation이 완료되지 않은 경우)\n",
        "            if len(train_loader) % accumulation_steps != 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "            # 검증 단계 (간단한 검증)\n",
        "            model.eval()\n",
        "            val_preds = []\n",
        "            val_labels = []\n",
        "            val_probs = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm(test_loader, desc=\"검증 진행\"):\n",
        "                    try:\n",
        "                        lr_patches = batch['lr_patches'].to(device, non_blocking=True)\n",
        "                        global_patches = batch['global_patches'].to(device, non_blocking=True)\n",
        "                        hr_patches = batch['hr_patches'].to(device, non_blocking=True)\n",
        "                        labels = batch['label'].to(device, non_blocking=True)\n",
        "\n",
        "                        # Feature extraction\n",
        "                        lr_features, global_features, hr_features = extract_features_efficiently(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        # Forward pass\n",
        "                        if hasattr(model, 'module'):\n",
        "                            logits, _, _ = model.module(lr_features, global_features, hr_features)\n",
        "                        else:\n",
        "                            logits, _, _ = model(lr_features, global_features, hr_features)\n",
        "\n",
        "                        probs = F.softmax(logits, dim=1)\n",
        "                        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                        val_preds.extend(preds.cpu().tolist())\n",
        "                        val_labels.extend(labels.cpu().tolist())\n",
        "                        val_probs.extend(probs[:, 1].cpu().tolist())\n",
        "\n",
        "                    except RuntimeError as e:\n",
        "                        if \"out of memory\" in str(e):\n",
        "                            print(f\"💥 검증 중 OOM 발생! 배치 스킵\")\n",
        "                            torch.cuda.empty_cache()\n",
        "                            continue\n",
        "                        else:\n",
        "                            raise e\n",
        "\n",
        "            # 검증 메트릭 계산\n",
        "            if val_labels:\n",
        "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "                val_precision = precision_score(val_labels, val_preds, zero_division=0)\n",
        "                val_recall = recall_score(val_labels, val_preds, zero_division=0)\n",
        "                val_f1 = f1_score(val_labels, val_preds, zero_division=0)\n",
        "\n",
        "                try:\n",
        "                    val_auc = roc_auc_score(val_labels, val_probs)\n",
        "                except:\n",
        "                    val_auc = 0.0\n",
        "\n",
        "                val_metrics = {\n",
        "                    'accuracy': val_accuracy,\n",
        "                    'precision': val_precision,\n",
        "                    'recall': val_recall,\n",
        "                    'f1': val_f1,\n",
        "                    'auc': val_auc\n",
        "                }\n",
        "\n",
        "                # 최고 성능 체크\n",
        "                is_best = val_f1 > checkpoint_manager.best_score\n",
        "\n",
        "                print(f\"   📊 Epoch {epoch+1} 결과:\")\n",
        "                print(f\"      훈련 Loss: {avg_loss:.4f}\")\n",
        "                print(f\"      검증 Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}\")\n",
        "                if is_best:\n",
        "                    print(f\"      🏆 새로운 최고 성능!\")\n",
        "\n",
        "            else:\n",
        "                val_metrics = {}\n",
        "                is_best = False\n",
        "                print(f\"   📊 Epoch {epoch+1} 결과: 훈련 Loss {avg_loss:.4f} (검증 데이터 없음)\")\n",
        "\n",
        "            # 체크포인트 저장 (매 epoch마다)\n",
        "            checkpoint_manager.save_checkpoint(\n",
        "                model=model,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                epoch=epoch,\n",
        "                fold=fold + 1,\n",
        "                train_loss=avg_loss,\n",
        "                val_metrics=val_metrics,\n",
        "                is_best=is_best\n",
        "            )\n",
        "\n",
        "            # 메모리 정리\n",
        "            torch.cuda.empty_cache()\n",
        "            log_gpu_memory(f\"Epoch {epoch+1} 완료\")\n",
        "\n",
        "        # Fold 완료 후 최종 평가\n",
        "        print(f\"\\n🎯 Fold {fold+1} 최종 평가 중...\")\n",
        "\n",
        "        # 최고 성능 모델 로딩\n",
        "        best_model_path = os.path.join(checkpoint_manager.checkpoint_dir, f\"best_model_fold{fold+1}.pt\")\n",
        "        if os.path.exists(best_model_path):\n",
        "            checkpoint = torch.load(best_model_path, map_location=device)\n",
        "            if hasattr(model, 'module'):\n",
        "                model.module.load_state_dict(checkpoint['model_state_dict'])\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(f\"   📂 최고 성능 모델 로딩 완료\")\n",
        "\n",
        "        # 최종 테스트\n",
        "        model.eval()\n",
        "        final_preds = []\n",
        "        final_labels = []\n",
        "        final_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(test_loader, desc=\"최종 평가\"):\n",
        "                try:\n",
        "                    lr_patches = batch['lr_patches'].to(device, non_blocking=True)\n",
        "                    global_patches = batch['global_patches'].to(device, non_blocking=True)\n",
        "                    hr_patches = batch['hr_patches'].to(device, non_blocking=True)\n",
        "                    labels = batch['label'].to(device, non_blocking=True)\n",
        "\n",
        "                    lr_features, global_features, hr_features = extract_features_efficiently(\n",
        "                        lr_patches, global_patches, hr_patches, model\n",
        "                    )\n",
        "\n",
        "                    if hasattr(model, 'module'):\n",
        "                        logits, attention_maps, selection_stats = model.module(\n",
        "                            lr_features, global_features, hr_features\n",
        "                        )\n",
        "                    else:\n",
        "                        logits, attention_maps, selection_stats = model(\n",
        "                            lr_features, global_features, hr_features\n",
        "                        )\n",
        "\n",
        "                    probs = F.softmax(logits, dim=1)\n",
        "                    preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                    final_preds.extend(preds.cpu().tolist())\n",
        "                    final_labels.extend(labels.cpu().tolist())\n",
        "                    final_probs.extend(probs[:, 1].cpu().tolist())\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(f\"💥 최종 평가 중 OOM 발생! 배치 스킵\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        continue\n",
        "                    else:\n",
        "                        raise e\n",
        "\n",
        "        # 최종 메트릭 계산\n",
        "        if final_labels:\n",
        "            final_accuracy = accuracy_score(final_labels, final_preds)\n",
        "            final_precision = precision_score(final_labels, final_preds, zero_division=0)\n",
        "            final_recall = recall_score(final_labels, final_preds, zero_division=0)\n",
        "            final_f1 = f1_score(final_labels, final_preds, zero_division=0)\n",
        "\n",
        "            try:\n",
        "                final_auc = roc_auc_score(final_labels, final_probs)\n",
        "            except:\n",
        "                final_auc = 0.0\n",
        "\n",
        "            print(f\"\\n🏆 Fold {fold+1} 최종 결과:\")\n",
        "            print(f\"   Accuracy: {final_accuracy:.4f}\")\n",
        "            print(f\"   Precision: {final_precision:.4f}\")\n",
        "            print(f\"   Recall: {final_recall:.4f}\")\n",
        "            print(f\"   F1: {final_f1:.4f}\")\n",
        "            print(f\"   AUC: {final_auc:.4f}\")\n",
        "\n",
        "            # 결과 저장\n",
        "            all_results['accuracy'].append(final_accuracy)\n",
        "            all_results['precision'].append(final_precision)\n",
        "            all_results['recall'].append(final_recall)\n",
        "            all_results['f1'].append(final_f1)\n",
        "            all_results['auc'].append(final_auc)\n",
        "\n",
        "            # Confusion Matrix 계산 및 저장\n",
        "            cm = confusion_matrix(final_labels, final_preds)\n",
        "            fold_detail = {\n",
        "                'fold': fold + 1,\n",
        "                'accuracy': final_accuracy,\n",
        "                'precision': final_precision,\n",
        "                'recall': final_recall,\n",
        "                'f1': final_f1,\n",
        "                'auc': final_auc,\n",
        "                'confusion_matrix': cm.tolist(),\n",
        "                'predictions': final_preds,\n",
        "                'true_labels': final_labels,\n",
        "                'probabilities': final_probs\n",
        "            }\n",
        "            all_results['fold_details'].append(fold_detail)\n",
        "\n",
        "        # 모델 메모리 정리\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"✅ Fold {fold+1} 완료!\")\n",
        "\n",
        "    # 전체 결과 요약\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"🏁 전체 훈련 완료! ({target_type})\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    if all_results['accuracy']:\n",
        "        print(f\"📊 평균 성능 (±표준편차):\")\n",
        "        print(f\"   Accuracy:  {np.mean(all_results['accuracy']):.4f} ± {np.std(all_results['accuracy']):.4f}\")\n",
        "        print(f\"   Precision: {np.mean(all_results['precision']):.4f} ± {np.std(all_results['precision']):.4f}\")\n",
        "        print(f\"   Recall:    {np.mean(all_results['recall']):.4f} ± {np.std(all_results['recall']):.4f}\")\n",
        "        print(f\"   F1:        {np.mean(all_results['f1']):.4f} ± {np.std(all_results['f1']):.4f}\")\n",
        "        print(f\"   AUC:       {np.mean(all_results['auc']):.4f} ± {np.std(all_results['auc']):.4f}\")\n",
        "\n",
        "        # 결과 파일 저장\n",
        "        results_path = os.path.join(target_dir, f\"final_results_{target_type}.json\")\n",
        "        with open(results_path, 'w') as f:\n",
        "            # numpy arrays를 list로 변환하여 JSON serializable하게 만들기\n",
        "            json_results = {}\n",
        "            for key, value in all_results.items():\n",
        "                if isinstance(value, list) and len(value) > 0:\n",
        "                    if isinstance(value[0], np.ndarray):\n",
        "                        json_results[key] = [v.tolist() for v in value]\n",
        "                    else:\n",
        "                        json_results[key] = value\n",
        "                else:\n",
        "                    json_results[key] = value\n",
        "\n",
        "            json.dump(json_results, f, indent=2)\n",
        "\n",
        "        print(f\"💾 결과 저장 완료: {results_path}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "def extract_features_efficiently(lr_patches, global_patches, hr_patches, model):\n",
        "    \"\"\"\n",
        "    🔧 메모리 효율적인 feature extraction\n",
        "    큰 배치를 작은 청크로 나누어 처리하여 OOM 방지\n",
        "    \"\"\"\n",
        "    batch_size = lr_patches.shape[0]\n",
        "\n",
        "    # LR features 추출\n",
        "    num_lr = lr_patches.shape[1]\n",
        "    lr_flat = lr_patches.view(-1, 3, 64, 64)\n",
        "\n",
        "    if hasattr(model, 'module'):\n",
        "        extractor = model.module.lr_extractor\n",
        "    else:\n",
        "        extractor = model.lr_extractor\n",
        "\n",
        "    lr_features = extractor(lr_flat)\n",
        "    lr_features = lr_features.view(batch_size, num_lr, -1)\n",
        "\n",
        "    # Global features 추출\n",
        "    num_global = global_patches.shape[1]\n",
        "    global_flat = global_patches.view(-1, 3, 64, 64)\n",
        "\n",
        "    if hasattr(model, 'module'):\n",
        "        global_extractor = model.module.global_extractor\n",
        "    else:\n",
        "        global_extractor = model.global_extractor\n",
        "\n",
        "    global_features = global_extractor(global_flat)\n",
        "    global_features = global_features.view(batch_size, num_global, -1)\n",
        "\n",
        "    # HR features 추출 (메모리 집약적이므로 청크 단위로 처리)\n",
        "    num_hr = hr_patches.shape[1]\n",
        "    hr_flat = hr_patches.view(-1, 3, 256, 256)\n",
        "\n",
        "    if hasattr(model, 'module'):\n",
        "        hr_extractor = model.module.hr_extractor\n",
        "    else:\n",
        "        hr_extractor = model.hr_extractor\n",
        "\n",
        "    # HR patches를 청크로 나누어 처리 (메모리 절약)\n",
        "    chunk_size = 8  # 한 번에 8개씩 처리\n",
        "    hr_features_list = []\n",
        "\n",
        "    for i in range(0, hr_flat.shape[0], chunk_size):\n",
        "        chunk = hr_flat[i:i+chunk_size]\n",
        "        chunk_features = hr_extractor(chunk)\n",
        "        hr_features_list.append(chunk_features)\n",
        "\n",
        "        # 중간 메모리 정리\n",
        "        del chunk\n",
        "\n",
        "    hr_features = torch.cat(hr_features_list, dim=0)\n",
        "    hr_features = hr_features.view(batch_size, num_hr, -1)\n",
        "\n",
        "    return lr_features, global_features, hr_features\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 8 완료: 체크포인트를 완벽 지원하는 훈련 함수 준비 완료!\")\n",
        "print(\"이제 훈련 중단되어도 언제든 재시작 가능합니다!\")\n",
        "print(\"📁 매 epoch마다 자동 저장되며, 최고 성능 모델은 별도 보관됩니다.\")\n",
        "print(\"=\"*80)\n",
        "# 데이터를 GPU로 이동\n",
        "    lr_patches = batch['lr_patches'].to(device, non_blocking=True)\n",
        "    global_patches = batch['global_patches'].to(device, non_blocking=True)\n",
        "    hr_patches = batch['hr_patches'].to(device, non_blocking=True)\n",
        "    labels = batch['label'].to(device, non_blocking=True)\n",
        "\n",
        "    with autocast():\n",
        "        # Feature extraction (메모리 효율적으로)\n",
        "        lr_features, global_features, hr_features = extract_features_efficiently(\n",
        "            lr_patches, global_patches, hr_patches, model\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        if hasattr(model, 'module'):\n",
        "            logits, attention_maps, selection_stats = model.module(\n",
        "                lr_features, global_features, hr_features\n",
        "            )\n",
        "        else:\n",
        "            logits, attention_maps, selection_stats = model(\n",
        "                lr_features, global_features, hr_features\n",
        "            )\n",
        "\n",
        "        # Loss 계산 (accumulation으로 나누기)\n",
        "        loss = criterion(logits, labels) / accumulation_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMNJcnhXUJ3P"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 9: 실제 훈련 실행\n",
        "# ========================================================================\n",
        "\n",
        "# 이 셀을 아홉 번째로 실행하세요 - 실제 훈련을 시작합니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdydXp_JUJ3P"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 훈련 전 최종 확인 및 설정\n",
        "print(\"🚀 FlexAttention MIL 훈련 준비 완료!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"💾 데이터: {len(patient_data) if 'patient_data' in locals() else 0}명의 환자\")\n",
        "print(f\"🖥️  디바이스: {device}\")\n",
        "print(f\"📁 작업 디렉토리: {work_dir}\")\n",
        "print(f\"⏰ 예상 소요 시간: 1-2일 (최적화된 설정)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 메모리 및 시스템 상태 확인\n",
        "log_gpu_memory(\"훈련 시작 전\")\n",
        "\n",
        "# 훈련 설정 확인\n",
        "print(\"\\n⚙️  훈련 설정:\")\n",
        "print(\"   - 메가패치당 패치 수: 8개 (16→8, 50% 절약)\")\n",
        "print(\"   - Feature dimension: 256 (384→256, 33% 절약)\")\n",
        "print(\"   - Attention heads: 4개 (6→4, 33% 절약)\")\n",
        "print(\"   - FlexAttention layers: 1개 (2→1, 50% 절약)\")\n",
        "print(\"   - 배치 크기: 1 (물리적) × 4 (누적) = 4 (효과적)\")\n",
        "print(\"   - Feature extractor: ResNet18 (안정성 우선)\")\n",
        "\n",
        "# 사용자 확인\n",
        "print(f\"\\n❓ 설정이 맞다면 다음 셀을 실행하세요!\")\n",
        "print(f\"   T-stage 분류와 재발 예측을 순차적으로 훈련합니다.\")\n",
        "print(f\"   각 fold마다 체크포인트가 자동 저장됩니다.\")\n",
        "\n",
        "# 훈련 파라미터 설정\n",
        "TRAINING_CONFIG = {\n",
        "    'num_folds': 5,\n",
        "    'num_epochs': 8,           # 2일 안에 완주하기 위해 12→10\n",
        "    'batch_size': 1,            # 메모리 안전\n",
        "    'accumulation_steps': 4,    # 효과적 배치 크기 = 4\n",
        "    'learning_rate': 3e-4,\n",
        "    'extractor_type': 'resnet18',  # 안정성 우선\n",
        "    'resume_from_checkpoint': True\n",
        "}\n",
        "\n",
        "print(f\"\\n📋 훈련 파라미터:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# 데이터 존재 확인\n",
        "if 'patient_data' not in locals() or not patient_data:\n",
        "    print(f\"\\n❌ 환자 데이터가 로딩되지 않았습니다!\")\n",
        "    print(f\"   Part 5를 먼저 실행하여 데이터를 로딩하세요.\")\n",
        "else:\n",
        "    print(f\"\\n✅ 환자 데이터 준비 완료: {len(patient_data)}명\")\n",
        "\n",
        "    # 라벨 분포 재확인\n",
        "    t_labels = [info.get('t_label', 0) for info in patient_data.values()]\n",
        "    recur_labels = [info.get('recur_label', 0) for info in patient_data.values()]\n",
        "\n",
        "    print(f\"📊 라벨 분포:\")\n",
        "    print(f\"   T-stage: {dict(zip(*np.unique(t_labels, return_counts=True)))}\")\n",
        "    print(f\"   재발: {dict(zip(*np.unique(recur_labels, return_counts=True)))}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 9 완료: 훈련 실행 준비 완료!\")\n",
        "print(\"다음 셀에서 실제 훈련을 시작합니다.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVe_By63UJ3P"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 10: T-stage 분류 훈련 실행\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgoIZ9HlUJ3P"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 이 셀을 열 번째로 실행하세요 - T-stage 분류 훈련을 시작합니다!\n",
        "\n",
        "print(\"🎯 T-stage 분류 훈련 시작!\")\n",
        "print(\"=\"*60)\n",
        "print(\"📋 T-stage 분류:\")\n",
        "print(\"   - 클래스 0: Ta, T1 (저위험 - 근육층 침범 없음)\")\n",
        "print(\"   - 클래스 1: T2+ (고위험 - 근육층 침범 있음)\")\n",
        "print(\"   - 임상적 중요성: 치료 계획 및 예후 예측에 핵심\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 훈련 시작 시간 기록\n",
        "import time\n",
        "start_time = time.time()\n",
        "start_datetime = datetime.now()\n",
        "\n",
        "print(f\"🕒 훈련 시작 시간: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# 초기 메모리 상태 확인\n",
        "log_gpu_memory(\"T-stage 훈련 시작\")\n",
        "\n",
        "try:\n",
        "    # T-stage 분류 훈련 실행\n",
        "    print(f\"\\n🚀 T-stage 분류 훈련 시작...\")\n",
        "\n",
        "    t_stage_results = train_flexattention_model_with_checkpoints(\n",
        "        patient_data=patient_data,\n",
        "        target_type='t_label',\n",
        "        **TRAINING_CONFIG  # Part 9에서 정의한 설정 사용\n",
        "    )\n",
        "\n",
        "    # 훈련 완료 시간 계산\n",
        "    end_time = time.time()\n",
        "    training_duration = end_time - start_time\n",
        "    hours = int(training_duration // 3600)\n",
        "    minutes = int((training_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\n🎉 T-stage 분류 훈련 완료!\")\n",
        "    print(f\"⏱️  소요 시간: {hours}시간 {minutes}분\")\n",
        "    print(f\"📊 최종 성능:\")\n",
        "\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        print(f\"   평균 Accuracy: {np.mean(t_stage_results['accuracy']):.4f} ± {np.std(t_stage_results['accuracy']):.4f}\")\n",
        "        print(f\"   평균 F1 Score: {np.mean(t_stage_results['f1']):.4f} ± {np.std(t_stage_results['f1']):.4f}\")\n",
        "        print(f\"   평균 AUC: {np.mean(t_stage_results['auc']):.4f} ± {np.std(t_stage_results['auc']):.4f}\")\n",
        "\n",
        "        # 최고 성능 fold 찾기\n",
        "        best_fold_idx = np.argmax(t_stage_results['f1'])\n",
        "        best_f1 = t_stage_results['f1'][best_fold_idx]\n",
        "        print(f\"   최고 성능: Fold {best_fold_idx + 1} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    # 결과 시각화 (간단한 성능 그래프)\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            values = t_stage_results[metric]\n",
        "            plt.bar(range(1, len(values)+1), values, alpha=0.7)\n",
        "            plt.title(f'{name}')\n",
        "            plt.xlabel('Fold')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            # 평균선 추가\n",
        "            mean_val = np.mean(values)\n",
        "            plt.axhline(y=mean_val, color='red', linestyle='--', alpha=0.8)\n",
        "            plt.text(0.5, mean_val + 0.02, f'평균: {mean_val:.3f}', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # 그래프 저장\n",
        "        plot_path = os.path.join(work_dir, \"results_t_label\", \"t_stage_performance.png\")\n",
        "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"📈 성능 그래프 저장: {plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # 메모리 정리\n",
        "    torch.cuda.empty_cache()\n",
        "    log_gpu_memory(\"T-stage 훈련 완료\")\n",
        "\n",
        "    print(f\"\\n✅ T-stage 분류 훈련 성공적으로 완료!\")\n",
        "    print(f\"📁 결과 저장 위치: {os.path.join(work_dir, 'results_t_label')}\")\n",
        "    print(f\"💾 체크포인트: {os.path.join(work_dir, 'results_t_label', 'checkpoints')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ T-stage 훈련 중 오류 발생: {e}\")\n",
        "    print(f\"📋 오류 상세:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # 메모리 정리\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\n🔧 문제 해결 방법:\")\n",
        "    print(f\"   1. GPU 메모리 부족: batch_size를 1로 줄이기\")\n",
        "    print(f\"   2. 시스템 메모리 부족: patches_per_megapatch를 8→6으로 줄이기\")\n",
        "    print(f\"   3. 데이터 문제: Part 5에서 데이터 로딩 다시 확인\")\n",
        "    print(f\"   4. 체크포인트에서 재시작: resume_from_checkpoint=True 설정\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 10 완료: T-stage 분류 훈련 실행!\")\n",
        "if 't_stage_results' in locals():\n",
        "    print(\"✅ 훈련 성공! 다음 Part에서 재발 예측 훈련을 진행합니다.\")\n",
        "else:\n",
        "    print(\"⚠️  훈련에 문제가 발생했습니다. 위의 해결 방법을 참고하세요.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cJt3OZrUJ3P"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention 기반 방광암 분류 모델 - Part 11: 재발 예측 훈련 및 최종 결과\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OknC1VGPUJ3Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 이 셀을 열한 번째로 실행하세요 - 재발 예측 훈련을 시작하고 전체 결과를 요약합니다!\n",
        "\n",
        "print(\"🔄 재발 예측 훈련 시작!\")\n",
        "print(\"=\"*60)\n",
        "print(\"📋 재발 예측:\")\n",
        "print(\"   - 클래스 0: No (재발 없음)\")\n",
        "print(\"   - 클래스 1: Yes (재발 있음)\")\n",
        "print(\"   - 임상적 중요성: 환자 모니터링 및 추가 치료 계획\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 재발 예측 훈련 시작 시간 기록\n",
        "recur_start_time = time.time()\n",
        "recur_start_datetime = datetime.now()\n",
        "\n",
        "print(f\"🕒 재발 예측 훈련 시작: {recur_start_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# 메모리 상태 확인\n",
        "log_gpu_memory(\"재발 예측 훈련 시작\")\n",
        "\n",
        "try:\n",
        "    # 재발 예측 훈련 실행\n",
        "    print(f\"\\n🚀 재발 예측 훈련 시작...\")\n",
        "\n",
        "    recurrence_results = train_flexattention_model_with_checkpoints(\n",
        "        patient_data=patient_data,\n",
        "        target_type='recur_label',\n",
        "        **TRAINING_CONFIG  # 동일한 설정 사용\n",
        "    )\n",
        "\n",
        "    # 재발 예측 훈련 완료 시간 계산\n",
        "    recur_end_time = time.time()\n",
        "    recur_duration = recur_end_time - recur_start_time\n",
        "    recur_hours = int(recur_duration // 3600)\n",
        "    recur_minutes = int((recur_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\n🎉 재발 예측 훈련 완료!\")\n",
        "    print(f\"⏱️  소요 시간: {recur_hours}시간 {recur_minutes}분\")\n",
        "    print(f\"📊 최종 성능:\")\n",
        "\n",
        "    if recurrence_results and recurrence_results['accuracy']:\n",
        "        print(f\"   평균 Accuracy: {np.mean(recurrence_results['accuracy']):.4f} ± {np.std(recurrence_results['accuracy']):.4f}\")\n",
        "        print(f\"   평균 F1 Score: {np.mean(recurrence_results['f1']):.4f} ± {np.std(recurrence_results['f1']):.4f}\")\n",
        "        print(f\"   평균 AUC: {np.mean(recurrence_results['auc']):.4f} ± {np.std(recurrence_results['auc']):.4f}\")\n",
        "\n",
        "        # 최고 성능 fold 찾기\n",
        "        best_fold_idx = np.argmax(recurrence_results['f1'])\n",
        "        best_f1 = recurrence_results['f1'][best_fold_idx]\n",
        "        print(f\"   최고 성능: Fold {best_fold_idx + 1} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    # 재발 예측 결과 시각화\n",
        "    if recurrence_results and recurrence_results['accuracy']:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            values = recurrence_results[metric]\n",
        "            plt.bar(range(1, len(values)+1), values, alpha=0.7, color='orange')\n",
        "            plt.title(f'{name}')\n",
        "            plt.xlabel('Fold')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            # 평균선 추가\n",
        "            mean_val = np.mean(values)\n",
        "            plt.axhline(y=mean_val, color='red', linestyle='--', alpha=0.8)\n",
        "            plt.text(0.5, mean_val + 0.02, f'평균: {mean_val:.3f}', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # 그래프 저장\n",
        "        plot_path = os.path.join(work_dir, \"results_recur_label\", \"recurrence_performance.png\")\n",
        "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"📈 성능 그래프 저장: {plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    print(f\"\\n✅ 재발 예측 훈련 성공적으로 완료!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ 재발 예측 훈련 중 오류 발생: {e}\")\n",
        "    print(f\"📋 오류 상세:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # 오류 발생시에도 T-stage 결과는 보존\n",
        "    if 't_stage_results' in locals():\n",
        "        print(f\"ℹ️  T-stage 결과는 정상적으로 완료되었습니다.\")\n",
        "\n",
        "# 전체 훈련 완료 시간 계산\n",
        "if 'start_time' in locals():\n",
        "    total_end_time = time.time()\n",
        "    total_duration = total_end_time - start_time\n",
        "    total_hours = int(total_duration // 3600)\n",
        "    total_minutes = int((total_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\n⏰ 전체 훈련 소요 시간: {total_hours}시간 {total_minutes}분\")\n",
        "\n",
        "# 최종 결과 요약 및 비교\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"🏁 FlexAttention MIL 모델 훈련 완료!\")\n",
        "print(f\"=\"*80)\n",
        "\n",
        "# 결과 비교표 생성\n",
        "if 't_stage_results' in locals() and 'recurrence_results' in locals():\n",
        "    if t_stage_results.get('accuracy') and recurrence_results.get('accuracy'):\n",
        "\n",
        "        print(f\"\\n📊 최종 성능 비교:\")\n",
        "        print(f\"{'메트릭':<12} {'T-stage 분류':<20} {'재발 예측':<20}\")\n",
        "        print(f\"{'-'*12} {'-'*20} {'-'*20}\")\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for metric, name in zip(metrics, metric_names):\n",
        "            t_mean = np.mean(t_stage_results[metric])\n",
        "            t_std = np.std(t_stage_results[metric])\n",
        "            r_mean = np.mean(recurrence_results[metric])\n",
        "            r_std = np.std(recurrence_results[metric])\n",
        "\n",
        "            print(f\"{name:<12} {t_mean:.3f}±{t_std:.3f:<12} {r_mean:.3f}±{r_std:.3f}\")\n",
        "\n",
        "        # 전체 결과를 하나의 파일로 저장\n",
        "        final_summary = {\n",
        "            'training_info': {\n",
        "                'start_time': start_datetime.isoformat() if 'start_datetime' in locals() else None,\n",
        "                'total_duration_hours': total_hours if 'total_hours' in locals() else None,\n",
        "                'training_config': TRAINING_CONFIG,\n",
        "                'num_patients': len(patient_data)\n",
        "            },\n",
        "            't_stage_classification': {\n",
        "                'task_description': 'Ta,T1 vs T2+ classification',\n",
        "                'clinical_importance': 'Treatment planning and prognosis',\n",
        "                'results': t_stage_results\n",
        "            },\n",
        "            'recurrence_prediction': {\n",
        "                'task_description': 'No recurrence vs Recurrence prediction',\n",
        "                'clinical_importance': 'Patient monitoring and follow-up care',\n",
        "                'results': recurrence_results\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 전체 요약 저장\n",
        "        summary_path = os.path.join(work_dir, \"final_summary_all_tasks.json\")\n",
        "        with open(summary_path, 'w') as f:\n",
        "            # numpy 객체를 JSON serializable하게 변환\n",
        "            def convert_numpy(obj):\n",
        "                if isinstance(obj, np.ndarray):\n",
        "                    return obj.tolist()\n",
        "                elif isinstance(obj, np.integer):\n",
        "                    return int(obj)\n",
        "                elif isinstance(obj, np.floating):\n",
        "                    return float(obj)\n",
        "                elif isinstance(obj, dict):\n",
        "                    return {key: convert_numpy(value) for key, value in obj.items()}\n",
        "                elif isinstance(obj, list):\n",
        "                    return [convert_numpy(item) for item in obj]\n",
        "                return obj\n",
        "\n",
        "            final_summary_json = convert_numpy(final_summary)\n",
        "            json.dump(final_summary_json, f, indent=2)\n",
        "\n",
        "        print(f\"\\n💾 전체 결과 요약 저장: {summary_path}\")\n",
        "\n",
        "        # 성능 비교 시각화\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        x = np.arange(len(metric_names))\n",
        "        width = 0.35\n",
        "\n",
        "        t_means = [np.mean(t_stage_results[m]) for m in metrics]\n",
        "        r_means = [np.mean(recurrence_results[m]) for m in metrics]\n",
        "\n",
        "        plt.bar(x - width/2, t_means, width, label='T-stage 분류', alpha=0.8)\n",
        "        plt.bar(x + width/2, r_means, width, label='재발 예측', alpha=0.8)\n",
        "\n",
        "        plt.xlabel('메트릭')\n",
        "        plt.ylabel('점수')\n",
        "        plt.title('FlexAttention MIL 모델 성능 비교')\n",
        "        plt.xticks(x, metric_names)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # 수치 표시\n",
        "        for i, (t_val, r_val) in enumerate(zip(t_means, r_means)):\n",
        "            plt.text(i - width/2, t_val + 0.01, f'{t_val:.3f}', ha='center', fontsize=8)\n",
        "            plt.text(i + width/2, r_val + 0.01, f'{r_val:.3f}', ha='center', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        comparison_plot_path = os.path.join(work_dir, \"performance_comparison.png\")\n",
        "        plt.savefig(comparison_plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"📊 비교 그래프 저장: {comparison_plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# 메모리 정리\n",
        "torch.cuda.empty_cache()\n",
        "log_gpu_memory(\"전체 훈련 완료\")\n",
        "\n",
        "# 최종 메시지\n",
        "print(f\"\\n🎊 축하합니다! FlexAttention MIL 모델 훈련이 완료되었습니다!\")\n",
        "print(f\"📁 모든 결과는 다음 위치에 저장되었습니다:\")\n",
        "print(f\"   {work_dir}\")\n",
        "print(f\"\\n📋 저장된 파일들:\")\n",
        "print(f\"   - T-stage 분류 결과: results_t_label/\")\n",
        "print(f\"   - 재발 예측 결과: results_recur_label/\")\n",
        "print(f\"   - 체크포인트: */checkpoints/\")\n",
        "print(f\"   - 전체 요약: final_summary_all_tasks.json\")\n",
        "print(f\"   - 성능 그래프: *.png\")\n",
        "\n",
        "if 'total_hours' in locals():\n",
        "    if total_hours < 48:  # 2일 이내\n",
        "        print(f\"\\n⏰ 목표 달성! {total_hours}시간 {total_minutes}분만에 완료 (2일 이내)\")\n",
        "    else:\n",
        "        print(f\"\\n⏰ 총 소요 시간: {total_hours}시간 {total_minutes}분\")\n",
        "\n",
        "print(f\"\\n✨ FlexAttention을 이용한 방광암 병리 이미지 분석이 성공적으로 완료되었습니다!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 11 완료: 전체 훈련 완료 및 결과 요약!\")\n",
        "print(\"🎉 모든 과정이 완료되었습니다!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}