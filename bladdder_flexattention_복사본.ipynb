{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongwoonalee/jongwoonalee.github.io/blob/main/bladdder_flexattention_%EB%B3%B5%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SQZtrFEUJ3I"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ê¸°ë³¸ ì„¤ì •\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5NDXfQWUJ3J"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ì´ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš” - í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ import í•©ë‹ˆë‹¤\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from skimage.filters import threshold_otsu\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import hashlib\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")\n",
        "\n",
        "# GPU ì„¤ì • ë° í™•ì¸ - RTX 6000 Ada x2 ìµœì í™”\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"ğŸš€ {num_gpus}ê°œì˜ GPU ë°œê²¬!\")\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "        print(f\"   GPU {i}: {gpu_name} ({memory_gb:.1f}GB)\")\n",
        "\n",
        "    # CUDA ìµœì í™” ì„¤ì •\n",
        "    torch.backends.cudnn.benchmark = True  # ë™ì¼í•œ ì…ë ¥ í¬ê¸°ì— ëŒ€í•´ ìµœì í™”\n",
        "    torch.cuda.empty_cache()               # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "\n",
        "    print(f\"âœ… ì£¼ ë””ë°”ì´ìŠ¤: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"âš ï¸  GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
        "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
        "\n",
        "# ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    Args:\n",
        "        seed (int): ê³ ì •í•  ì‹œë“œ ê°’ (ê¸°ë³¸ê°’: 42)\n",
        "    \"\"\"\n",
        "    random.seed(seed)              # Python ê¸°ë³¸ random\n",
        "    np.random.seed(seed)           # NumPy random\n",
        "    torch.manual_seed(seed)        # PyTorch CPU random\n",
        "    torch.cuda.manual_seed(seed)   # PyTorch GPU random (í˜„ì¬ ë””ë°”ì´ìŠ¤)\n",
        "    torch.cuda.manual_seed_all(seed)  # PyTorch ëª¨ë“  GPU random\n",
        "\n",
        "    # ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì • (ì†ë„ê°€ ì•½ê°„ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì‹œë“œ ì„¤ì •\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    print(f\"âœ… ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ {seed}ë¡œ ê³ ì •í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ì‹œë“œ ê³ ì • ì‹¤í–‰\n",
        "set_seed(42)\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜\n",
        "def log_gpu_memory(step_name=\"\"):\n",
        "    \"\"\"\n",
        "    í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "    Args:\n",
        "        step_name (str): í˜„ì¬ ë‹¨ê³„ ì´ë¦„ (ë¡œê·¸ êµ¬ë¶„ìš©)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3  # GB ë‹¨ìœ„\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3    # GB ë‹¨ìœ„\n",
        "        max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
        "\n",
        "        print(f\"ğŸ” [{step_name}] GPU ë©”ëª¨ë¦¬ - \"\n",
        "              f\"ì‚¬ìš©ì¤‘: {allocated:.2f}GB, \"\n",
        "              f\"ì˜ˆì•½ë¨: {reserved:.2f}GB, \"\n",
        "              f\"ìµœëŒ€ì‚¬ìš©: {max_allocated:.2f}GB\")\n",
        "    else:\n",
        "        print(f\"ğŸ” [{step_name}] CPU ëª¨ë“œ ì‹¤í–‰ ì¤‘\")\n",
        "\n",
        "# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"ì´ˆê¸° ìƒíƒœ\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuLEAIHJUJ3K"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 2: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP3m7VdkUJ3K"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ë‘ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ë°ì´í„° ì²˜ë¦¬ì— í•„ìš”í•œ ëª¨ë“  í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
        "\n",
        "def extract_identifier(filename):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ëª…ì—ì„œ í™˜ì IDë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        filename (str): ì´ë¯¸ì§€ íŒŒì¼ëª… (ì˜ˆ: \"S123-456.jpg\")\n",
        "\n",
        "    Returns:\n",
        "        str or None: ì¶”ì¶œëœ í™˜ì ID (ì˜ˆ: \"S123000456\")\n",
        "        str: íŒŒì¼ í™•ì¥ì\n",
        "\n",
        "    Example:\n",
        "        extract_identifier(\"S123-456.jpg\") â†’ (\"S123000456\", \".jpg\")\n",
        "    \"\"\"\n",
        "    # íŒŒì¼ëª…ê³¼ í™•ì¥ì ë¶„ë¦¬\n",
        "    name, ext = os.path.splitext(filename)\n",
        "\n",
        "    # ëŒ€ê´„í˜¸ê°€ ìˆìœ¼ë©´ ì œê±° (ì˜ˆ: \"[comment]\" ë¶€ë¶„)\n",
        "    if '[' in name:\n",
        "        name = name.split('[')[0].strip()\n",
        "\n",
        "    # íŒ¨í„´ 1: Sìˆ«ì-ìˆ«ì í˜•íƒœ (ì˜ˆ: S123-456)\n",
        "    m1 = re.match(r'^S(\\d+)-(\\d+)(?:_\\d{4}-\\d{2}-\\d{2})?', name)\n",
        "    if m1:\n",
        "        slide = m1.group(1)      # \"123\"\n",
        "        patch = m1.group(2)      # \"456\"\n",
        "\n",
        "        # íŒ¨ì¹˜ ë²ˆí˜¸ë¥¼ 6ìë¦¬ë¡œ íŒ¨ë”© (ì•ì— 0 ì¶”ê°€)\n",
        "        if len(patch) == 3:\n",
        "            patch_padded = \"000\" + patch    # 456 â†’ 000456\n",
        "        elif len(patch) == 4:\n",
        "            patch_padded = \"00\" + patch     # 1456 â†’ 001456\n",
        "        elif len(patch) == 5:\n",
        "            patch_padded = \"0\" + patch      # 12456 â†’ 012456\n",
        "        else:\n",
        "            patch_padded = patch            # ì´ë¯¸ 6ìë¦¬ë©´ ê·¸ëŒ€ë¡œ\n",
        "\n",
        "        return f\"S{slide}{patch_padded}\"\n",
        "\n",
        "    # íŒ¨í„´ 2: Sìˆ«ì, í˜•íƒœ (ì˜ˆ: S123,)\n",
        "    m2 = re.match(r'^S(\\d+)[,;]', name)\n",
        "    if m2:\n",
        "        slide_id = m2.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # íŒ¨í„´ 3: S + 6-8ìë¦¬ ìˆ«ì (ì˜ˆ: S12345678)\n",
        "    m3 = re.match(r'^S(\\d{8}|\\d{7}|\\d{6})', name)\n",
        "    if m3:\n",
        "        slide_id = m3.group(1)\n",
        "        return f\"S{slide_id}\", ext\n",
        "\n",
        "    # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜\n",
        "    return None, ext\n",
        "\n",
        "def convert_file_id_to_excel_format(file_id):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ IDë¥¼ Excelì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜\n",
        "\n",
        "    Args:\n",
        "        file_id (str): íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ ID\n",
        "\n",
        "    Returns:\n",
        "        str or None: Excel í˜•íƒœë¡œ ë³€í™˜ëœ ID\n",
        "\n",
        "    Example:\n",
        "        convert_file_id_to_excel_format(\"S123-456\") â†’ \"S123000456\"\n",
        "    \"\"\"\n",
        "    if file_id is None:\n",
        "        return None\n",
        "\n",
        "    file_id = str(file_id).strip()\n",
        "\n",
        "    # \"-\"ê°€ í¬í•¨ëœ ê²½ìš° (ì˜ˆ: S123-456)\n",
        "    if \"-\" in file_id:\n",
        "        parts = file_id.split(\"-\")\n",
        "        if len(parts) == 2 and parts[1].isdigit():\n",
        "            patch = parts[1]\n",
        "\n",
        "            # íŒ¨ì¹˜ ë²ˆí˜¸ë¥¼ 6ìë¦¬ë¡œ íŒ¨ë”©\n",
        "            if len(patch) == 3:\n",
        "                padded_number = \"000\" + patch\n",
        "            elif len(patch) == 4:\n",
        "                padded_number = \"00\" + patch\n",
        "            elif len(patch) == 5:\n",
        "                padded_number = \"0\" + patch\n",
        "            else:\n",
        "                padded_number = patch\n",
        "\n",
        "            return f\"{parts[0]}{padded_number}\"\n",
        "\n",
        "    # ì´ë¯¸ Së¡œ ì‹œì‘í•˜ëŠ” ê¸´ í˜•íƒœë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
        "    elif len(file_id) > 3 and file_id.startswith(\"S\"):\n",
        "        return file_id\n",
        "\n",
        "    return None\n",
        "\n",
        "# ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ í•¨ìˆ˜ (ì—¬ê¸°ì„œëŠ” í•¨ìˆ˜ë§Œ ì •ì˜, ì‹¤ì œ ë¡œë”©ì€ ë‹¤ìŒ ì…€ì—ì„œ)\n",
        "def load_and_match_data(zip_path, excel_path, base_dir=None):\n",
        "    \"\"\"\n",
        "    ZIP íŒŒì¼ê³¼ Excel íŒŒì¼ì„ ë§¤ì¹­í•˜ì—¬ í™˜ìë³„ ë°ì´í„°ë¥¼ êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” ZIP íŒŒì¼ ê²½ë¡œ\n",
        "        excel_path (str): ë¼ë²¨ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” Excel íŒŒì¼ ê²½ë¡œ\n",
        "        base_dir (str, optional): ZIP ì••ì¶• í•´ì œí•  ë””ë ‰í† ë¦¬\n",
        "\n",
        "    Returns:\n",
        "        dict: í™˜ìë³„ë¡œ êµ¬ì„±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
        "        {\n",
        "            \"patient_id\": {\n",
        "                \"images\": [ì´ë¯¸ì§€íŒŒì¼ê²½ë¡œë“¤],\n",
        "                \"t_label\": T-stage ë¼ë²¨,\n",
        "                \"recur_label\": ì¬ë°œ ë¼ë²¨,\n",
        "                \"grade\": ë“±ê¸‰ ì •ë³´,\n",
        "                ... ê¸°íƒ€ ì •ë³´\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ ì‹œì‘...\")\n",
        "\n",
        "    # Excel íŒŒì¼ ì½ê¸°\n",
        "    print(\"ğŸ“Š Excel íŒŒì¼ ì½ëŠ” ì¤‘...\")\n",
        "    try:\n",
        "        df = pd.read_excel(excel_path)\n",
        "        print(f\"   âœ… Excel íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰\")\n",
        "        print(f\"   ğŸ“‹ ì»¬ëŸ¼ë“¤: {list(df.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # T-stageì™€ ì¬ë°œ ë¼ë²¨ ìƒì„±\n",
        "    print(\"ğŸ·ï¸  ë¼ë²¨ ë³€í™˜ ì¤‘...\")\n",
        "\n",
        "        # T-stage ë¼ë²¨: 1 â†’ 0 (ì €ìœ„í—˜), 2 â†’ 1 (ê³ ìœ„í—˜)\n",
        "        second_column = df.columns[1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ (Subtype)\n",
        "        df['t_label'] = df[second_column].apply(\n",
        "            lambda x: 0 if str(x) == '1' else 1\n",
        "        )\n",
        "        t_counts = df['t_label'].value_counts()\n",
        "        print(f\"   ğŸ“ˆ T-stage ë¶„í¬: ì €ìœ„í—˜(0): {t_counts.get(0, 0)}ê°œ, ê³ ìœ„í—˜(1): {t_counts.get(1, 0)}ê°œ\")\n",
        "\n",
        "    # ì¬ë°œ ë¼ë²¨: No â†’ 0, Yes â†’ 1\n",
        "    #if 'Recurrence' in df.columns:\n",
        "        #df['recur_label'] = df['Recurrence'].apply(\n",
        "           # lambda x: 0 if str(x).lower() == 'no' else 1\n",
        "        #)\n",
        "       # recur_counts = df['recur_label'].value_counts()\n",
        "      #  print(f\"   ğŸ”„ ì¬ë°œ ë¶„í¬: ì—†ìŒ(0): {recur_counts.get(0, 0)}ê°œ, ìˆìŒ(1): {recur_counts.get(1, 0)}ê°œ\")\n",
        "\n",
        "    # ZIP íŒŒì¼ ì²˜ë¦¬\n",
        "    if base_dir is None:\n",
        "        base_dir = zip_path.replace('.zip', '')\n",
        "\n",
        "    print(f\"ğŸ“¦ ZIP íŒŒì¼ ì²˜ë¦¬ ì¤‘: {zip_path}\")\n",
        "\n",
        "    # ZIP íŒŒì¼ì´ ì´ë¯¸ ì••ì¶• í•´ì œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(\"   ğŸ”„ ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì¤‘...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(os.path.dirname(base_dir))\n",
        "        print(\"   âœ… ZIP íŒŒì¼ ì••ì¶• í•´ì œ ì™„ë£Œ\")\n",
        "    else:\n",
        "        print(\"   âœ… ì´ë¯¸ ì••ì¶• í•´ì œëœ í´ë” ë°œê²¬\")\n",
        "\n",
        "    # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°\n",
        "    print(\"ğŸ” ì´ë¯¸ì§€ íŒŒì¼ë“¤ íƒìƒ‰ ì¤‘...\")\n",
        "    image_files = []\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                full_path = os.path.join(root, file)\n",
        "                image_files.append(full_path)\n",
        "\n",
        "    print(f\"   ğŸ“· ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬\")\n",
        "\n",
        "    # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ ë° ë§¤ì¹­\n",
        "    print(\"ğŸ”— í™˜ì ID ë§¤ì¹­ ì¤‘...\")\n",
        "    patient_data = {}\n",
        "    matched_count = 0\n",
        "    unmatched_files = []\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬\"):\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ\n",
        "        file_id, _ = extract_identifier(filename)\n",
        "        if file_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excel í˜•íƒœë¡œ ë³€í™˜\n",
        "        excel_id = convert_file_id_to_excel_format(file_id)\n",
        "        if excel_id is None:\n",
        "            unmatched_files.append(filename)\n",
        "            continue\n",
        "\n",
        "        # Excelì—ì„œ í•´ë‹¹ í™˜ì ì°¾ê¸°\n",
        "        patient_row = df[df.iloc[:, 0].astype(str).str.contains(excel_id, na=False)]\n",
        "\n",
        "        if len(patient_row) > 0:\n",
        "            patient_info = patient_row.iloc[0]\n",
        "            patient_id = str(patient_info.iloc[0])\n",
        "\n",
        "            # í™˜ì ë°ì´í„° ì´ˆê¸°í™” (ì²˜ìŒ ë°œê²¬ëœ ê²½ìš°)\n",
        "            if patient_id not in patient_data:\n",
        "                patient_data[patient_id] = {\n",
        "                    'images': [],\n",
        "                    't_label': patient_info.get('t_label', 0),\n",
        "                    'recur_label': patient_info.get('recur_label', 0),\n",
        "                    'grade': patient_info.get('Grade', 'Unknown'),\n",
        "                    't_stage': patient_info.get('T-stage', 'Unknown'),\n",
        "                    'recurrence': patient_info.get('Recurrence', 'Unknown')\n",
        "                }\n",
        "\n",
        "            # ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€\n",
        "            patient_data[patient_id]['images'].append(img_path)\n",
        "            matched_count += 1\n",
        "        else:\n",
        "            unmatched_files.append(filename)\n",
        "\n",
        "    print(f\"   âœ… ë§¤ì¹­ ì™„ë£Œ: {matched_count}ê°œ íŒŒì¼ ë§¤ì¹­\")\n",
        "    print(f\"   âš ï¸  ë§¤ì¹­ ì‹¤íŒ¨: {len(unmatched_files)}ê°œ íŒŒì¼\")\n",
        "    print(f\"   ğŸ‘¥ ì´ í™˜ì ìˆ˜: {len(patient_data)}ëª…\")\n",
        "\n",
        "    # í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜ í†µê³„\n",
        "    image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "    if image_counts:\n",
        "        print(f\"   ğŸ“Š í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜ - í‰ê· : {np.mean(image_counts):.1f}ê°œ, \"\n",
        "              f\"ìµœì†Œ: {min(image_counts)}ê°œ, ìµœëŒ€: {max(image_counts)}ê°œ\")\n",
        "\n",
        "    # ë§¤ì¹­ë˜ì§€ ì•Šì€ íŒŒì¼ ì¼ë¶€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)\n",
        "    if unmatched_files:\n",
        "        print(f\"   ğŸ“ ë§¤ì¹­ ì‹¤íŒ¨ íŒŒì¼ ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):\")\n",
        "        for file in unmatched_files[:5]:\n",
        "            print(f\"      - {file}\")\n",
        "\n",
        "    print(\"âœ… ë°ì´í„° ë¡œë”© ë° ë§¤ì¹­ ì™„ë£Œ!\")\n",
        "    return patient_data\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 2 ì™„ë£Œ: ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒìœ¼ë¡œ Part 3ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNOP6sVNUJ3L"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 3: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsZVwwPtUJ3L"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ì„¸ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - FlexAttentionì˜ í•µì‹¬ì¸ ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
        "\n",
        "def split_megapatch_to_patches(megapatch_path, grid_size=4):\n",
        "    \"\"\"\n",
        "    ğŸ”ª STEP 1: 1024x1024 ë©”ê°€íŒ¨ì¹˜ë¥¼ 4x4=16ê°œì˜ 256x256 íŒ¨ì¹˜ë¡œ ë¶„í• \n",
        "\n",
        "    FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - í° ì´ë¯¸ì§€ë¥¼ ì‘ì€ íŒ¨ì¹˜ë“¤ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬\n",
        "    - ê° íŒ¨ì¹˜ëŠ” ë™ì¼í•œ í¬ê¸°ë¡œ ì •ê·œí™”\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 ë©”ê°€íŒ¨ì¹˜ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "        grid_size (int): ê·¸ë¦¬ë“œ í¬ê¸° (4x4 = 16ê°œ íŒ¨ì¹˜, 3x3 = 9ê°œ íŒ¨ì¹˜ ë“±)\n",
        "\n",
        "    Returns:\n",
        "        list: 16ê°œì˜ 256x256 íŒ¨ì¹˜ë“¤ (numpy arrays)\n",
        "        list: ê° íŒ¨ì¹˜ì˜ ìœ„ì¹˜ ì •ë³´ [(i, j), ...]\n",
        "\n",
        "    Example:\n",
        "        patches, positions = split_megapatch_to_patches(\"image.jpg\", 4)\n",
        "        # patches[0]: ì¢Œìƒë‹¨ íŒ¨ì¹˜, patches[15]: ìš°í•˜ë‹¨ íŒ¨ì¹˜\n",
        "        # positions[0]: (0, 0), positions[15]: (3, 3)\n",
        "    \"\"\"\n",
        "    # 1024x1024 ë©”ê°€íŒ¨ì¹˜ ì½ê¸°\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"âŒ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {megapatch_path}\")\n",
        "\n",
        "    # BGR â†’ RGB ë³€í™˜ (OpenCVëŠ” BGR, ìš°ë¦¬ëŠ” RGB ì‚¬ìš©)\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "    h, w = megapatch.shape[:2]\n",
        "\n",
        "    # ê° íŒ¨ì¹˜ í¬ê¸° ê³„ì‚°: 1024/4 = 256\n",
        "    patch_size = h // grid_size  # 256x256\n",
        "\n",
        "    patches = []      # ë¶„í• ëœ íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    positions = []    # ê° íŒ¨ì¹˜ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    # 4x4 ê·¸ë¦¬ë“œë¡œ ë¶„í•  (ì™¼ìª½ ìœ„ë¶€í„° ì˜¤ë¥¸ìª½ ì•„ë˜ë¡œ)\n",
        "    for i in range(grid_size):        # ì„¸ë¡œ ë°©í–¥ (í–‰)\n",
        "        for j in range(grid_size):    # ê°€ë¡œ ë°©í–¥ (ì—´)\n",
        "            # íŒ¨ì¹˜ì˜ ì‹œì‘ì ê³¼ ëì  ê³„ì‚°\n",
        "            y_start = i * patch_size      # ì„¸ë¡œ ì‹œì‘ ìœ„ì¹˜\n",
        "            x_start = j * patch_size      # ê°€ë¡œ ì‹œì‘ ìœ„ì¹˜\n",
        "            y_end = y_start + patch_size  # ì„¸ë¡œ ë ìœ„ì¹˜\n",
        "            x_end = x_start + patch_size  # ê°€ë¡œ ë ìœ„ì¹˜\n",
        "\n",
        "            # 256x256 íŒ¨ì¹˜ ì¶”ì¶œ\n",
        "            patch = megapatch[y_start:y_end, x_start:x_end]\n",
        "            patches.append(patch)\n",
        "            positions.append((i, j))  # (í–‰, ì—´) ìœ„ì¹˜ ì €ì¥\n",
        "\n",
        "    return patches, positions\n",
        "\n",
        "def create_three_streams_from_patch(patch_256, megapatch_1024):\n",
        "    \"\"\"\n",
        "    ğŸ¯ STEP 2: ê° 256x256 íŒ¨ì¹˜ë¡œë¶€í„° 3-stream ìƒì„±\n",
        "\n",
        "    FlexAttentionì˜ 3-stream êµ¬ì¡°:\n",
        "    1. LR (Low Resolution): ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ 64x64 ì €í•´ìƒë„\n",
        "    2. HR (High Resolution): ì„¸ë°€í•œ ë¶„ì„ì„ ìœ„í•œ 256x256 ê³ í•´ìƒë„\n",
        "    3. Global: ì „ì²´ ë§¥ë½ì„ ìœ„í•œ 64x64 ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸\n",
        "\n",
        "    Args:\n",
        "        patch_256 (numpy.ndarray): 256x256 íŒ¨ì¹˜ (numpy array)\n",
        "        megapatch_1024 (numpy.ndarray): ì „ì²´ 1024x1024 ë©”ê°€íŒ¨ì¹˜ (Global ìƒì„±ìš©)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr': 64x64 LR íŒ¨ì¹˜,\n",
        "            'hr': 256x256 HR íŒ¨ì¹˜ (ì›ë³¸),\n",
        "            'global': 64x64 Global ì»¨í…ìŠ¤íŠ¸\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 1. LR ìŠ¤íŠ¸ë¦¼: 256x256 â†’ 64x64 ë‹¤ìš´ìƒ˜í”Œë§\n",
        "    # INTER_AREA: ì¶•ì†Œì‹œ í’ˆì§ˆì´ ì¢‹ì€ ë³´ê°„ë²•\n",
        "    lr_patch =  patch_256.copy()  # 256x256 ê·¸ëŒ€ë¡œ\n",
        "\n",
        "    # 2. HR ìŠ¤íŠ¸ë¦¼: 256x256 ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "    # ì„¸ë°€í•œ íŠ¹ì§•ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ì›ë³¸ í•´ìƒë„ ìœ ì§€\n",
        "    hr_patch = patch_256.copy()\n",
        "\n",
        "    # 3. Global ìŠ¤íŠ¸ë¦¼: ì „ì²´ 1024x1024 â†’ 64x64 (ë§¤ìš° ì‘ì€ overview)\n",
        "    # ì „ì²´ì ì¸ êµ¬ì¡°ì™€ ë§¥ë½ ì •ë³´ë¥¼ ì œê³µ\n",
        "    global_context = cv2.resize(megapatch_1024, (64, 64), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return {\n",
        "        'lr': lr_patch,         # 64x64 LR (ë¹ ë¥¸ ì²˜ë¦¬ìš©)\n",
        "        'hr': hr_patch,         # 256x256 HR (ì„¸ë°€í•œ ë¶„ì„ìš©)\n",
        "        'global': global_context # 64x64 Global (ë§¥ë½ ì •ë³´ìš©)\n",
        "    }\n",
        "\n",
        "def process_megapatch_complete(megapatch_path, patches_per_megapatch=16):\n",
        "    \"\"\"\n",
        "    ğŸš€ STEP 3: ë©”ê°€íŒ¨ì¹˜ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "    ì „ì²´ ê³¼ì •:\n",
        "    1024x1024 ë©”ê°€íŒ¨ì¹˜ â†’ 16ê°œ íŒ¨ì¹˜ë¡œ ë¶„í•  â†’ ê°ê° 3-stream ìƒì„±\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): 1024x1024 ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        patches_per_megapatch (int): ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ê°œìˆ˜ (16 or 8 ë“±)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'lr_patches': 16ê°œì˜ 64x64 LR íŒ¨ì¹˜ë“¤,\n",
        "            'hr_patches': 16ê°œì˜ 256x256 HR íŒ¨ì¹˜ë“¤,\n",
        "            'global_tokens': 16ê°œì˜ 64x64 Global í† í°ë“¤ (ëª¨ë‘ ë™ì¼),\n",
        "            'positions': íŒ¨ì¹˜ ìœ„ì¹˜ ì •ë³´ [(i,j), ...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    # ì›ë³¸ ë©”ê°€íŒ¨ì¹˜ ì½ê¸°\n",
        "    megapatch = cv2.imread(megapatch_path)\n",
        "    if megapatch is None:\n",
        "        raise ValueError(f\"âŒ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {megapatch_path}\")\n",
        "    megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # patches_per_megapatchì— ë”°ë¼ grid_size ê²°ì •\n",
        "    if patches_per_megapatch == 16:\n",
        "        grid_size = 4    # 4x4 = 16\n",
        "    elif patches_per_megapatch == 9:\n",
        "        grid_size = 3    # 3x3 = 9\n",
        "    elif patches_per_megapatch == 8:\n",
        "        # 8ê°œëŠ” íŠ¹ë³„ ì²˜ë¦¬: 4x4ì—ì„œ 8ê°œë§Œ ì„ íƒ\n",
        "        grid_size = 4\n",
        "        use_subset = True\n",
        "    else:\n",
        "        grid_size = int(math.sqrt(patches_per_megapatch))\n",
        "        use_subset = False\n",
        "\n",
        "    # STEP 1: 1024x1024 â†’ ì—¬ëŸ¬ê°œ 256x256 íŒ¨ì¹˜ë¡œ ë¶„í• \n",
        "    patches_256, positions = split_megapatch_to_patches(megapatch_path, grid_size)\n",
        "\n",
        "    # 8ê°œë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°: ì²´ìŠ¤íŒ íŒ¨í„´ìœ¼ë¡œ ì„ íƒ (ê· ë“± ë¶„í¬)\n",
        "    if patches_per_megapatch == 8 and len(patches_256) == 16:\n",
        "        # ì²´ìŠ¤íŒ íŒ¨í„´: (0,0), (0,2), (1,1), (1,3), (2,0), (2,2), (3,1), (3,3)\n",
        "        selected_indices = []\n",
        "        for i, (row, col) in enumerate(positions):\n",
        "            if (row + col) % 2 == 0:  # ì²´ìŠ¤íŒ íŒ¨í„´\n",
        "                selected_indices.append(i)\n",
        "\n",
        "        # 8ê°œë§Œ ì„ íƒ\n",
        "        selected_indices = selected_indices[:patches_per_megapatch]\n",
        "        patches_256 = [patches_256[i] for i in selected_indices]\n",
        "        positions = [positions[i] for i in selected_indices]\n",
        "\n",
        "    # STEP 2: ê° íŒ¨ì¹˜ë³„ë¡œ 3-stream ìƒì„±\n",
        "    lr_patches = []       # LR íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    hr_patches = []       # HR íŒ¨ì¹˜ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    global_tokens = []    # Global í† í°ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    for patch_256 in patches_256:\n",
        "        # ê° íŒ¨ì¹˜ì— ëŒ€í•´ 3-stream ìƒì„±\n",
        "        streams = create_three_streams_from_patch(patch_256, megapatch)\n",
        "\n",
        "        lr_patches.append(streams['lr'])        # 64x64 LR\n",
        "        hr_patches.append(streams['hr'])        # 256x256 HR\n",
        "        global_tokens.append(streams['global']) # 64x64 Global\n",
        "\n",
        "        # ì°¸ê³ : global_tokensëŠ” ëª¨ë‘ ë™ì¼í•œ ì „ì²´ ì´ë¯¸ì§€ì˜ ì¶•ì†Œë³¸ì…ë‹ˆë‹¤\n",
        "\n",
        "    return {\n",
        "        'lr_patches': lr_patches,     # patches_per_megapatchê°œ Ã— 64x64\n",
        "        'hr_patches': hr_patches,     # patches_per_megapatchê°œ Ã— 256x256\n",
        "        'global_tokens': global_tokens, # patches_per_megapatchê°œ Ã— 64x64 (ëª¨ë‘ ë™ì¼)\n",
        "        'positions': positions        # patches_per_megapatchê°œ ìœ„ì¹˜ ì •ë³´\n",
        "    }\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™” í•¨ìˆ˜\n",
        "def visualize_patch_splitting(megapatch_path, save_path=None):\n",
        "    \"\"\"\n",
        "    ğŸ“Š ë©”ê°€íŒ¨ì¹˜ ë¶„í•  ê³¼ì •ì„ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ (ë””ë²„ê¹… ë° í™•ì¸ìš©)\n",
        "\n",
        "    Args:\n",
        "        megapatch_path (str): ì‹œê°í™”í•  ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        save_path (str, optional): ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬\n",
        "        processed = process_megapatch_complete(megapatch_path)\n",
        "\n",
        "        # ì‹œê°í™” ì„¤ì •\n",
        "        fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
        "        fig.suptitle(f'ë©”ê°€íŒ¨ì¹˜ ë¶„í•  ê²°ê³¼: {os.path.basename(megapatch_path)}', fontsize=16)\n",
        "\n",
        "        # ì›ë³¸ ë©”ê°€íŒ¨ì¹˜ í‘œì‹œ\n",
        "        megapatch = cv2.imread(megapatch_path)\n",
        "        megapatch = cv2.cvtColor(megapatch, cv2.COLOR_BGR2RGB)\n",
        "        axes[0, 0].imshow(megapatch)\n",
        "        axes[0, 0].set_title('ì›ë³¸ ë©”ê°€íŒ¨ì¹˜\\n(1024x1024)', fontsize=10)\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # ì²˜ìŒ 5ê°œ íŒ¨ì¹˜ì˜ 3-stream í‘œì‹œ\n",
        "        for i in range(min(5, len(processed['lr_patches']))):\n",
        "            row = i // 5 + 1\n",
        "            col_start = (i % 5) + 1\n",
        "\n",
        "            # LR íŒ¨ì¹˜ (64x64)\n",
        "            axes[0, col_start].imshow(processed['lr_patches'][i])\n",
        "            axes[0, col_start].set_title(f'LR {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[0, col_start].axis('off')\n",
        "\n",
        "            # HR íŒ¨ì¹˜ (256x256)\n",
        "            axes[1, col_start].imshow(processed['hr_patches'][i])\n",
        "            axes[1, col_start].set_title(f'HR {i+1}\\n(256x256)', fontsize=8)\n",
        "            axes[1, col_start].axis('off')\n",
        "\n",
        "            # Global í† í° (64x64)\n",
        "            axes[2, col_start].imshow(processed['global_tokens'][i])\n",
        "            axes[2, col_start].set_title(f'Global {i+1}\\n(64x64)', fontsize=8)\n",
        "            axes[2, col_start].axis('off')\n",
        "\n",
        "        # ë¹ˆ subplotë“¤ ìˆ¨ê¸°ê¸°\n",
        "        for i in range(4):\n",
        "            for j in range(6):\n",
        "                if i > 2 or (i == 0 and j == 0) or (i > 0 and j == 0):\n",
        "                    continue\n",
        "                if not axes[i, j].has_data():\n",
        "                    axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"âœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # í†µê³„ ì •ë³´ ì¶œë ¥\n",
        "        print(f\"ğŸ“Š ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ ê²°ê³¼:\")\n",
        "        print(f\"   - LR íŒ¨ì¹˜ ê°œìˆ˜: {len(processed['lr_patches'])}ê°œ (ê° 64x64)\")\n",
        "        print(f\"   - HR íŒ¨ì¹˜ ê°œìˆ˜: {len(processed['hr_patches'])}ê°œ (ê° 256x256)\")\n",
        "        print(f\"   - Global í† í° ê°œìˆ˜: {len(processed['global_tokens'])}ê°œ (ê° 64x64)\")\n",
        "        print(f\"   - ìœ„ì¹˜ ì •ë³´: {processed['positions'][:5]}... (ì²˜ìŒ 5ê°œ)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 3 ì™„ë£Œ: ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ 1024x1024 ì´ë¯¸ì§€ë¥¼ 16ê°œì˜ 3-stream íŒ¨ì¹˜ë¡œ ë¶„í• í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS5SQBHRUJ3L"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 4: Feature Extractorì™€ HR Selection\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5-YAFexUJ3L"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ë„¤ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ResNet ê¸°ë°˜ feature extractorì™€ ë…¼ë¬¸ì˜ threshold ë°©ì‹ HR selectionì„ êµ¬í˜„í•©ë‹ˆë‹¤\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ”¬ ResNet18 ê¸°ë°˜ Feature Extractor\n",
        "\n",
        "    ì—­í• :\n",
        "    - 64x64 ì´ë¯¸ì§€ìš© (LR, Global streams)\n",
        "    - 256x256 ì´ë¯¸ì§€ìš© (HR stream)\n",
        "    - ì´ë¯¸ì§€ë¥¼ ê³ ì • í¬ê¸° feature vectorë¡œ ë³€í™˜\n",
        "\n",
        "    ì„ íƒì§€:\n",
        "    - ResNet18: ì•ˆì •ì ì´ê³  ê²€ì¦ëœ ì„±ëŠ¥ (ì¶”ì²œ)\n",
        "    - MobileNetV3: ë” ë¹ ë¥´ì§€ë§Œ ì„±ëŠ¥ ì•½ê°„ ë‚®ìŒ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, model_type='resnet18', pretrained=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): ì¶œë ¥ feature ì°¨ì› (256 or 384)\n",
        "            model_type (str): ì‚¬ìš©í•  ë°±ë³¸ ëª¨ë¸ ('resnet18', 'mobilenet', 'efficientnet')\n",
        "            pretrained (bool): ImageNet ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€\n",
        "        \"\"\"\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.model_type = model_type\n",
        "\n",
        "        # ë°±ë³¸ ëª¨ë¸ ì„ íƒ ë° ì„¤ì •\n",
        "        if model_type == 'resnet18':\n",
        "            # ResNet18: ì•ˆì •ì ì´ê³  ë„ë¦¬ ì‚¬ìš©ë¨ (11M parameters)\n",
        "            resnet = models.resnet18(pretrained=pretrained)\n",
        "            self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # avgpool, fc ì œê±°\n",
        "            backbone_out_dim = 512\n",
        "\n",
        "        elif model_type == 'mobilenet':\n",
        "            # MobileNetV3-Small: ë¹ ë¥´ê³  ê²½ëŸ‰ (2.5M parameters)\n",
        "            from torchvision.models import mobilenet_v3_small\n",
        "            mobilenet = mobilenet_v3_small(pretrained=pretrained)\n",
        "            self.backbone = mobilenet.features\n",
        "            backbone_out_dim = 576\n",
        "\n",
        "        elif model_type == 'efficientnet':\n",
        "            # EfficientNet-B0: íš¨ìœ¨ì ì´ê³  ì„±ëŠ¥ ì¢‹ìŒ (5.3M parameters)\n",
        "            from torchvision.models import efficientnet_b0\n",
        "            efficientnet = efficientnet_b0(pretrained=pretrained)\n",
        "            self.backbone = efficientnet.features\n",
        "            backbone_out_dim = 1280\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}\")\n",
        "\n",
        "        # Global Average Pooling: spatial dimensionsë¥¼ 1x1ë¡œ ì¶•ì†Œ\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Feature projection: backbone output â†’ ì›í•˜ëŠ” feature dimension\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(backbone_out_dim, feature_dim),\n",
        "            nn.LayerNorm(feature_dim),  # Layer Normalizationìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1)             # 10% ë“œë¡­ì•„ì›ƒìœ¼ë¡œ overfitting ë°©ì§€\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… {model_type.upper()} Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "        print(f\"   - ë°±ë³¸ ì¶œë ¥ ì°¨ì›: {backbone_out_dim}\")\n",
        "        print(f\"   - ìµœì¢… feature ì°¨ì›: {feature_dim}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ feature vectorsë¡œ ë³€í™˜\n",
        "\n",
        "        Args:\n",
        "            x: [batch_size, 3, H, W] - RGB ì´ë¯¸ì§€ ë°°ì¹˜\n",
        "               H, WëŠ” 64 (LR, Global) ë˜ëŠ” 256 (HR)\n",
        "\n",
        "        Returns:\n",
        "            [batch_size, feature_dim] - ì¶”ì¶œëœ feature vectors\n",
        "        \"\"\"\n",
        "        # 1. ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ feature map ì¶”ì¶œ\n",
        "        features = self.backbone(x)      # [B, C, H', W'] - ì˜ˆ: [B, 512, H'/32, W'/32]\n",
        "\n",
        "        # 2. Global Average Poolingìœ¼ë¡œ spatial dimensions ì¶•ì†Œ\n",
        "        pooled = self.avgpool(features)  # [B, C, 1, 1]\n",
        "\n",
        "        # 3. Flatten: [B, C, 1, 1] â†’ [B, C]\n",
        "        flattened = pooled.view(pooled.size(0), -1)  # [B, backbone_out_dim]\n",
        "\n",
        "        # 4. Projectionì„ í†µí•´ ì›í•˜ëŠ” ì°¨ì›ìœ¼ë¡œ ë³€í™˜\n",
        "        projected = self.projection(flattened)       # [B, feature_dim]\n",
        "\n",
        "        return projected\n",
        "\n",
        "\n",
        "class ThresholdBasedHRSelector(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ ë…¼ë¬¸ì˜ ì •í™•í•œ ë°©ì‹: Threshold ê¸°ë°˜ HR Feature Selection\n",
        "\n",
        "    FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - LR attention scoresì—ì„œ thresholdë¥¼ ê³„ì‚°\n",
        "    - Threshold ì´ìƒì¸ íŒ¨ì¹˜ë“¤ë§Œ HRë¡œ ì„ íƒ\n",
        "    - ì•½ 10% ì •ë„ê°€ ì„ íƒë˜ë„ë¡ ë™ì  ì¡°ì •\n",
        "    - Top-K ê³ ì • ì„ íƒì´ ì•„ë‹Œ ì‹¤ì œ ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target_selection_ratio=0.1, min_patches=1, max_patches=4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            target_selection_ratio (float): ëª©í‘œ ì„ íƒ ë¹„ìœ¨ (0.1 = ì•½ 10%)\n",
        "            min_patches (int): ìµœì†Œ ì„ íƒ íŒ¨ì¹˜ ê°œìˆ˜ (ë„ˆë¬´ ì ìœ¼ë©´ ê°•ì œ ì„ íƒ)\n",
        "            max_patches (int): ìµœëŒ€ ì„ íƒ íŒ¨ì¹˜ ê°œìˆ˜ (ë„ˆë¬´ ë§ìœ¼ë©´ ì œí•œ)\n",
        "        \"\"\"\n",
        "        super(ThresholdBasedHRSelector, self).__init__()\n",
        "        self.target_selection_ratio = target_selection_ratio\n",
        "        self.min_patches = min_patches\n",
        "        self.max_patches = max_patches\n",
        "\n",
        "        print(f\"âœ… Threshold ê¸°ë°˜ HR Selector ì´ˆê¸°í™”\")\n",
        "        print(f\"   - ëª©í‘œ ì„ íƒ ë¹„ìœ¨: {target_selection_ratio*100:.1f}%\")\n",
        "        print(f\"   - ì„ íƒ ë²”ìœ„: {min_patches}~{max_patches}ê°œ\")\n",
        "\n",
        "    def forward(self, lr_attention_scores, hr_features):\n",
        "        \"\"\"\n",
        "        Threshold ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”í•œ HR featuresë§Œ ì„ íƒ\n",
        "\n",
        "        Args:\n",
        "            lr_attention_scores: [batch_size, 16] - LR patchesì˜ attention scores\n",
        "            hr_features: [batch_size, 16, feature_dim] - HR patch features\n",
        "\n",
        "        Returns:\n",
        "            selected_hr_features: [batch_size, max_patches, feature_dim] - ì„ íƒëœ HR features\n",
        "            selection_masks: [batch_size, 16] - binary selection mask (ì‹œê°í™”ìš©)\n",
        "            thresholds: [batch_size] - ì‚¬ìš©ëœ threshold ê°’ë“¤ (ë¶„ì„ìš©)\n",
        "        \"\"\"\n",
        "        batch_size, num_patches, feature_dim = hr_features.shape\n",
        "\n",
        "        selected_hr_features = []  # ì„ íƒëœ HR featuresë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        selection_masks = []       # ì„ íƒ ë§ˆìŠ¤í¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        thresholds = []           # ì‚¬ìš©ëœ thresholdë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "        # ë°°ì¹˜ì˜ ê° ìƒ˜í”Œì— ëŒ€í•´ ê°œë³„ ì²˜ë¦¬\n",
        "        for b in range(batch_size):\n",
        "            att_scores = lr_attention_scores[b]  # [16] - ì´ ìƒ˜í”Œì˜ attention scores\n",
        "\n",
        "            # Step 1: Adaptive threshold ê³„ì‚°\n",
        "            threshold = self._compute_adaptive_threshold(att_scores)\n",
        "\n",
        "            # Step 2: Threshold ì ìš©í•˜ì—¬ íŒ¨ì¹˜ ì„ íƒ\n",
        "            mask = att_scores > threshold\n",
        "            selected_indices = torch.where(mask)[0]  # threshold ì´ìƒì¸ íŒ¨ì¹˜ë“¤ì˜ ì¸ë±ìŠ¤\n",
        "\n",
        "            num_selected = len(selected_indices)\n",
        "\n",
        "            # Step 3: ì„ íƒëœ íŒ¨ì¹˜ ìˆ˜ ê²€ì¦ ë° ì¡°ì •\n",
        "            if num_selected < self.min_patches:\n",
        "                # ë„ˆë¬´ ì ê²Œ ì„ íƒëœ ê²½ìš°: ê°•ì œë¡œ ìµœì†Œ ê°œìˆ˜ë§Œí¼ ì„ íƒ\n",
        "                _, top_indices = torch.topk(att_scores, self.min_patches)\n",
        "                selected_indices = top_indices\n",
        "                threshold = att_scores[top_indices[-1]]  # ìƒˆë¡œìš´ threshold\n",
        "\n",
        "            elif num_selected > self.max_patches:\n",
        "                # ë„ˆë¬´ ë§ì´ ì„ íƒëœ ê²½ìš°: ìƒìœ„ max_patchesê°œë§Œ ì„ íƒ\n",
        "                selected_scores = att_scores[selected_indices]\n",
        "                _, top_within_selected = torch.topk(selected_scores, self.max_patches)\n",
        "                selected_indices = selected_indices[top_within_selected]\n",
        "                threshold = att_scores[selected_indices[-1]]  # ìƒˆë¡œìš´ threshold\n",
        "\n",
        "            # Step 4: ì„ íƒëœ HR features ì¶”ì¶œ\n",
        "            selected_features = hr_features[b, selected_indices]  # [num_selected, feature_dim]\n",
        "\n",
        "            # Step 5: ê³ ì • í¬ê¸°ë¡œ íŒ¨ë”© (ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´)\n",
        "            if len(selected_indices) < self.max_patches:\n",
        "                padding_size = self.max_patches - len(selected_indices)\n",
        "                padding = torch.zeros(padding_size, feature_dim, device=hr_features.device)\n",
        "                selected_features = torch.cat([selected_features, padding], dim=0)\n",
        "\n",
        "            selected_hr_features.append(selected_features)\n",
        "\n",
        "            # Step 6: Binary mask ìƒì„± (ì‹œê°í™” ë° ë¶„ì„ìš©)\n",
        "            binary_mask = torch.zeros_like(att_scores)\n",
        "            if len(selected_indices) > 0:\n",
        "                binary_mask[selected_indices] = 1.0\n",
        "            selection_masks.append(binary_mask)\n",
        "\n",
        "            thresholds.append(threshold)\n",
        "\n",
        "        # ë¦¬ìŠ¤íŠ¸ë“¤ì„ í…ì„œë¡œ ë³€í™˜\n",
        "        selected_hr_features = torch.stack(selected_hr_features)  # [B, max_patches, feature_dim]\n",
        "        selection_masks = torch.stack(selection_masks)            # [B, 16]\n",
        "        thresholds = torch.stack(thresholds)                      # [B]\n",
        "\n",
        "        return selected_hr_features, selection_masks, thresholds\n",
        "\n",
        "    def _compute_adaptive_threshold(self, attention_scores):\n",
        "        \"\"\"\n",
        "        ì ì‘ì  threshold ê³„ì‚° - ì—¬ëŸ¬ ë°©ë²• ì¤‘ ê°€ì¥ ì ì ˆí•œ ê²ƒ ì„ íƒ\n",
        "\n",
        "        Args:\n",
        "            attention_scores: [16] - í•˜ë‚˜ì˜ ìƒ˜í”Œì— ëŒ€í•œ attention scores\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: ê³„ì‚°ëœ threshold ê°’\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Method 1: Otsu threshold (ì´ì§„í™”ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìµœì  ë¶„í• ì )\n",
        "            # ê°€ì¥ ì¢‹ì€ ë°©ë²•ì´ì§€ë§Œ sklearn í•„ìš”\n",
        "            scores_np = attention_scores.detach().cpu().numpy()\n",
        "            threshold_val = threshold_otsu(scores_np)\n",
        "            return torch.tensor(threshold_val, device=attention_scores.device)\n",
        "\n",
        "        except:\n",
        "            # Method 2: Percentile-based threshold (Fallback)\n",
        "            # ìƒìœ„ target_selection_ratio*2 ì •ë„ê°€ ì„ íƒë˜ë„ë¡\n",
        "            percentile = 1.0 - (self.target_selection_ratio * 2)  # 80th percentile for 10% target\n",
        "            threshold_val = torch.quantile(attention_scores, percentile)\n",
        "            return threshold_val\n",
        "\n",
        "    def get_selection_statistics(self, selection_masks):\n",
        "        \"\"\"\n",
        "        ì„ íƒ í†µê³„ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§ìš©)\n",
        "\n",
        "        Args:\n",
        "            selection_masks: [batch_size, 16] - binary selection masks\n",
        "\n",
        "        Returns:\n",
        "            dict: ì„ íƒ í†µê³„ ì •ë³´\n",
        "        \"\"\"\n",
        "        num_selected_per_sample = selection_masks.sum(dim=1)  # [batch_size]\n",
        "\n",
        "        stats = {\n",
        "            'mean_selected': num_selected_per_sample.float().mean().item(),\n",
        "            'min_selected': num_selected_per_sample.min().item(),\n",
        "            'max_selected': num_selected_per_sample.max().item(),\n",
        "            'selection_ratio': (num_selected_per_sample.float() / selection_masks.shape[1]).mean().item(),\n",
        "            'std_selected': num_selected_per_sample.float().std().item()\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "\n",
        "# Feature Extractor ì„±ëŠ¥ ë¹„êµ í•¨ìˆ˜\n",
        "def compare_feature_extractors():\n",
        "    \"\"\"\n",
        "    ğŸ”¬ ë‹¤ì–‘í•œ Feature Extractorë“¤ì˜ ì„±ëŠ¥ê³¼ ì†ë„ ë¹„êµ\n",
        "    ì‹¤ì œ ì„ íƒì— ë„ì›€ì„ ì£¼ëŠ” ë²¤ì¹˜ë§ˆí¬\n",
        "    \"\"\"\n",
        "    print(\"ğŸ”¬ Feature Extractor ì„±ëŠ¥ ë¹„êµ\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ ë°ì´í„°\n",
        "    dummy_lr = torch.randn(4, 3, 64, 64)    # LR íŒ¨ì¹˜ë“¤\n",
        "    dummy_hr = torch.randn(4, 3, 256, 256)  # HR íŒ¨ì¹˜ë“¤\n",
        "\n",
        "    extractors = {\n",
        "        'ResNet18': ResNetFeatureExtractor(feature_dim=256, model_type='resnet18'),\n",
        "        'MobileNetV3': ResNetFeatureExtractor(feature_dim=256, model_type='mobilenet'),\n",
        "        'EfficientNet-B0': ResNetFeatureExtractor(feature_dim=256, model_type='efficientnet')\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, extractor in extractors.items():\n",
        "        print(f\"\\nğŸ“Š {name} í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
        "\n",
        "        # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
        "        total_params = sum(p.numel() for p in extractor.parameters())\n",
        "        trainable_params = sum(p.numel() for p in extractor.parameters() if p.requires_grad)\n",
        "\n",
        "        # ì†ë„ ì¸¡ì • (LR íŒ¨ì¹˜)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10ë²ˆ ë°˜ë³µ ì¸¡ì •\n",
        "                _ = extractor(dummy_lr)\n",
        "        lr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        # ì†ë„ ì¸¡ì • (HR íŒ¨ì¹˜)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # 10ë²ˆ ë°˜ë³µ ì¸¡ì •\n",
        "                _ = extractor(dummy_hr)\n",
        "        hr_time = (time.time() - start_time) / 10\n",
        "\n",
        "        results[name] = {\n",
        "            'total_params': total_params,\n",
        "            'trainable_params': trainable_params,\n",
        "            'lr_time_ms': lr_time * 1000,\n",
        "            'hr_time_ms': hr_time * 1000\n",
        "        }\n",
        "\n",
        "        print(f\"   íŒŒë¼ë¯¸í„° ìˆ˜: {total_params/1e6:.1f}M\")\n",
        "        print(f\"   LR ì²˜ë¦¬ ì†ë„: {lr_time*1000:.1f}ms\")\n",
        "        print(f\"   HR ì²˜ë¦¬ ì†ë„: {hr_time*1000:.1f}ms\")\n",
        "\n",
        "    # ì¶”ì²œ ì¶œë ¥\n",
        "    print(f\"\\nğŸ¯ ì¶”ì²œ:\")\n",
        "    print(f\"   - ì•ˆì •ì„± ìš°ì„ : ResNet18 (ê²€ì¦ëœ ì„±ëŠ¥)\")\n",
        "    print(f\"   - ì†ë„ ìš°ì„ : MobileNetV3 (ê°€ì¥ ë¹ ë¦„)\")\n",
        "    print(f\"   - ë°¸ëŸ°ìŠ¤: EfficientNet-B0 (ì„±ëŠ¥-ì†ë„ ì ˆì¶©)\")\n",
        "    print(f\"   - 2ì¼ ì•ˆì— ì™„ì£¼: ResNet18 ë˜ëŠ” MobileNetV3\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ì‚¬ìš©ë²• ì˜ˆì‹œ\n",
        "def example_usage():\n",
        "    \"\"\"Feature Extractorì™€ HR Selector ì‚¬ìš© ì˜ˆì‹œ\"\"\"\n",
        "    print(\"ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:\")\n",
        "\n",
        "    # Feature Extractor ìƒì„±\n",
        "    feature_extractor = ResNetFeatureExtractor(\n",
        "        feature_dim=256,\n",
        "        model_type='resnet18',  # 'resnet18', 'mobilenet', 'efficientnet' ì¤‘ ì„ íƒ\n",
        "        pretrained=True\n",
        "    )\n",
        "\n",
        "    # HR Selector ìƒì„±\n",
        "    hr_selector = ThresholdBasedHRSelector(\n",
        "        target_selection_ratio=0.1,  # 10% ì„ íƒ ëª©í‘œ\n",
        "        min_patches=1,               # ìµœì†Œ 1ê°œ\n",
        "        max_patches=4                # ìµœëŒ€ 4ê°œ\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 4 ì™„ë£Œ: Feature Extractorì™€ HR Selector ì •ì˜ ì™„ë£Œ!\")\n",
        "print(\"ResNet18 vs MobileNet vs EfficientNet ì¤‘ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4jZt1HEUJ3M"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 5: ì‹¤ì œ ë°ì´í„° ë¡œë”© (ë¡œì»¬ ê²½ë¡œ)\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaS2aMbTUJ3M"
      },
      "outputs": [],
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 5: ì‹¤ì œ ë°ì´í„° ë¡œë”© (ë¡œì»¬ ê²½ë¡œ)\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ë‹¤ì„¯ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê³  í™˜ìë³„ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤\n",
        "\n",
        "# ğŸ  ë¡œì»¬ ê²½ë¡œ ì„¤ì • (ì§‘ ì»´í“¨í„°ìš©) - ì´ë¯¸ ì••ì¶• í•´ì œë¨\n",
        "zip_path = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710.zip\"  # ì›ë³¸ ZIP (ì°¸ì¡°ìš©)\n",
        "excel_path = r\"C:\\Users\\ehdwk\\Downloads\\MIL_TURB_240918_Modified.xlsx\"\n",
        "base_dir = r\"C:\\Users\\ehdwk\\Downloads\\ExternalUSB_Bladder_240710\"  # ì´ë¯¸ ì••ì¶• í•´ì œëœ í´ë”\n",
        "\n",
        "# ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì • (ì²´í¬í¬ì¸íŠ¸, ë¡œê·¸, ê²°ê³¼ ì €ì¥ìš©)\n",
        "work_dir = r\"C:\\Users\\ehdwk\\Downloads\\FlexAttention_Results\"\n",
        "checkpoint_dir = os.path.join(work_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(work_dir, \"logs\")\n",
        "cache_dir = os.path.join(work_dir, \"cache\")\n",
        "result_dir = os.path.join(work_dir, \"results\")\n",
        "\n",
        "# í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ ìƒì„±\n",
        "for directory in [work_dir, checkpoint_dir, log_dir, cache_dir, result_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    print(f\"ğŸ“ ë””ë ‰í† ë¦¬ ì¤€ë¹„: {directory}\")\n",
        "\n",
        "print(f\"\\nğŸ  ë¡œì»¬ í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\n",
        "print(f\"   ZIP íŒŒì¼: {zip_path}\")\n",
        "print(f\"   Excel íŒŒì¼: {excel_path}\")\n",
        "print(f\"   ì‘ì—… ë””ë ‰í† ë¦¬: {work_dir}\")\n",
        "\n",
        "# íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
        "print(f\"\\nğŸ” íŒŒì¼/í´ë” ì¡´ì¬ í™•ì¸:\")\n",
        "print(f\"   ì••ì¶• í•´ì œëœ í´ë” ì¡´ì¬: {os.path.exists(base_dir)}\")\n",
        "print(f\"   Excel íŒŒì¼ ì¡´ì¬: {os.path.exists(excel_path)}\")\n",
        "\n",
        "if not os.path.exists(base_dir):\n",
        "    print(f\"âŒ ì••ì¶• í•´ì œëœ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_dir}\")\n",
        "    print(f\"   ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!\")\n",
        "\n",
        "if not os.path.exists(excel_path):\n",
        "    print(f\"âŒ Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}\")\n",
        "    print(f\"   ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!\")\n",
        "\n",
        "# ì••ì¶• í•´ì œëœ í´ë”ì˜ ë‚´ìš© í™•ì¸\n",
        "if os.path.exists(base_dir):\n",
        "    folder_contents = os.listdir(base_dir)\n",
        "    print(f\"ğŸ“ í´ë” ë‚´ìš© (ì²˜ìŒ 10ê°œ): {folder_contents[:10]}\")\n",
        "    print(f\"ğŸ“‚ ì´ íŒŒì¼/í´ë” ê°œìˆ˜: {len(folder_contents)}ê°œ\")\n",
        "\n",
        "# ì‹¤ì œ ë°ì´í„° ë¡œë”© ì‹¤í–‰\n",
        "print(f\"\\nğŸš€ ë°ì´í„° ë¡œë”© ì‹œì‘...\")\n",
        "log_gpu_memory(\"ë°ì´í„° ë¡œë”© ì „\")\n",
        "\n",
        "try:\n",
        "    # Part 2ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ ì‚¬ìš©\n",
        "    patient_data = load_and_match_data(\n",
        "        zip_path=zip_path,\n",
        "        excel_path=excel_path,\n",
        "        base_dir=base_dir\n",
        "    )\n",
        "\n",
        "    print(f\"\\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!\")\n",
        "    print(f\"   ì´ í™˜ì ìˆ˜: {len(patient_data)}ëª…\")\n",
        "\n",
        "    # í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜ í†µê³„\n",
        "    image_counts = [len(info['images']) for info in patient_data.values()]\n",
        "    if image_counts:\n",
        "        print(f\"   í™˜ìë³„ ì´ë¯¸ì§€ ê°œìˆ˜:\")\n",
        "        print(f\"     - í‰ê· : {np.mean(image_counts):.1f}ê°œ\")\n",
        "        print(f\"     - ì¤‘ê°„ê°’: {np.median(image_counts):.1f}ê°œ\")\n",
        "        print(f\"     - ìµœì†Œ: {min(image_counts)}ê°œ\")\n",
        "        print(f\"     - ìµœëŒ€: {max(image_counts)}ê°œ\")\n",
        "        print(f\"     - 75% ì§€ì : {np.percentile(image_counts, 75):.1f}ê°œ\")\n",
        "\n",
        "    # ë¼ë²¨ ë¶„í¬ í™•ì¸\n",
        "    t_labels = [info.get('t_label', 0) for info in patient_data.values()]\n",
        "    recur_labels = [info.get('recur_label', 0) for info in patient_data.values()]\n",
        "\n",
        "    print(f\"\\nğŸ“Š ë¼ë²¨ ë¶„í¬:\")\n",
        "    print(f\"   T-stage - ì €ìœ„í—˜(0): {t_labels.count(0)}ëª…, ê³ ìœ„í—˜(1): {t_labels.count(1)}ëª…\")\n",
        "    print(f\"   ì¬ë°œ - ì—†ìŒ(0): {recur_labels.count(0)}ëª…, ìˆìŒ(1): {recur_labels.count(1)}ëª…\")\n",
        "\n",
        "    # ìƒ˜í”Œ í™˜ì ì •ë³´ ì¶œë ¥\n",
        "    sample_patient_id = list(patient_data.keys())[0]\n",
        "    sample_info = patient_data[sample_patient_id]\n",
        "    print(f\"\\nğŸ‘¤ ìƒ˜í”Œ í™˜ì ì •ë³´ ({sample_patient_id}):\")\n",
        "    print(f\"   ì´ë¯¸ì§€ ê°œìˆ˜: {len(sample_info['images'])}ê°œ\")\n",
        "    print(f\"   T-stage: {sample_info.get('t_stage', 'Unknown')}\")\n",
        "    print(f\"   ì¬ë°œ: {sample_info.get('recurrence', 'Unknown')}\")\n",
        "    print(f\"   ì²« ë²ˆì§¸ ì´ë¯¸ì§€: {sample_info['images'][0] if sample_info['images'] else 'None'}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    patient_data = {}\n",
        "\n",
        "log_gpu_memory(\"ë°ì´í„° ë¡œë”© í›„\")\n",
        "\n",
        "# ë°ì´í„° ì €ì¥ (ë‚˜ì¤‘ì— ë¹ ë¥´ê²Œ ë¡œë”©í•˜ê¸° ìœ„í•´)\n",
        "if patient_data:\n",
        "    data_save_path = os.path.join(cache_dir, \"patient_data.pkl\")\n",
        "    try:\n",
        "        with open(data_save_path, 'wb') as f:\n",
        "            pickle.dump(patient_data, f)\n",
        "        print(f\"\\nğŸ’¾ í™˜ì ë°ì´í„° ì €ì¥ ì™„ë£Œ: {data_save_path}\")\n",
        "        print(f\"   ë‹¤ìŒì—ëŠ” ì´ íŒŒì¼ë¡œ ë¹ ë¥´ê²Œ ë¡œë”© ê°€ëŠ¥!\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 5 ì™„ë£Œ: ì‹¤ì œ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "print(f\"í™˜ì ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤: {len(patient_data) if patient_data else 0}ëª…\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "# Part 5ì— ì¶”ê°€\n",
        "patient_ids = list(patient_data.keys())[:20]  # ì²˜ìŒ 20ëª…ë§Œ\n",
        "patient_data = {pid: patient_data[pid] for pid in patient_ids}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiBUd9i7UJ3M"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 6: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention\n",
        "# ========================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P56JKxAdUJ3M"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class CheckpointManager:\n",
        "    \"\"\"\n",
        "    ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
        "\n",
        "    ê¸°ëŠ¥:\n",
        "    - ë§¤ epochë§ˆë‹¤ ëª¨ë¸ ìƒíƒœ ìë™ ì €ì¥\n",
        "    - í›ˆë ¨ ì¤‘ë‹¨ì‹œ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥\n",
        "    - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ì¥\n",
        "    - í›ˆë ¨ ë¡œê·¸ ë° í†µê³„ ì €ì¥\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir, max_keep=5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            checkpoint_dir (str): ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "            max_keep (int): ìµœëŒ€ ë³´ê´€í•  ì²´í¬í¬ì¸íŠ¸ ê°œìˆ˜ (ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ)\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.max_keep = max_keep\n",
        "        self.best_score = 0.0\n",
        "        self.training_log = []\n",
        "\n",
        "        # ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        print(f\"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”: {checkpoint_dir}\")\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, epoch, fold,\n",
        "                       train_loss, val_metrics=None, is_best=False):\n",
        "        \"\"\"\n",
        "        ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë§¤ epochë§ˆë‹¤ í˜¸ì¶œ)\n",
        "\n",
        "        Args:\n",
        "            model: í›ˆë ¨ ì¤‘ì¸ ëª¨ë¸\n",
        "            optimizer: ì˜µí‹°ë§ˆì´ì €\n",
        "            scheduler: ìŠ¤ì¼€ì¤„ëŸ¬\n",
        "            epoch: í˜„ì¬ epoch\n",
        "            fold: í˜„ì¬ fold ë²ˆí˜¸\n",
        "            train_loss: í›ˆë ¨ loss\n",
        "            val_metrics: ê²€ì¦ ë©”íŠ¸ë¦­ë“¤ (dict)\n",
        "            is_best: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì¸ì§€ ì—¬ë¶€\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ì •ë³´\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.module.state_dict() if hasattr(model, 'module') else model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp,\n",
        "            'best_score': self.best_score\n",
        "        }\n",
        "\n",
        "        # ì •ê·œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
        "        checkpoint_path = os.path.join(\n",
        "            self.checkpoint_dir,\n",
        "            f\"checkpoint_fold{fold}_epoch{epoch:03d}_{timestamp}.pt\"\n",
        "        )\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "        # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ë¡œ ë§í¬ (ì¬ì‹œì‘ ì‹œ ì‚¬ìš©)\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ì¥\n",
        "        if is_best:\n",
        "            best_path = os.path.join(self.checkpoint_dir, f\"best_model_fold{fold}.pt\")\n",
        "            torch.save(checkpoint, best_path)\n",
        "            self.best_score = val_metrics.get('f1', 0.0) if val_metrics else 0.0\n",
        "            print(f\"ğŸ† ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥! F1: {self.best_score:.4f}\")\n",
        "\n",
        "        # í›ˆë ¨ ë¡œê·¸ ì—…ë°ì´íŠ¸\n",
        "        log_entry = {\n",
        "            'epoch': epoch,\n",
        "            'fold': fold,\n",
        "            'train_loss': train_loss,\n",
        "            'val_metrics': val_metrics or {},\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "        self.training_log.append(log_entry)\n",
        "\n",
        "        # ë¡œê·¸ íŒŒì¼ ì €ì¥\n",
        "        log_path = os.path.join(self.checkpoint_dir, f\"training_log_fold{fold}.json\")\n",
        "        with open(log_path, 'w') as f:\n",
        "            json.dump(self.training_log, f, indent=2)\n",
        "\n",
        "        print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: Fold {fold}, Epoch {epoch}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬\n",
        "        self._cleanup_old_checkpoints(fold)\n",
        "\n",
        "    def _cleanup_old_checkpoints(self, fold):\n",
        "        \"\"\"ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì •ë¦¬\"\"\"\n",
        "        import glob\n",
        "\n",
        "        # í•´ë‹¹ foldì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì°¾ê¸°\n",
        "        pattern = os.path.join(self.checkpoint_dir, f\"checkpoint_fold{fold}_*.pt\")\n",
        "        checkpoints = glob.glob(pattern)\n",
        "\n",
        "        # ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
        "        checkpoints.sort(key=os.path.getctime)\n",
        "\n",
        "        # max_keep ê°œìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ\n",
        "        while len(checkpoints) > self.max_keep:\n",
        "            old_checkpoint = checkpoints.pop(0)\n",
        "            try:\n",
        "                os.remove(old_checkpoint)\n",
        "                print(f\"ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: {os.path.basename(old_checkpoint)}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    def load_latest_checkpoint(self, fold):\n",
        "        \"\"\"\n",
        "        ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë¡œë”© (ì¬ì‹œì‘ ì‹œ ì‚¬ìš©)\n",
        "\n",
        "        Args:\n",
        "            fold: ë¡œë”©í•  fold ë²ˆí˜¸\n",
        "\n",
        "        Returns:\n",
        "            dict or None: ì²´í¬í¬ì¸íŠ¸ ë°ì´í„°, ì—†ìœ¼ë©´ None\n",
        "        \"\"\"\n",
        "        latest_path = os.path.join(self.checkpoint_dir, f\"latest_fold{fold}.pt\")\n",
        "\n",
        "        if os.path.exists(latest_path):\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            print(f\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: Fold {fold}, Epoch {checkpoint['epoch']}\")\n",
        "            return checkpoint\n",
        "        else:\n",
        "            print(f\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ: Fold {fold} (ì²˜ìŒë¶€í„° ì‹œì‘)\")\n",
        "            return None\n",
        "\n",
        "\n",
        "class HierarchicalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ FlexAttention ë…¼ë¬¸ì˜ í•µì‹¬: Hierarchical Self-Attention\n",
        "\n",
        "    í•µì‹¬ ì•„ì´ë””ì–´:\n",
        "    - ì¼ë°˜ Self-Attention: O(nÂ²) - ëª¨ë“  í† í°ì´ ëª¨ë“  í† í°ê³¼ ìƒí˜¸ì‘ìš©\n",
        "    - Hierarchical: O(nÃ—M) - ì„ íƒëœ HR í† í°ë§Œ ìƒí˜¸ì‘ìš© (M << n)\n",
        "    - ê³„ì‚°ëŸ‰ ëŒ€í­ ê°ì†Œí•˜ë©´ì„œ ì„±ëŠ¥ ìœ ì§€!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_heads=4, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): feature ì°¨ì› (256 ì¶”ì²œ, 384ëŠ” ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)\n",
        "            num_heads (int): attention head ê°œìˆ˜ (4 ì¶”ì²œ, 6ì€ ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)\n",
        "            dropout (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
        "        \"\"\"\n",
        "        super(HierarchicalSelfAttention, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = feature_dim // num_heads\n",
        "\n",
        "        # feature_dimì´ num_headsë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ëŠ”ì§€ í™•ì¸\n",
        "        assert feature_dim % num_heads == 0, f\"feature_dim({feature_dim})ì´ num_heads({num_heads})ë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤!\"\n",
        "\n",
        "        # ğŸ”µ ì¼ë°˜ hidden statesìš© projections (LR + Global + CLS tokens)\n",
        "        self.q_proj = nn.Linear(feature_dim, feature_dim)  # Query projection\n",
        "        self.k_proj = nn.Linear(feature_dim, feature_dim)  # Key projection\n",
        "        self.v_proj = nn.Linear(feature_dim, feature_dim)  # Value projection\n",
        "\n",
        "        # ğŸ”´ HR features ì „ìš© projections (ë…¼ë¬¸ì˜ W'_K, W'_V)\n",
        "        # ì¤‘ìš”: HR featuresëŠ” ë³„ë„ì˜ projectionì„ ì‚¬ìš©!\n",
        "        self.k_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_K for HR\n",
        "        self.v_proj_hr = nn.Linear(feature_dim, feature_dim)  # W'_V for HR\n",
        "\n",
        "        # ì¶œë ¥ projection\n",
        "        self.out_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = math.sqrt(self.head_dim)  # attention scaling factor\n",
        "\n",
        "        print(f\"âœ… Hierarchical Self-Attention ì´ˆê¸°í™”\")\n",
        "        print(f\"   - Feature dim: {feature_dim}, Heads: {num_heads}, Head dim: {self.head_dim}\")\n",
        "\n",
        "    def forward(self, hidden_states, selected_hr_features):\n",
        "        \"\"\"\n",
        "        Hierarchical Self-Attention ê³„ì‚° (ë…¼ë¬¸ì˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜)\n",
        "\n",
        "        Args:\n",
        "            hidden_states: [batch_size, N, feature_dim]\n",
        "                          N = LR tokens + Global tokens + CLS token\n",
        "            selected_hr_features: [batch_size, M, feature_dim]\n",
        "                                M = ì„ íƒëœ HR tokens (ë³´í†µ 1~4ê°œ)\n",
        "\n",
        "        Returns:\n",
        "            output: [batch_size, N, feature_dim] - ì—…ë°ì´íŠ¸ëœ hidden states\n",
        "            attention_map: [batch_size, N-1] - CLS tokenì˜ attention (ë‹¤ìŒ layerìš©)\n",
        "        \"\"\"\n",
        "        batch_size, N, _ = hidden_states.shape          # N: LR + Global + CLS ê°œìˆ˜\n",
        "        _, M, _ = selected_hr_features.shape            # M: ì„ íƒëœ HR ê°œìˆ˜\n",
        "\n",
        "        # ğŸ”µ Step 1: ì¼ë°˜ hidden statesì— ëŒ€í•œ Q, K, V ê³„ì‚°\n",
        "        Q = self.q_proj(hidden_states)      # [B, N, D] - Query (ì–´ë””ì— ì§‘ì¤‘í• ì§€?)\n",
        "        K_h = self.k_proj(hidden_states)    # [B, N, D] - Key (ë‚˜ëŠ” ì´ëŸ° ì •ë³´ì•¼)\n",
        "        V_h = self.v_proj(hidden_states)    # [B, N, D] - Value (ì‹¤ì œ ì „ë‹¬í•  ì •ë³´)\n",
        "\n",
        "        # ğŸ”´ Step 2: HR featuresì— ëŒ€í•œ ë³„ë„ K, V ê³„ì‚° (ë…¼ë¬¸ì˜ í•µì‹¬!)\n",
        "        K_hr = self.k_proj_hr(selected_hr_features)  # [B, M, D] - HRìš© Key\n",
        "        V_hr = self.v_proj_hr(selected_hr_features)  # [B, M, D] - HRìš© Value\n",
        "\n",
        "        # ğŸ”— Step 3: Keyì™€ Valueë¥¼ ì—°ê²° [ì¼ë°˜ tokens + HR tokens]\n",
        "        K_all = torch.cat([K_h, K_hr], dim=1)  # [B, N+M, D] - ëª¨ë“  Keys\n",
        "        V_all = torch.cat([V_h, V_hr], dim=1)  # [B, N+M, D] - ëª¨ë“  Values\n",
        "\n",
        "        # ğŸ§  Step 4: Multi-head attentionì„ ìœ„í•œ reshape\n",
        "        # [B, seq_len, D] â†’ [B, num_heads, seq_len, head_dim]\n",
        "        Q = Q.view(batch_size, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K_all = K_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V_all = V_all.view(batch_size, N+M, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # âš¡ Step 5: Attention ê³„ì‚° - ì—¬ê¸°ì„œ ê³„ì‚°ëŸ‰ O(NÃ—(N+M))\n",
        "        # ì¼ë°˜ Self-Attentionì´ë¼ë©´ O((N+M)Â²)ì´ì§€ë§Œ,\n",
        "        # QueryëŠ” Nê°œë¿ì´ë¯€ë¡œ O(NÃ—(N+M)) = O(NÂ²+NM)\n",
        "        scores = torch.matmul(Q, K_all.transpose(-2, -1)) / self.scale  # [B, H, N, N+M]\n",
        "        attention_weights = F.softmax(scores, dim=-1)                   # attention í™•ë¥ \n",
        "        attention_weights = self.dropout(attention_weights)             # ë“œë¡­ì•„ì›ƒ ì ìš©\n",
        "\n",
        "        # ğŸ¯ Step 6: Attention ì ìš©í•˜ì—¬ ì •ë³´ ì§‘ì•½\n",
        "        attended = torch.matmul(attention_weights, V_all)  # [B, H, N, head_dim]\n",
        "\n",
        "        # ğŸ”„ Step 7: Multi-head ê²°ê³¼ í•©ì¹˜ê¸°\n",
        "        attended = attended.transpose(1, 2).contiguous()  # [B, N, H, head_dim]\n",
        "        attended = attended.view(batch_size, N, self.feature_dim)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“¤ Step 8: ìµœì¢… ì¶œë ¥ projection\n",
        "        output = self.out_proj(attended)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“Š Step 9: ë‹¤ìŒ layerìš© attention map ì¶”ì¶œ\n",
        "        # CLS token (ë§ˆì§€ë§‰ í† í°)ì´ LR tokensì— ì£¼ëŠ” attention\n",
        "        cls_attention = attention_weights[:, :, -1, :N-1]  # [B, H, N-1] - CLS â†’ LR\n",
        "        attention_map = cls_attention.mean(dim=1)          # [B, N-1] - head í‰ê· \n",
        "\n",
        "        return output, attention_map\n",
        "\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í•¨ìˆ˜ë“¤\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ì„¤ì •\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ attention ì‚¬ìš© (PyTorch 2.0+)\n",
        "        try:\n",
        "            torch.backends.cuda.enable_flash_sdp(True)\n",
        "            print(\"âœ… Flash Attention í™œì„±í™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)\")\n",
        "        except:\n",
        "            print(\"âš ï¸  Flash Attention ë¯¸ì§€ì› (PyTorch ë²„ì „ í™•ì¸)\")\n",
        "\n",
        "        # CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "        print(\"âœ… CUDA ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"âœ… GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
        "\n",
        "def log_model_info(model):\n",
        "    \"\"\"ëª¨ë¸ ì •ë³´ ë¡œê¹…\"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"ğŸ” ëª¨ë¸ ì •ë³´:\")\n",
        "    print(f\"   - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ ({total_params/1e6:.1f}M)\")\n",
        "    print(f\"   - í›ˆë ¨ ê°€ëŠ¥: {trainable_params:,}ê°œ ({trainable_params/1e6:.1f}M)\")\n",
        "    print(f\"   - ëª¨ë¸ í¬ê¸°: {total_params * 4 / 1024**2:.1f}MB (float32 ê¸°ì¤€)\")\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    max_keep=3  # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ ë³´ê´€ (ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½)\n",
        ")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰\n",
        "optimize_memory_usage()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 6 ì™„ë£Œ: ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ & Hierarchical Self-Attention ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ í›ˆë ¨ ì¤‘ë‹¨ë˜ì–´ë„ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnefL1TYUJ3N"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 7: ì™„ì „í•œ MIL ëª¨ë¸ê³¼ Dataset\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ì¼ê³± ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì™„ì „í•œ FlexAttention MIL ëª¨ë¸ê³¼ Datasetì„ êµ¬í˜„í•©ë‹ˆë‹¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf7PtQ41UJ3N"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FlexAttentionPatientMIL(nn.Module):\n",
        "    \"\"\"\n",
        "    ğŸ¯ ì™„ì „í•œ FlexAttention Multiple Instance Learning ëª¨ë¸\n",
        "\n",
        "    ì „ì²´ êµ¬ì¡°:\n",
        "    1. í™˜ìë³„ ì—¬ëŸ¬ ë©”ê°€íŒ¨ì¹˜ â†’ ê°ê° 8ê°œ íŒ¨ì¹˜ â†’ 3-stream features\n",
        "    2. LR + Global tokens â†’ Standard Self-Attention layers\n",
        "    3. LR attention â†’ HR selection â†’ FlexAttention layers\n",
        "    4. CLS token â†’ Patient-level classification (ì•” ë‹¨ê³„/ì¬ë°œ ì˜ˆì¸¡)\n",
        "\n",
        "    ê³„ì‚°ëŸ‰ ìµœì í™”:\n",
        "    - ë©”ê°€íŒ¨ì¹˜ë‹¹ 16ê°œ â†’ 8ê°œ íŒ¨ì¹˜ë¡œ ê°ì†Œ (50% ì ˆì•½)\n",
        "    - Feature dim 384 â†’ 256ë¡œ ê°ì†Œ (33% ì ˆì•½)\n",
        "    - FA layers 2ê°œ â†’ 1ê°œë¡œ ê°ì†Œ (50% ì ˆì•½)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_dim=256, num_classes=2, num_heads=4,\n",
        "                 num_sa_layers=1, num_fa_layers=1, dropout=0.1,\n",
        "                 extractor_type='resnet18'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_dim (int): Feature ì°¨ì› (256 ì¶”ì²œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "            num_classes (int): ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜ (2: binary classification)\n",
        "            num_heads (int): Attention head ìˆ˜ (4 ì¶”ì²œ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "            num_sa_layers (int): Standard Self-Attention layer ìˆ˜\n",
        "            num_fa_layers (int): FlexAttention layer ìˆ˜\n",
        "            dropout (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨\n",
        "            extractor_type (str): Feature extractor íƒ€ì… ('resnet18', 'mobilenet')\n",
        "        \"\"\"\n",
        "        super(FlexAttentionPatientMIL, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_sa_layers = num_sa_layers\n",
        "        self.num_fa_layers = num_fa_layers\n",
        "\n",
        "        print(f\"ğŸ—ï¸  FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...\")\n",
        "        print(f\"   - Feature dim: {feature_dim}\")\n",
        "        print(f\"   - Attention heads: {num_heads}\")\n",
        "        print(f\"   - SA layers: {num_sa_layers}, FA layers: {num_fa_layers}\")\n",
        "        print(f\"   - Extractor: {extractor_type}\")\n",
        "\n",
        "        # ğŸ”¬ Feature extractors (3ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ í•´ìƒë„ìš©)\n",
        "        self.lr_extractor =  ResNetFeatureExtractor()\n",
        "        self.global_extractor =  ResNetFeatureExtractor()\n",
        "        self.hr_extractor =  ResNetFeatureExtractor()    # 256x256ìš© (HR)\n",
        "\n",
        "        # ğŸ¯ CLS token (í™˜ì ë ˆë²¨ ë¶„ë¥˜ë¥¼ ìœ„í•œ íŠ¹ë³„í•œ í† í°)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, feature_dim))\n",
        "\n",
        "        # ğŸ“ Positional encoding (í† í° ìœ„ì¹˜ ì •ë³´)\n",
        "        # ìµœëŒ€ í† í° ìˆ˜: í™˜ìë‹¹ 20ë©”ê°€íŒ¨ì¹˜ Ã— 8íŒ¨ì¹˜ = 160 LR + 20 Global + 1 CLS = 181\n",
        "        max_tokens = 200  # ì—¬ìœ ìˆê²Œ ì„¤ì •\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, max_tokens, feature_dim))\n",
        "\n",
        "        # ğŸ§  Standard Self-Attention layers (LR + Global + CLSë§Œ ì‚¬ìš©)\n",
        "        self.sa_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=feature_dim,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=feature_dim * 4,  # FFN hidden dim\n",
        "                dropout=dropout,\n",
        "                batch_first=True,\n",
        "                norm_first=True  # Pre-LN for better training stability\n",
        "            ) for _ in range(num_sa_layers)\n",
        "        ])\n",
        "\n",
        "        # ğŸ¯ FlexAttention components\n",
        "        self.hr_selectors = nn.ModuleList([\n",
        "            ThresholdBasedHRSelector(\n",
        "                target_selection_ratio=0.1,  # 10% ì„ íƒ\n",
        "                min_patches=1,\n",
        "                max_patches=4\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.hierarchical_attentions = nn.ModuleList([\n",
        "            HierarchicalSelfAttention(feature_dim, num_heads, dropout)\n",
        "            for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # FlexAttention layerìš© FFNê³¼ LayerNorm\n",
        "        self.fa_ffns = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(feature_dim, feature_dim * 4),\n",
        "                nn.GELU(),  # ReLUë³´ë‹¤ ë” ë¶€ë“œëŸ¬ìš´ í™œì„±í™” í•¨ìˆ˜\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(feature_dim * 4, feature_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            ) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        self.fa_layer_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(feature_dim) for _ in range(num_fa_layers)\n",
        "        ])\n",
        "\n",
        "        # ğŸ¥ ìµœì¢… ë¶„ë¥˜ê¸° (í™˜ì ë ˆë²¨ ì˜ˆì¸¡)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feature_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
        "        self._initialize_weights()\n",
        "\n",
        "        print(f\"âœ… FlexAttention MIL ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ë” ì•ˆì •ì ì¸ í›ˆë ¨ì„ ìœ„í•´)\"\"\"\n",
        "        # CLS token ì´ˆê¸°í™”\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "\n",
        "        # Positional encoding ì´ˆê¸°í™”\n",
        "        nn.init.trunc_normal_(self.pos_encoding, std=0.02)\n",
        "\n",
        "        # Linear layer ì´ˆê¸°í™”\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.trunc_normal_(module.weight, std=0.02)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def forward(self, lr_features, global_features, hr_features):\n",
        "        \"\"\"\n",
        "        FlexAttention MIL Forward Pass\n",
        "\n",
        "        Args:\n",
        "            lr_features: [batch_size, total_lr_patches, feature_dim] - ëª¨ë“  LR features\n",
        "            global_features: [batch_size, num_megapatches, feature_dim] - Global features\n",
        "            hr_features: [batch_size, total_hr_patches, feature_dim] - ëª¨ë“  HR features\n",
        "\n",
        "        Returns:\n",
        "            logits: [batch_size, num_classes] - í™˜ì ë ˆë²¨ ì˜ˆì¸¡\n",
        "            attention_maps: List[Tensor] - attention maps (ì‹œê°í™”ìš©)\n",
        "            selection_stats: Dict - HR selection í†µê³„ (ë¶„ì„ìš©)\n",
        "        \"\"\"\n",
        "        batch_size = lr_features.shape[0]\n",
        "\n",
        "        # ğŸ“Š ì…ë ¥ ë°ì´í„° í¬ê¸° í™•ì¸ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
        "        max_lr_tokens = min(lr_features.shape[1], 128)    # ìµœëŒ€ 128ê°œ LR tokens\n",
        "        max_global_tokens = min(global_features.shape[1], 16)  # ìµœëŒ€ 16ê°œ Global tokens\n",
        "        max_hr_tokens = min(hr_features.shape[1], 128)    # ìµœëŒ€ 128ê°œ HR tokens\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ í† í°ë§Œ ì‚¬ìš©\n",
        "        lr_subset = lr_features[:, :max_lr_tokens]        # [B, â‰¤128, D]\n",
        "        global_subset = global_features[:, :max_global_tokens]  # [B, â‰¤16, D]\n",
        "        hr_subset = hr_features[:, :max_hr_tokens]        # [B, â‰¤128, D] (ë‚˜ì¤‘ì— ì¼ë¶€ë§Œ ì„ íƒë¨)\n",
        "\n",
        "        # ğŸ¯ Step 1: Token sequence êµ¬ì„± [LR + Global + CLS]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # [B, 1, D]\n",
        "\n",
        "        # ì´ˆê¸° hidden states: LR tokens + Global tokens + CLS token\n",
        "        hidden_states = torch.cat([lr_subset, global_subset, cls_tokens], dim=1)  # [B, N, D]\n",
        "\n",
        "        # ğŸ“ Positional encoding ì¶”ê°€\n",
        "        seq_len = hidden_states.shape[1]\n",
        "        if seq_len <= self.pos_encoding.shape[1]:\n",
        "            hidden_states = hidden_states + self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        attention_maps = []  # attention mapë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "        selection_stats = {'total_selected': [], 'selection_ratios': []}\n",
        "\n",
        "        # ğŸ§  Step 2: Standard Self-Attention layers (Algorithm 1, lines 8-12)\n",
        "        for i in range(self.num_sa_layers):\n",
        "            hidden_states = self.sa_layers[i](hidden_states)\n",
        "\n",
        "        # ğŸ¯ Step 3: FlexAttention layers (Algorithm 1, lines 14-19)\n",
        "        for i in range(self.num_fa_layers):\n",
        "            # Step 3a: LR attention ê¸°ë°˜ HR selection\n",
        "            if i == 0:\n",
        "                # ì²« ë²ˆì§¸ layer: uniform attention (ëª¨ë“  LR í† í°ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜)\n",
        "                num_lr_tokens = lr_subset.shape[1]\n",
        "                lr_attention_map = torch.ones(batch_size, num_lr_tokens, device=lr_features.device)\n",
        "                lr_attention_map = lr_attention_map / lr_attention_map.sum(dim=1, keepdim=True)\n",
        "            else:\n",
        "                # ì´ì „ layerì˜ attention ì‚¬ìš©\n",
        "                lr_attention_map = attention_maps[-1][:, :lr_subset.shape[1]]  # LR ë¶€ë¶„ë§Œ\n",
        "\n",
        "            # HR featuresë¥¼ LRê³¼ ëŒ€ì‘ë˜ë„ë¡ í¬ê¸° ë§ì¶¤\n",
        "            hr_corresponding_size = min(hr_subset.shape[1], lr_subset.shape[1])\n",
        "            hr_for_selection = hr_subset[:, :hr_corresponding_size]\n",
        "            lr_attention_for_selection = lr_attention_map[:, :hr_corresponding_size]\n",
        "\n",
        "            # Step 3b: ì¤‘ìš”í•œ HR features ì„ íƒ (ë…¼ë¬¸ì˜ í•µì‹¬!)\n",
        "            selected_hr_features, selection_masks, thresholds = self.hr_selectors[i](\n",
        "                lr_attention_for_selection, hr_for_selection\n",
        "            )\n",
        "\n",
        "            # ì„ íƒ í†µê³„ ìˆ˜ì§‘\n",
        "            stats = self.hr_selectors[i].get_selection_statistics(selection_masks)\n",
        "            selection_stats['total_selected'].append(stats['mean_selected'])\n",
        "            selection_stats['selection_ratios'].append(stats['selection_ratio'])\n",
        "\n",
        "            # Step 3c: Hierarchical Self-Attention (Algorithm 1, line 16)\n",
        "            attended_output, new_attention_map = self.hierarchical_attentions[i](\n",
        "                hidden_states, selected_hr_features\n",
        "            )\n",
        "\n",
        "            # Step 3d: Residual connection + Layer normalization\n",
        "            hidden_states = self.fa_layer_norms[i](hidden_states + attended_output)\n",
        "\n",
        "            # Step 3e: FFN + residual connection (Algorithm 1, line 18)\n",
        "            ffn_output = self.fa_ffns[i](hidden_states)\n",
        "            hidden_states = hidden_states + ffn_output\n",
        "\n",
        "            attention_maps.append(new_attention_map)\n",
        "\n",
        "        # ğŸ¥ Step 4: í™˜ì ë ˆë²¨ ë¶„ë¥˜ (Algorithm 1, line 20)\n",
        "        cls_output = hidden_states[:, -1]  # CLS tokenì˜ ìµœì¢… representation\n",
        "        logits = self.classifier(cls_output)  # [B, num_classes]\n",
        "\n",
        "        return logits, attention_maps, selection_stats\n",
        "\n",
        "\n",
        "class DynamicFlexAttentionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ğŸ—‚ï¸  FlexAttentionìš© ë™ì  í™˜ì Dataset\n",
        "\n",
        "    íŠ¹ì§•:\n",
        "    - í™˜ìë³„ë¡œ ë‹¤ë¥¸ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ì²˜ë¦¬\n",
        "    - ë©”ê°€íŒ¨ì¹˜ë‹¹ 8ê°œ íŒ¨ì¹˜ë¡œ ê°ì†Œ (ì†ë„ í–¥ìƒ)\n",
        "    - ìºì‹±ìœ¼ë¡œ ë°˜ë³µ ë¡œë”© ë°©ì§€\n",
        "    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patient_data, target_type='t_label',\n",
        "                 patches_per_megapatch=8, cache_dir=None,\n",
        "                 max_megapatches=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patient_data (dict): í™˜ìë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
        "            target_type (str): ë¼ë²¨ íƒ€ì… ('t_label', 'recur_label')\n",
        "            patches_per_megapatch (int): ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ê°œìˆ˜ (8 ì¶”ì²œ)\n",
        "            cache_dir (str): ìºì‹œ ë””ë ‰í† ë¦¬ (ì²˜ë¦¬ëœ features ì €ì¥)\n",
        "            max_megapatches (int): í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜ ìˆ˜ (Noneì´ë©´ ìë™ ê²°ì •)\n",
        "        \"\"\"\n",
        "        self.patient_data = patient_data\n",
        "        self.patient_ids = list(patient_data.keys())\n",
        "        self.target_type = target_type\n",
        "        self.patches_per_megapatch = patches_per_megapatch\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        if cache_dir:\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "        # í™˜ìë³„ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„ì„ ë° ìµœì  max_megapatches ê²°ì •\n",
        "        self._analyze_megapatch_distribution()\n",
        "        if max_megapatches is None:\n",
        "            self.max_megapatches = self._determine_optimal_max_megapatches()\n",
        "        else:\n",
        "            self.max_megapatches = max_megapatches\n",
        "\n",
        "        print(f\"ğŸ“Š Dataset ì´ˆê¸°í™” ì™„ë£Œ:\")\n",
        "        print(f\"   - í™˜ì ìˆ˜: {len(self.patient_ids)}ëª…\")\n",
        "        print(f\"   - ë¼ë²¨ íƒ€ì…: {target_type}\")\n",
        "        print(f\"   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: {patches_per_megapatch}ê°œ\")\n",
        "        print(f\"   - í™˜ìë‹¹ ìµœëŒ€ ë©”ê°€íŒ¨ì¹˜: {self.max_megapatches}ê°œ\")\n",
        "\n",
        "        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ transform\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™” (ì‚¬ì „í›ˆë ¨ ëª¨ë¸ê³¼ ë§ì¶¤)\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def _analyze_megapatch_distribution(self):\n",
        "        \"\"\"í™˜ìë³„ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬ ë¶„ì„\"\"\"\n",
        "        counts = []\n",
        "        for patient_id, info in self.patient_data.items():\n",
        "            counts.append(len(info['images']))\n",
        "\n",
        "        if counts:\n",
        "            print(f\"ğŸ“ˆ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ë¶„í¬:\")\n",
        "            print(f\"   - í‰ê· : {np.mean(counts):.1f}ê°œ\")\n",
        "            print(f\"   - ì¤‘ê°„ê°’: {np.median(counts):.1f}ê°œ\")\n",
        "            print(f\"   - 25%/75% ì§€ì : {np.percentile(counts, 25):.1f}/{np.percentile(counts, 75):.1f}ê°œ\")\n",
        "            print(f\"   - ìµœì†Œ/ìµœëŒ€: {min(counts)}/{max(counts)}ê°œ\")\n",
        "\n",
        "        self.megapatch_counts = counts\n",
        "\n",
        "    def _determine_optimal_max_megapatches(self):\n",
        "        \"\"\"ë©”ëª¨ë¦¬ì™€ ì„±ëŠ¥ì„ ê³ ë ¤í•œ ìµœì  max_megapatches ê²°ì •\"\"\"\n",
        "        if not self.megapatch_counts:\n",
        "            return 10  # ê¸°ë³¸ê°’\n",
        "\n",
        "        # 75% percentile ì‚¬ìš© (ëŒ€ë¶€ë¶„ í™˜ìë¥¼ ì»¤ë²„í•˜ë©´ì„œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "        optimal = int(np.percentile(self.megapatch_counts, 75))\n",
        "\n",
        "        # ìµœì†Œ 5ê°œ, ìµœëŒ€ 15ê°œë¡œ ì œí•œ (ë©”ëª¨ë¦¬ ê³ ë ¤)\n",
        "        optimal = max(5, min(optimal, 15))\n",
        "\n",
        "        print(f\"ğŸ¯ ìµœì  max_megapatches ê²°ì •: {optimal}ê°œ (75th percentile ê¸°ì¤€)\")\n",
        "        return optimal\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        í™˜ì ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
        "\n",
        "        Returns:\n",
        "            dict: {\n",
        "                'patient_id': í™˜ì ID,\n",
        "                'lr_patches': [total_lr, 3, 64, 64] - LR íŒ¨ì¹˜ë“¤,\n",
        "                'global_patches': [num_megapatches, 3, 64, 64] - Global íŒ¨ì¹˜ë“¤,\n",
        "                'hr_patches': [total_hr, 3, 256, 256] - HR íŒ¨ì¹˜ë“¤,\n",
        "                'label': ë¼ë²¨,\n",
        "                'num_megapatches': ì‹¤ì œ ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜\n",
        "            }\n",
        "        \"\"\"\n",
        "        patient_id = self.patient_ids[idx]\n",
        "        patient_info = self.patient_data[patient_id]\n",
        "\n",
        "        # ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°\n",
        "        label = patient_info.get(self.target_type, 0)\n",
        "        if label is None:\n",
        "            label = 0\n",
        "\n",
        "        # ì´ í™˜ìì˜ ëª¨ë“  ë©”ê°€íŒ¨ì¹˜ ê²½ë¡œ\n",
        "        megapatch_paths = patient_info['images']\n",
        "\n",
        "        # ë©”ê°€íŒ¨ì¹˜ ê°œìˆ˜ ì¡°ì •\n",
        "        if len(megapatch_paths) > self.max_megapatches:\n",
        "            # ë„ˆë¬´ ë§ìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§\n",
        "            megapatch_paths = random.sample(megapatch_paths, self.max_megapatches)\n",
        "        elif len(megapatch_paths) == 0:\n",
        "            # ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # ê° streamë³„ ë°ì´í„° ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë“¤\n",
        "        all_lr_features = []\n",
        "        all_global_features = []\n",
        "        all_hr_features = []\n",
        "\n",
        "        # ê° ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬\n",
        "        processed_count = 0\n",
        "        for megapatch_path in megapatch_paths:\n",
        "            try:\n",
        "                # ìºì‹± í™•ì¸\n",
        "                if self.cache_dir:\n",
        "                    cache_key = hashlib.md5(\n",
        "                        f\"{megapatch_path}_{self.patches_per_megapatch}\".encode()\n",
        "                    ).hexdigest()\n",
        "                    cache_path = os.path.join(self.cache_dir, f\"{cache_key}.pkl\")\n",
        "\n",
        "                    if os.path.exists(cache_path):\n",
        "                        with open(cache_path, 'rb') as f:\n",
        "                            processed = pickle.load(f)\n",
        "                    else:\n",
        "                        processed = process_megapatch_complete(\n",
        "                            megapatch_path, self.patches_per_megapatch\n",
        "                        )\n",
        "                        with open(cache_path, 'wb') as f:\n",
        "                            pickle.dump(processed, f)\n",
        "                else:\n",
        "                    processed = process_megapatch_complete(\n",
        "                        megapatch_path, self.patches_per_megapatch\n",
        "                    )\n",
        "\n",
        "                # ê° streamë³„ë¡œ tensor ë³€í™˜\n",
        "                for lr_patch in processed['lr_patches']:\n",
        "                    lr_pil = Image.fromarray(lr_patch)\n",
        "                    lr_tensor = self.transform(lr_pil)\n",
        "                    all_lr_features.append(lr_tensor)\n",
        "\n",
        "                # Global token (ë©”ê°€íŒ¨ì¹˜ë‹¹ 1ê°œ)\n",
        "                global_pil = Image.fromarray(processed['global_tokens'][0])\n",
        "                global_tensor = self.transform(global_pil)\n",
        "                all_global_features.append(global_tensor)\n",
        "\n",
        "                # HR patches\n",
        "                for hr_patch in processed['hr_patches']:\n",
        "                    hr_pil = Image.fromarray(hr_patch)\n",
        "                    hr_tensor = self.transform(hr_pil)\n",
        "                    all_hr_features.append(hr_tensor)\n",
        "\n",
        "                processed_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  ë©”ê°€íŒ¨ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ {megapatch_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # ì²˜ë¦¬ëœ ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°\n",
        "        if processed_count == 0:\n",
        "            return self._create_dummy_data(patient_id, label)\n",
        "\n",
        "        # Tensorë¡œ ë³€í™˜\n",
        "        lr_tensor = torch.stack(all_lr_features)      # [total_lr, 3, 64, 64]\n",
        "        global_tensor = torch.stack(all_global_features)  # [num_megapatches, 3, 64, 64]\n",
        "        hr_tensor = torch.stack(all_hr_features)      # [total_hr, 3, 256, 256]\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': lr_tensor,\n",
        "            'global_patches': global_tensor,\n",
        "            'hr_patches': hr_tensor,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': processed_count\n",
        "        }\n",
        "\n",
        "    def _create_dummy_data(self, patient_id, label):\n",
        "        \"\"\"ë©”ê°€íŒ¨ì¹˜ê°€ ì—†ê±°ë‚˜ ì²˜ë¦¬ ì‹¤íŒ¨ì‹œ ë”ë¯¸ ë°ì´í„° ìƒì„±\"\"\"\n",
        "        dummy_lr = torch.zeros(self.patches_per_megapatch, 3, 64, 64)\n",
        "        dummy_global = torch.zeros(1, 3, 64, 64)\n",
        "        dummy_hr = torch.zeros(self.patches_per_megapatch, 3, 256, 256)\n",
        "\n",
        "        return {\n",
        "            'patient_id': patient_id,\n",
        "            'lr_patches': dummy_lr,\n",
        "            'global_patches': dummy_global,\n",
        "            'hr_patches': dummy_hr,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'num_megapatches': 1\n",
        "        }\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 7 ì™„ë£Œ: ì™„ì „í•œ FlexAttention MIL ëª¨ë¸ê³¼ Dataset ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ í™˜ìë³„ ë‹¤ì¤‘ ë©”ê°€íŒ¨ì¹˜ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì•” ë‹¨ê³„/ì¬ë°œì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64mZpB_ZUJ3O"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 8: í›ˆë ¨ í•¨ìˆ˜ (ì²´í¬í¬ì¸íŠ¸ ì™„ë²½ ì§€ì›)\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shhotdosUJ3O"
      },
      "outputs": [],
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 8: í›ˆë ¨ í•¨ìˆ˜ (ì²´í¬í¬ì¸íŠ¸ ì™„ë²½ ì§€ì›)\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ì—¬ëŸ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì²´í¬í¬ì¸íŠ¸ë¥¼ ì™„ë²½ ì§€ì›í•˜ëŠ” í›ˆë ¨ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤\n",
        "\n",
        "def train_flexattention_model_with_checkpoints(\n",
        "    patient_data,\n",
        "    target_type='t_label',\n",
        "    num_folds=3,\n",
        "    num_epochs=12,\n",
        "    batch_size=1,              # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "    accumulation_steps=4,      # effective batch_size = 4\n",
        "    learning_rate=3e-4,\n",
        "    extractor_type='resnet18', # 'resnet18' or 'mobilenet'\n",
        "    device=device,\n",
        "    work_dir=work_dir,\n",
        "    resume_from_checkpoint=True\n",
        "):\n",
        "    \"\"\"\n",
        "    ğŸš€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì™„ë²½ ì§€ì›í•˜ëŠ” FlexAttention MIL í›ˆë ¨ í•¨ìˆ˜\n",
        "\n",
        "    ì£¼ìš” íŠ¹ì§•:\n",
        "    - ë§¤ epochë§ˆë‹¤ ìë™ ì €ì¥\n",
        "    - í›ˆë ¨ ì¤‘ë‹¨ì‹œ ë§ˆì§€ë§‰ ì§€ì ë¶€í„° ì¬ì‹œì‘ ê°€ëŠ¥\n",
        "    - Gradient accumulationìœ¼ë¡œ ì•ˆì •ì ì¸ í›ˆë ¨\n",
        "    - ì‹¤ì‹œê°„ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§\n",
        "    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
        "\n",
        "    Args:\n",
        "        patient_data (dict): í™˜ìë³„ ë°ì´í„°\n",
        "        target_type (str): ë¼ë²¨ íƒ€ì… ('t_label' ë˜ëŠ” 'recur_label')\n",
        "        num_folds (int): K-fold ê°œìˆ˜\n",
        "        num_epochs (int): epoch ìˆ˜\n",
        "        batch_size (int): ë¬¼ë¦¬ì  ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë§ì¶° ì¡°ì •)\n",
        "        accumulation_steps (int): gradient accumulation ë‹¨ê³„ ìˆ˜\n",
        "        learning_rate (float): í•™ìŠµë¥ \n",
        "        extractor_type (str): feature extractor íƒ€ì…\n",
        "        device: í›ˆë ¨ ë””ë°”ì´ìŠ¤\n",
        "        work_dir (str): ì‘ì—… ë””ë ‰í† ë¦¬\n",
        "        resume_from_checkpoint (bool): ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘ ì—¬ë¶€\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"ğŸš€ FlexAttention MIL í›ˆë ¨ ì‹œì‘!\")\n",
        "    print(f\"   Target: {target_type}\")\n",
        "    print(f\"   Folds: {num_folds}, Epochs: {num_epochs}\")\n",
        "    print(f\"   Batch size: {batch_size} (ë¬¼ë¦¬ì ) Ã— {accumulation_steps} (ëˆ„ì ) = {batch_size * accumulation_steps} (íš¨ê³¼ì )\")\n",
        "    print(f\"   Learning rate: {learning_rate}\")\n",
        "    print(f\"   Extractor: {extractor_type}\")\n",
        "    print(f\"   ì‘ì—… ë””ë ‰í† ë¦¬: {work_dir}\")\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "    target_dir = os.path.join(work_dir, f\"results_{target_type}\")\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
        "    checkpoint_manager = CheckpointManager(\n",
        "        checkpoint_dir=os.path.join(target_dir, \"checkpoints\"),\n",
        "        max_keep=3\n",
        "    )\n",
        "\n",
        "    # í™˜ì ë°ì´í„° ì¤€ë¹„\n",
        "    patient_ids = list(patient_data.keys())\n",
        "    patient_labels = [patient_data[pid].get(target_type, 0) for pid in patient_ids]\n",
        "    patient_labels = [0 if label is None else label for label in patient_labels]\n",
        "\n",
        "    print(f\"\\nğŸ‘¥ í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:\")\n",
        "    print(f\"   ì´ í™˜ì ìˆ˜: {len(patient_ids)}ëª…\")\n",
        "    print(f\"   ë¼ë²¨ ë¶„í¬: {dict(zip(*np.unique(patient_labels, return_counts=True)))}\")\n",
        "\n",
        "    # Stratified K-Fold ì„¤ì •\n",
        "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # ì „ì²´ ê²°ê³¼ ì €ì¥\n",
        "    all_results = {\n",
        "        'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'auc': [],\n",
        "        'fold_details': []\n",
        "    }\n",
        "\n",
        "    # ê° fold ë³„ í›ˆë ¨\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(patient_ids, patient_labels)):\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"ğŸ”„ Fold {fold+1}/{num_folds} ì‹œì‘\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # ë°ì´í„° ë¶„í• \n",
        "        train_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in train_idx}\n",
        "        test_patients = {patient_ids[i]: patient_data[patient_ids[i]] for i in test_idx}\n",
        "\n",
        "        print(f\"   í›ˆë ¨ í™˜ì: {len(train_patients)}ëª…\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ í™˜ì: {len(test_patients)}ëª…\")\n",
        "\n",
        "        # Dataset ìƒì„±\n",
        "        train_dataset = DynamicFlexAttentionDataset(\n",
        "            train_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=8,  # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=12        # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "        )\n",
        "\n",
        "        test_dataset = DynamicFlexAttentionDataset(\n",
        "            test_patients,\n",
        "            target_type=target_type,\n",
        "            patches_per_megapatch=8,\n",
        "            cache_dir=os.path.join(target_dir, \"cache\"),\n",
        "            max_megapatches=12\n",
        "        )\n",
        "\n",
        "        # DataLoader ìƒì„±\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2,              # Windowsì—ì„œ ì•ˆì •ì ì¸ ê°’\n",
        "            pin_memory=True,\n",
        "            persistent_workers=True,\n",
        "            drop_last=False\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        print(f\"   í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
        "        print(f\"   í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")\n",
        "\n",
        "        # ëª¨ë¸ ì´ˆê¸°í™”\n",
        "        model = FlexAttentionPatientMIL(\n",
        "            feature_dim=256,           # ë©”ëª¨ë¦¬ íš¨ìœ¨ì \n",
        "            num_classes=2,\n",
        "            num_heads=4,               # ë©”ëª¨ë¦¬ íš¨ìœ¨ì \n",
        "            num_sa_layers=1,\n",
        "            num_fa_layers=1,           # ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "            dropout=0.1,\n",
        "            extractor_type=extractor_type\n",
        "        )\n",
        "\n",
        "        # GPU ì„¤ì •\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            print(f\"   ğŸ”— {torch.cuda.device_count()}ê°œ GPUë¡œ DataParallel ì„¤ì •\")\n",
        "            model = nn.DataParallel(model)\n",
        "\n",
        "        model = model.to(device)\n",
        "        log_model_info(model)\n",
        "\n",
        "        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
        "        # Effective batch sizeì— ë§ì¶° learning rate ì¡°ì •\n",
        "        effective_batch_size = batch_size * accumulation_steps\n",
        "        adjusted_lr = learning_rate * (effective_batch_size / 4)  # baseëŠ” 4\n",
        "\n",
        "        optimizer = AdamW(\n",
        "            model.parameters(),\n",
        "            lr=adjusted_lr,\n",
        "            weight_decay=1e-4,\n",
        "            betas=(0.9, 0.999),\n",
        "            eps=1e-8\n",
        "        )\\n        \\n        # ì‹¤ì œ ì—…ë°ì´íŠ¸ íšŸìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\\n        total_updates = (len(train_loader) // accumulation_steps) * num_epochs\\n        scheduler = OneCycleLR(\\n            optimizer, \\n            max_lr=adjusted_lr, \\n            total_steps=total_updates,\\n            pct_start=0.1,  # 10%ëŠ” warm-up\\n            anneal_strategy='cos'\\n        )\\n        \\n        # Loss function & Scaler\\n        criterion = nn.CrossEntropyLoss()\\n        scaler = GradScaler()\\n        \\n        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘ í™•ì¸\\n        start_epoch = 0\\n        if resume_from_checkpoint:\\n            checkpoint = checkpoint_manager.load_latest_checkpoint(fold + 1)\\n            if checkpoint:\\n                # ëª¨ë¸ ìƒíƒœ ë³µì›\\n                if hasattr(model, 'module'):\\n                    model.module.load_state_dict(checkpoint['model_state_dict'])\\n                else:\\n                    model.load_state_dict(checkpoint['model_state_dict'])\\n                \\n                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\\n                \\n                if checkpoint['scheduler_state_dict'] and scheduler:\\n                    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\\n                \\n                start_epoch = checkpoint['epoch'] + 1\\n                checkpoint_manager.best_score = checkpoint.get('best_score', 0.0)\\n                \\n                print(f\\\"   ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: Epoch {start_epoch}ë¶€í„°\\\")\\n                print(f\\\"   ğŸ† ì´ì „ ìµœê³  ì„±ëŠ¥: {checkpoint_manager.best_score:.4f}\\\")\\n        \\n        # í›ˆë ¨ ë£¨í”„\\n        for epoch in range(start_epoch, num_epochs):\\n            print(f\\\"\\\\nğŸ”„ Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\\\")\\n            log_gpu_memory(f\\\"Epoch {epoch+1} ì‹œì‘\\\")\\n            \\n            # í›ˆë ¨ ë‹¨ê³„\\n            model.train()\\n            total_loss = 0\\n            num_updates = 0\\n            optimizer.zero_grad()  # accumulation ì‹œì‘\\n            \\n            progress_bar = tqdm(train_loader, desc=f\\\"í›ˆë ¨ ì§„í–‰\\\")\\n            \\n            for batch_idx, batch in enumerate(progress_bar):\\n                try:\\n                    # Backward pass\n",
        "                    scaler.scale(loss).backward()\n",
        "\n",
        "                    # Gradient accumulation ì²´í¬\n",
        "                    if (batch_idx + 1) % accumulation_steps == 0:\n",
        "                        # ì‹¤ì œ parameter ì—…ë°ì´íŠ¸\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                        scheduler.step()\n",
        "                        optimizer.zero_grad()\n",
        "                        num_updates += 1\n",
        "\n",
        "                        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì£¼ê¸°ì ìœ¼ë¡œ)\n",
        "                        if num_updates % 10 == 0:\n",
        "                            torch.cuda.empty_cache()\n",
        "\n",
        "                    total_loss += loss.item() * accumulation_steps  # ì›ë˜ lossë¡œ ë³µì›\n",
        "\n",
        "                    # Progress bar ì—…ë°ì´íŠ¸\n",
        "                    current_lr = scheduler.get_last_lr()[0] if scheduler else adjusted_lr\n",
        "                    progress_bar.set_postfix({\n",
        "                        'Loss': f'{loss.item() * accumulation_steps:.4f}',\n",
        "                        'LR': f'{current_lr:.2e}',\n",
        "                        'Updates': num_updates\n",
        "                    })\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(f\"ğŸ’¥ OOM ë°œìƒ! ë°°ì¹˜ {batch_idx} ìŠ¤í‚µ\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        continue\n",
        "                    else:\n",
        "                        raise e\n",
        "\n",
        "            # ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬ (accumulationì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš°)\n",
        "            if len(train_loader) % accumulation_steps != 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "            # ê²€ì¦ ë‹¨ê³„ (ê°„ë‹¨í•œ ê²€ì¦)\n",
        "            model.eval()\n",
        "            val_preds = []\n",
        "            val_labels = []\n",
        "            val_probs = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm(test_loader, desc=\"ê²€ì¦ ì§„í–‰\"):\n",
        "                    try:\n",
        "                        lr_patches = batch['lr_patches'].to(device, non_blocking=True)\n",
        "                        global_patches = batch['global_patches'].to(device, non_blocking=True)\n",
        "                        hr_patches = batch['hr_patches'].to(device, non_blocking=True)\n",
        "                        labels = batch['label'].to(device, non_blocking=True)\n",
        "\n",
        "                        # Feature extraction\n",
        "                        lr_features, global_features, hr_features = extract_features_efficiently(\n",
        "                            lr_patches, global_patches, hr_patches, model\n",
        "                        )\n",
        "\n",
        "                        # Forward pass\n",
        "                        if hasattr(model, 'module'):\n",
        "                            logits, _, _ = model.module(lr_features, global_features, hr_features)\n",
        "                        else:\n",
        "                            logits, _, _ = model(lr_features, global_features, hr_features)\n",
        "\n",
        "                        probs = F.softmax(logits, dim=1)\n",
        "                        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                        val_preds.extend(preds.cpu().tolist())\n",
        "                        val_labels.extend(labels.cpu().tolist())\n",
        "                        val_probs.extend(probs[:, 1].cpu().tolist())\n",
        "\n",
        "                    except RuntimeError as e:\n",
        "                        if \"out of memory\" in str(e):\n",
        "                            print(f\"ğŸ’¥ ê²€ì¦ ì¤‘ OOM ë°œìƒ! ë°°ì¹˜ ìŠ¤í‚µ\")\n",
        "                            torch.cuda.empty_cache()\n",
        "                            continue\n",
        "                        else:\n",
        "                            raise e\n",
        "\n",
        "            # ê²€ì¦ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
        "            if val_labels:\n",
        "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "                val_precision = precision_score(val_labels, val_preds, zero_division=0)\n",
        "                val_recall = recall_score(val_labels, val_preds, zero_division=0)\n",
        "                val_f1 = f1_score(val_labels, val_preds, zero_division=0)\n",
        "\n",
        "                try:\n",
        "                    val_auc = roc_auc_score(val_labels, val_probs)\n",
        "                except:\n",
        "                    val_auc = 0.0\n",
        "\n",
        "                val_metrics = {\n",
        "                    'accuracy': val_accuracy,\n",
        "                    'precision': val_precision,\n",
        "                    'recall': val_recall,\n",
        "                    'f1': val_f1,\n",
        "                    'auc': val_auc\n",
        "                }\n",
        "\n",
        "                # ìµœê³  ì„±ëŠ¥ ì²´í¬\n",
        "                is_best = val_f1 > checkpoint_manager.best_score\n",
        "\n",
        "                print(f\"   ğŸ“Š Epoch {epoch+1} ê²°ê³¼:\")\n",
        "                print(f\"      í›ˆë ¨ Loss: {avg_loss:.4f}\")\n",
        "                print(f\"      ê²€ì¦ Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}\")\n",
        "                if is_best:\n",
        "                    print(f\"      ğŸ† ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥!\")\n",
        "\n",
        "            else:\n",
        "                val_metrics = {}\n",
        "                is_best = False\n",
        "                print(f\"   ğŸ“Š Epoch {epoch+1} ê²°ê³¼: í›ˆë ¨ Loss {avg_loss:.4f} (ê²€ì¦ ë°ì´í„° ì—†ìŒ)\")\n",
        "\n",
        "            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë§¤ epochë§ˆë‹¤)\n",
        "            checkpoint_manager.save_checkpoint(\n",
        "                model=model,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                epoch=epoch,\n",
        "                fold=fold + 1,\n",
        "                train_loss=avg_loss,\n",
        "                val_metrics=val_metrics,\n",
        "                is_best=is_best\n",
        "            )\n",
        "\n",
        "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "            torch.cuda.empty_cache()\n",
        "            log_gpu_memory(f\"Epoch {epoch+1} ì™„ë£Œ\")\n",
        "\n",
        "        # Fold ì™„ë£Œ í›„ ìµœì¢… í‰ê°€\n",
        "        print(f\"\\nğŸ¯ Fold {fold+1} ìµœì¢… í‰ê°€ ì¤‘...\")\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë”©\n",
        "        best_model_path = os.path.join(checkpoint_manager.checkpoint_dir, f\"best_model_fold{fold+1}.pt\")\n",
        "        if os.path.exists(best_model_path):\n",
        "            checkpoint = torch.load(best_model_path, map_location=device)\n",
        "            if hasattr(model, 'module'):\n",
        "                model.module.load_state_dict(checkpoint['model_state_dict'])\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(f\"   ğŸ“‚ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë”© ì™„ë£Œ\")\n",
        "\n",
        "        # ìµœì¢… í…ŒìŠ¤íŠ¸\n",
        "        model.eval()\n",
        "        final_preds = []\n",
        "        final_labels = []\n",
        "        final_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(test_loader, desc=\"ìµœì¢… í‰ê°€\"):\n",
        "                try:\n",
        "                    lr_patches = batch['lr_patches'].to(device, non_blocking=True)\n",
        "                    global_patches = batch['global_patches'].to(device, non_blocking=True)\n",
        "                    hr_patches = batch['hr_patches'].to(device, non_blocking=True)\n",
        "                    labels = batch['label'].to(device, non_blocking=True)\n",
        "\n",
        "                    lr_features, global_features, hr_features = extract_features_efficiently(\n",
        "                        lr_patches, global_patches, hr_patches, model\n",
        "                    )\n",
        "\n",
        "                    if hasattr(model, 'module'):\n",
        "                        logits, attention_maps, selection_stats = model.module(\n",
        "                            lr_features, global_features, hr_features\n",
        "                        )\n",
        "                    else:\n",
        "                        logits, attention_maps, selection_stats = model(\n",
        "                            lr_features, global_features, hr_features\n",
        "                        )\n",
        "\n",
        "                    probs = F.softmax(logits, dim=1)\n",
        "                    preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "                    final_preds.extend(preds.cpu().tolist())\n",
        "                    final_labels.extend(labels.cpu().tolist())\n",
        "                    final_probs.extend(probs[:, 1].cpu().tolist())\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(f\"ğŸ’¥ ìµœì¢… í‰ê°€ ì¤‘ OOM ë°œìƒ! ë°°ì¹˜ ìŠ¤í‚µ\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        continue\n",
        "                    else:\n",
        "                        raise e\n",
        "\n",
        "        # ìµœì¢… ë©”íŠ¸ë¦­ ê³„ì‚°\n",
        "        if final_labels:\n",
        "            final_accuracy = accuracy_score(final_labels, final_preds)\n",
        "            final_precision = precision_score(final_labels, final_preds, zero_division=0)\n",
        "            final_recall = recall_score(final_labels, final_preds, zero_division=0)\n",
        "            final_f1 = f1_score(final_labels, final_preds, zero_division=0)\n",
        "\n",
        "            try:\n",
        "                final_auc = roc_auc_score(final_labels, final_probs)\n",
        "            except:\n",
        "                final_auc = 0.0\n",
        "\n",
        "            print(f\"\\nğŸ† Fold {fold+1} ìµœì¢… ê²°ê³¼:\")\n",
        "            print(f\"   Accuracy: {final_accuracy:.4f}\")\n",
        "            print(f\"   Precision: {final_precision:.4f}\")\n",
        "            print(f\"   Recall: {final_recall:.4f}\")\n",
        "            print(f\"   F1: {final_f1:.4f}\")\n",
        "            print(f\"   AUC: {final_auc:.4f}\")\n",
        "\n",
        "            # ê²°ê³¼ ì €ì¥\n",
        "            all_results['accuracy'].append(final_accuracy)\n",
        "            all_results['precision'].append(final_precision)\n",
        "            all_results['recall'].append(final_recall)\n",
        "            all_results['f1'].append(final_f1)\n",
        "            all_results['auc'].append(final_auc)\n",
        "\n",
        "            # Confusion Matrix ê³„ì‚° ë° ì €ì¥\n",
        "            cm = confusion_matrix(final_labels, final_preds)\n",
        "            fold_detail = {\n",
        "                'fold': fold + 1,\n",
        "                'accuracy': final_accuracy,\n",
        "                'precision': final_precision,\n",
        "                'recall': final_recall,\n",
        "                'f1': final_f1,\n",
        "                'auc': final_auc,\n",
        "                'confusion_matrix': cm.tolist(),\n",
        "                'predictions': final_preds,\n",
        "                'true_labels': final_labels,\n",
        "                'probabilities': final_probs\n",
        "            }\n",
        "            all_results['fold_details'].append(fold_detail)\n",
        "\n",
        "        # ëª¨ë¸ ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"âœ… Fold {fold+1} ì™„ë£Œ!\")\n",
        "\n",
        "    # ì „ì²´ ê²°ê³¼ ìš”ì•½\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"ğŸ ì „ì²´ í›ˆë ¨ ì™„ë£Œ! ({target_type})\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    if all_results['accuracy']:\n",
        "        print(f\"ğŸ“Š í‰ê·  ì„±ëŠ¥ (Â±í‘œì¤€í¸ì°¨):\")\n",
        "        print(f\"   Accuracy:  {np.mean(all_results['accuracy']):.4f} Â± {np.std(all_results['accuracy']):.4f}\")\n",
        "        print(f\"   Precision: {np.mean(all_results['precision']):.4f} Â± {np.std(all_results['precision']):.4f}\")\n",
        "        print(f\"   Recall:    {np.mean(all_results['recall']):.4f} Â± {np.std(all_results['recall']):.4f}\")\n",
        "        print(f\"   F1:        {np.mean(all_results['f1']):.4f} Â± {np.std(all_results['f1']):.4f}\")\n",
        "        print(f\"   AUC:       {np.mean(all_results['auc']):.4f} Â± {np.std(all_results['auc']):.4f}\")\n",
        "\n",
        "        # ê²°ê³¼ íŒŒì¼ ì €ì¥\n",
        "        results_path = os.path.join(target_dir, f\"final_results_{target_type}.json\")\n",
        "        with open(results_path, 'w') as f:\n",
        "            # numpy arraysë¥¼ listë¡œ ë³€í™˜í•˜ì—¬ JSON serializableí•˜ê²Œ ë§Œë“¤ê¸°\n",
        "            json_results = {}\n",
        "            for key, value in all_results.items():\n",
        "                if isinstance(value, list) and len(value) > 0:\n",
        "                    if isinstance(value[0], np.ndarray):\n",
        "                        json_results[key] = [v.tolist() for v in value]\n",
        "                    else:\n",
        "                        json_results[key] = value\n",
        "                else:\n",
        "                    json_results[key] = value\n",
        "\n",
        "            json.dump(json_results, f, indent=2)\n",
        "\n",
        "        print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_path}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "def extract_features_efficiently(lr_patches, global_patches, hr_patches, model):\n",
        "    \"\"\"\n",
        "    ğŸ”§ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ feature extraction\n",
        "    í° ë°°ì¹˜ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•˜ì—¬ OOM ë°©ì§€\n",
        "    \"\"\"\n",
        "    batch_size = lr_patches.shape[0]\n",
        "\n",
        "    # LR features ì¶”ì¶œ\n",
        "    num_lr = lr_patches.shape[1]\n",
        "    lr_flat = lr_patches.view(-1, 3, 64, 64)\n",
        "\n",
        "    if hasattr(model, 'module'):\n",
        "        extractor = model.module.lr_extractor\n",
        "    else:\n",
        "        extractor = model.lr_extractor\n",
        "\n",
        "    lr_features = extractor(lr_flat)\n",
        "    lr_features = lr_features.view(batch_size, num_lr, -1)\n",
        "\n",
        "    # Global features ì¶”ì¶œ\n",
        "    num_global = global_patches.shape[1]\n",
        "    global_flat = global_patches.view(-1, 3, 64, 64)\n",
        "\n",
        "    if hasattr(model, 'module'):\n",
        "        global_extractor = model.module.global_extractor\n",
        "    else:\n",
        "        global_extractor = model.global_extractor\n",
        "\n",
        "    global_features = global_extractor(global_flat)\n",
        "    global_features = global_features.view(batch_size, num_global, -1)\n",
        "\n",
        "    # HR features ì¶”ì¶œ (ë©”ëª¨ë¦¬ ì§‘ì•½ì ì´ë¯€ë¡œ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬)\n",
        "    num_hr = hr_patches.shape[1]\n",
        "    hr_flat = hr_patches.view(-1, 3, 256, 256)\n",
        "\n",
        "    if hasattr(model, 'module'):\n",
        "        hr_extractor = model.module.hr_extractor\n",
        "    else:\n",
        "        hr_extractor = model.hr_extractor\n",
        "\n",
        "    # HR patchesë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "    chunk_size = 8  # í•œ ë²ˆì— 8ê°œì”© ì²˜ë¦¬\n",
        "    hr_features_list = []\n",
        "\n",
        "    for i in range(0, hr_flat.shape[0], chunk_size):\n",
        "        chunk = hr_flat[i:i+chunk_size]\n",
        "        chunk_features = hr_extractor(chunk)\n",
        "        hr_features_list.append(chunk_features)\n",
        "\n",
        "        # ì¤‘ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        del chunk\n",
        "\n",
        "    hr_features = torch.cat(hr_features_list, dim=0)\n",
        "    hr_features = hr_features.view(batch_size, num_hr, -1)\n",
        "\n",
        "    return lr_features, global_features, hr_features\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 8 ì™„ë£Œ: ì²´í¬í¬ì¸íŠ¸ë¥¼ ì™„ë²½ ì§€ì›í•˜ëŠ” í›ˆë ¨ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ í›ˆë ¨ ì¤‘ë‹¨ë˜ì–´ë„ ì–¸ì œë“  ì¬ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
        "print(\"ğŸ“ ë§¤ epochë§ˆë‹¤ ìë™ ì €ì¥ë˜ë©°, ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì€ ë³„ë„ ë³´ê´€ë©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)\n",
        "# ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™\n",
        "    lr_patches = batch['lr_patches'].to(device, non_blocking=True)\n",
        "    global_patches = batch['global_patches'].to(device, non_blocking=True)\n",
        "    hr_patches = batch['hr_patches'].to(device, non_blocking=True)\n",
        "    labels = batch['label'].to(device, non_blocking=True)\n",
        "\n",
        "    with autocast():\n",
        "        # Feature extraction (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ)\n",
        "        lr_features, global_features, hr_features = extract_features_efficiently(\n",
        "            lr_patches, global_patches, hr_patches, model\n",
        "        )\n",
        "\n",
        "        # Forward pass\n",
        "        if hasattr(model, 'module'):\n",
        "            logits, attention_maps, selection_stats = model.module(\n",
        "                lr_features, global_features, hr_features\n",
        "            )\n",
        "        else:\n",
        "            logits, attention_maps, selection_stats = model(\n",
        "                lr_features, global_features, hr_features\n",
        "            )\n",
        "\n",
        "        # Loss ê³„ì‚° (accumulationìœ¼ë¡œ ë‚˜ëˆ„ê¸°)\n",
        "        loss = criterion(logits, labels) / accumulation_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMNJcnhXUJ3P"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 9: ì‹¤ì œ í›ˆë ¨ ì‹¤í–‰\n",
        "# ========================================================================\n",
        "\n",
        "# ì´ ì…€ì„ ì•„í™‰ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdydXp_JUJ3P"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# í›ˆë ¨ ì „ ìµœì¢… í™•ì¸ ë° ì„¤ì •\n",
        "print(\"ğŸš€ FlexAttention MIL í›ˆë ¨ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"ğŸ’¾ ë°ì´í„°: {len(patient_data) if 'patient_data' in locals() else 0}ëª…ì˜ í™˜ì\")\n",
        "print(f\"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}\")\n",
        "print(f\"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {work_dir}\")\n",
        "print(f\"â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 1-2ì¼ (ìµœì í™”ëœ ì„¤ì •)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"í›ˆë ¨ ì‹œì‘ ì „\")\n",
        "\n",
        "# í›ˆë ¨ ì„¤ì • í™•ì¸\n",
        "print(\"\\nâš™ï¸  í›ˆë ¨ ì„¤ì •:\")\n",
        "print(\"   - ë©”ê°€íŒ¨ì¹˜ë‹¹ íŒ¨ì¹˜ ìˆ˜: 8ê°œ (16â†’8, 50% ì ˆì•½)\")\n",
        "print(\"   - Feature dimension: 256 (384â†’256, 33% ì ˆì•½)\")\n",
        "print(\"   - Attention heads: 4ê°œ (6â†’4, 33% ì ˆì•½)\")\n",
        "print(\"   - FlexAttention layers: 1ê°œ (2â†’1, 50% ì ˆì•½)\")\n",
        "print(\"   - ë°°ì¹˜ í¬ê¸°: 1 (ë¬¼ë¦¬ì ) Ã— 4 (ëˆ„ì ) = 4 (íš¨ê³¼ì )\")\n",
        "print(\"   - Feature extractor: ResNet18 (ì•ˆì •ì„± ìš°ì„ )\")\n",
        "\n",
        "# ì‚¬ìš©ì í™•ì¸\n",
        "print(f\"\\nâ“ ì„¤ì •ì´ ë§ë‹¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
        "print(f\"   T-stage ë¶„ë¥˜ì™€ ì¬ë°œ ì˜ˆì¸¡ì„ ìˆœì°¨ì ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.\")\n",
        "print(f\"   ê° foldë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ê°€ ìë™ ì €ì¥ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "# í›ˆë ¨ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "TRAINING_CONFIG = {\n",
        "    'num_folds': 5,\n",
        "    'num_epochs': 8,           # 2ì¼ ì•ˆì— ì™„ì£¼í•˜ê¸° ìœ„í•´ 12â†’10\n",
        "    'batch_size': 1,            # ë©”ëª¨ë¦¬ ì•ˆì „\n",
        "    'accumulation_steps': 4,    # íš¨ê³¼ì  ë°°ì¹˜ í¬ê¸° = 4\n",
        "    'learning_rate': 3e-4,\n",
        "    'extractor_type': 'resnet18',  # ì•ˆì •ì„± ìš°ì„ \n",
        "    'resume_from_checkpoint': True\n",
        "}\n",
        "\n",
        "print(f\"\\nğŸ“‹ í›ˆë ¨ íŒŒë¼ë¯¸í„°:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# ë°ì´í„° ì¡´ì¬ í™•ì¸\n",
        "if 'patient_data' not in locals() or not patient_data:\n",
        "    print(f\"\\nâŒ í™˜ì ë°ì´í„°ê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"   Part 5ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    print(f\"\\nâœ… í™˜ì ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(patient_data)}ëª…\")\n",
        "\n",
        "    # ë¼ë²¨ ë¶„í¬ ì¬í™•ì¸\n",
        "    t_labels = [info.get('t_label', 0) for info in patient_data.values()]\n",
        "    recur_labels = [info.get('recur_label', 0) for info in patient_data.values()]\n",
        "\n",
        "    print(f\"ğŸ“Š ë¼ë²¨ ë¶„í¬:\")\n",
        "    print(f\"   T-stage: {dict(zip(*np.unique(t_labels, return_counts=True)))}\")\n",
        "    print(f\"   ì¬ë°œ: {dict(zip(*np.unique(recur_labels, return_counts=True)))}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 9 ì™„ë£Œ: í›ˆë ¨ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒ ì…€ì—ì„œ ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVe_By63UJ3P"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 10: T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰\n",
        "# ========================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgoIZ9HlUJ3P"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ì´ ì…€ì„ ì—´ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - T-stage ë¶„ë¥˜ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!\n",
        "\n",
        "print(\"ğŸ¯ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘!\")\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ“‹ T-stage ë¶„ë¥˜:\")\n",
        "print(\"   - í´ë˜ìŠ¤ 0: Ta, T1 (ì €ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ì—†ìŒ)\")\n",
        "print(\"   - í´ë˜ìŠ¤ 1: T2+ (ê³ ìœ„í—˜ - ê·¼ìœ¡ì¸µ ì¹¨ë²” ìˆìŒ)\")\n",
        "print(\"   - ì„ìƒì  ì¤‘ìš”ì„±: ì¹˜ë£Œ ê³„íš ë° ì˜ˆí›„ ì˜ˆì¸¡ì— í•µì‹¬\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# í›ˆë ¨ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
        "import time\n",
        "start_time = time.time()\n",
        "start_datetime = datetime.now()\n",
        "\n",
        "print(f\"ğŸ•’ í›ˆë ¨ ì‹œì‘ ì‹œê°„: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"T-stage í›ˆë ¨ ì‹œì‘\")\n",
        "\n",
        "try:\n",
        "    # T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰\n",
        "    print(f\"\\nğŸš€ T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘...\")\n",
        "\n",
        "    t_stage_results = train_flexattention_model_with_checkpoints(\n",
        "        patient_data=patient_data,\n",
        "        target_type='t_label',\n",
        "        **TRAINING_CONFIG  # Part 9ì—ì„œ ì •ì˜í•œ ì„¤ì • ì‚¬ìš©\n",
        "    )\n",
        "\n",
        "    # í›ˆë ¨ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
        "    end_time = time.time()\n",
        "    training_duration = end_time - start_time\n",
        "    hours = int(training_duration // 3600)\n",
        "    minutes = int((training_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\nğŸ‰ T-stage ë¶„ë¥˜ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "    print(f\"â±ï¸  ì†Œìš” ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„\")\n",
        "    print(f\"ğŸ“Š ìµœì¢… ì„±ëŠ¥:\")\n",
        "\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        print(f\"   í‰ê·  Accuracy: {np.mean(t_stage_results['accuracy']):.4f} Â± {np.std(t_stage_results['accuracy']):.4f}\")\n",
        "        print(f\"   í‰ê·  F1 Score: {np.mean(t_stage_results['f1']):.4f} Â± {np.std(t_stage_results['f1']):.4f}\")\n",
        "        print(f\"   í‰ê·  AUC: {np.mean(t_stage_results['auc']):.4f} Â± {np.std(t_stage_results['auc']):.4f}\")\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ fold ì°¾ê¸°\n",
        "        best_fold_idx = np.argmax(t_stage_results['f1'])\n",
        "        best_f1 = t_stage_results['f1'][best_fold_idx]\n",
        "        print(f\"   ìµœê³  ì„±ëŠ¥: Fold {best_fold_idx + 1} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    # ê²°ê³¼ ì‹œê°í™” (ê°„ë‹¨í•œ ì„±ëŠ¥ ê·¸ë˜í”„)\n",
        "    if t_stage_results and t_stage_results['accuracy']:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            values = t_stage_results[metric]\n",
        "            plt.bar(range(1, len(values)+1), values, alpha=0.7)\n",
        "            plt.title(f'{name}')\n",
        "            plt.xlabel('Fold')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            # í‰ê· ì„  ì¶”ê°€\n",
        "            mean_val = np.mean(values)\n",
        "            plt.axhline(y=mean_val, color='red', linestyle='--', alpha=0.8)\n",
        "            plt.text(0.5, mean_val + 0.02, f'í‰ê· : {mean_val:.3f}', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # ê·¸ë˜í”„ ì €ì¥\n",
        "        plot_path = os.path.join(work_dir, \"results_t_label\", \"t_stage_performance.png\")\n",
        "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"ğŸ“ˆ ì„±ëŠ¥ ê·¸ë˜í”„ ì €ì¥: {plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    torch.cuda.empty_cache()\n",
        "    log_gpu_memory(\"T-stage í›ˆë ¨ ì™„ë£Œ\")\n",
        "\n",
        "    print(f\"\\nâœ… T-stage ë¶„ë¥˜ í›ˆë ¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {os.path.join(work_dir, 'results_t_label')}\")\n",
        "    print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸: {os.path.join(work_dir, 'results_t_label', 'checkpoints')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ T-stage í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    print(f\"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:\")\n",
        "    print(f\"   1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: batch_sizeë¥¼ 1ë¡œ ì¤„ì´ê¸°\")\n",
        "    print(f\"   2. ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë¶€ì¡±: patches_per_megapatchë¥¼ 8â†’6ìœ¼ë¡œ ì¤„ì´ê¸°\")\n",
        "    print(f\"   3. ë°ì´í„° ë¬¸ì œ: Part 5ì—ì„œ ë°ì´í„° ë¡œë”© ë‹¤ì‹œ í™•ì¸\")\n",
        "    print(f\"   4. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: resume_from_checkpoint=True ì„¤ì •\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 10 ì™„ë£Œ: T-stage ë¶„ë¥˜ í›ˆë ¨ ì‹¤í–‰!\")\n",
        "if 't_stage_results' in locals():\n",
        "    print(\"âœ… í›ˆë ¨ ì„±ê³µ! ë‹¤ìŒ Partì—ì„œ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ì„ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"âš ï¸  í›ˆë ¨ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ í•´ê²° ë°©ë²•ì„ ì°¸ê³ í•˜ì„¸ìš”.\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cJt3OZrUJ3P"
      },
      "source": [
        "# ========================================================================\n",
        "# FlexAttention ê¸°ë°˜ ë°©ê´‘ì•” ë¶„ë¥˜ ëª¨ë¸ - Part 11: ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ë° ìµœì¢… ê²°ê³¼\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OknC1VGPUJ3Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ì´ ì…€ì„ ì—´í•œ ë²ˆì§¸ë¡œ ì‹¤í–‰í•˜ì„¸ìš” - ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ì„ ì‹œì‘í•˜ê³  ì „ì²´ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤!\n",
        "\n",
        "print(\"ğŸ”„ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì‹œì‘!\")\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ“‹ ì¬ë°œ ì˜ˆì¸¡:\")\n",
        "print(\"   - í´ë˜ìŠ¤ 0: No (ì¬ë°œ ì—†ìŒ)\")\n",
        "print(\"   - í´ë˜ìŠ¤ 1: Yes (ì¬ë°œ ìˆìŒ)\")\n",
        "print(\"   - ì„ìƒì  ì¤‘ìš”ì„±: í™˜ì ëª¨ë‹ˆí„°ë§ ë° ì¶”ê°€ ì¹˜ë£Œ ê³„íš\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
        "recur_start_time = time.time()\n",
        "recur_start_datetime = datetime.now()\n",
        "\n",
        "print(f\"ğŸ•’ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì‹œì‘: {recur_start_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
        "log_gpu_memory(\"ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì‹œì‘\")\n",
        "\n",
        "try:\n",
        "    # ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì‹¤í–‰\n",
        "    print(f\"\\nğŸš€ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì‹œì‘...\")\n",
        "\n",
        "    recurrence_results = train_flexattention_model_with_checkpoints(\n",
        "        patient_data=patient_data,\n",
        "        target_type='recur_label',\n",
        "        **TRAINING_CONFIG  # ë™ì¼í•œ ì„¤ì • ì‚¬ìš©\n",
        "    )\n",
        "\n",
        "    # ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
        "    recur_end_time = time.time()\n",
        "    recur_duration = recur_end_time - recur_start_time\n",
        "    recur_hours = int(recur_duration // 3600)\n",
        "    recur_minutes = int((recur_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\nğŸ‰ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "    print(f\"â±ï¸  ì†Œìš” ì‹œê°„: {recur_hours}ì‹œê°„ {recur_minutes}ë¶„\")\n",
        "    print(f\"ğŸ“Š ìµœì¢… ì„±ëŠ¥:\")\n",
        "\n",
        "    if recurrence_results and recurrence_results['accuracy']:\n",
        "        print(f\"   í‰ê·  Accuracy: {np.mean(recurrence_results['accuracy']):.4f} Â± {np.std(recurrence_results['accuracy']):.4f}\")\n",
        "        print(f\"   í‰ê·  F1 Score: {np.mean(recurrence_results['f1']):.4f} Â± {np.std(recurrence_results['f1']):.4f}\")\n",
        "        print(f\"   í‰ê·  AUC: {np.mean(recurrence_results['auc']):.4f} Â± {np.std(recurrence_results['auc']):.4f}\")\n",
        "\n",
        "        # ìµœê³  ì„±ëŠ¥ fold ì°¾ê¸°\n",
        "        best_fold_idx = np.argmax(recurrence_results['f1'])\n",
        "        best_f1 = recurrence_results['f1'][best_fold_idx]\n",
        "        print(f\"   ìµœê³  ì„±ëŠ¥: Fold {best_fold_idx + 1} (F1: {best_f1:.4f})\")\n",
        "\n",
        "    # ì¬ë°œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
        "    if recurrence_results and recurrence_results['accuracy']:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            values = recurrence_results[metric]\n",
        "            plt.bar(range(1, len(values)+1), values, alpha=0.7, color='orange')\n",
        "            plt.title(f'{name}')\n",
        "            plt.xlabel('Fold')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1)\n",
        "\n",
        "            # í‰ê· ì„  ì¶”ê°€\n",
        "            mean_val = np.mean(values)\n",
        "            plt.axhline(y=mean_val, color='red', linestyle='--', alpha=0.8)\n",
        "            plt.text(0.5, mean_val + 0.02, f'í‰ê· : {mean_val:.3f}', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # ê·¸ë˜í”„ ì €ì¥\n",
        "        plot_path = os.path.join(work_dir, \"results_recur_label\", \"recurrence_performance.png\")\n",
        "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"ğŸ“ˆ ì„±ëŠ¥ ê·¸ë˜í”„ ì €ì¥: {plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    print(f\"\\nâœ… ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ ì¬ë°œ ì˜ˆì¸¡ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    print(f\"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸:\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ T-stage ê²°ê³¼ëŠ” ë³´ì¡´\n",
        "    if 't_stage_results' in locals():\n",
        "        print(f\"â„¹ï¸  T-stage ê²°ê³¼ëŠ” ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ì „ì²´ í›ˆë ¨ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
        "if 'start_time' in locals():\n",
        "    total_end_time = time.time()\n",
        "    total_duration = total_end_time - start_time\n",
        "    total_hours = int(total_duration // 3600)\n",
        "    total_minutes = int((total_duration % 3600) // 60)\n",
        "\n",
        "    print(f\"\\nâ° ì „ì²´ í›ˆë ¨ ì†Œìš” ì‹œê°„: {total_hours}ì‹œê°„ {total_minutes}ë¶„\")\n",
        "\n",
        "# ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° ë¹„êµ\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(f\"ğŸ FlexAttention MIL ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\")\n",
        "print(f\"=\"*80)\n",
        "\n",
        "# ê²°ê³¼ ë¹„êµí‘œ ìƒì„±\n",
        "if 't_stage_results' in locals() and 'recurrence_results' in locals():\n",
        "    if t_stage_results.get('accuracy') and recurrence_results.get('accuracy'):\n",
        "\n",
        "        print(f\"\\nğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ:\")\n",
        "        print(f\"{'ë©”íŠ¸ë¦­':<12} {'T-stage ë¶„ë¥˜':<20} {'ì¬ë°œ ì˜ˆì¸¡':<20}\")\n",
        "        print(f\"{'-'*12} {'-'*20} {'-'*20}\")\n",
        "\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "\n",
        "        for metric, name in zip(metrics, metric_names):\n",
        "            t_mean = np.mean(t_stage_results[metric])\n",
        "            t_std = np.std(t_stage_results[metric])\n",
        "            r_mean = np.mean(recurrence_results[metric])\n",
        "            r_std = np.std(recurrence_results[metric])\n",
        "\n",
        "            print(f\"{name:<12} {t_mean:.3f}Â±{t_std:.3f:<12} {r_mean:.3f}Â±{r_std:.3f}\")\n",
        "\n",
        "        # ì „ì²´ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì €ì¥\n",
        "        final_summary = {\n",
        "            'training_info': {\n",
        "                'start_time': start_datetime.isoformat() if 'start_datetime' in locals() else None,\n",
        "                'total_duration_hours': total_hours if 'total_hours' in locals() else None,\n",
        "                'training_config': TRAINING_CONFIG,\n",
        "                'num_patients': len(patient_data)\n",
        "            },\n",
        "            't_stage_classification': {\n",
        "                'task_description': 'Ta,T1 vs T2+ classification',\n",
        "                'clinical_importance': 'Treatment planning and prognosis',\n",
        "                'results': t_stage_results\n",
        "            },\n",
        "            'recurrence_prediction': {\n",
        "                'task_description': 'No recurrence vs Recurrence prediction',\n",
        "                'clinical_importance': 'Patient monitoring and follow-up care',\n",
        "                'results': recurrence_results\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # ì „ì²´ ìš”ì•½ ì €ì¥\n",
        "        summary_path = os.path.join(work_dir, \"final_summary_all_tasks.json\")\n",
        "        with open(summary_path, 'w') as f:\n",
        "            # numpy ê°ì²´ë¥¼ JSON serializableí•˜ê²Œ ë³€í™˜\n",
        "            def convert_numpy(obj):\n",
        "                if isinstance(obj, np.ndarray):\n",
        "                    return obj.tolist()\n",
        "                elif isinstance(obj, np.integer):\n",
        "                    return int(obj)\n",
        "                elif isinstance(obj, np.floating):\n",
        "                    return float(obj)\n",
        "                elif isinstance(obj, dict):\n",
        "                    return {key: convert_numpy(value) for key, value in obj.items()}\n",
        "                elif isinstance(obj, list):\n",
        "                    return [convert_numpy(item) for item in obj]\n",
        "                return obj\n",
        "\n",
        "            final_summary_json = convert_numpy(final_summary)\n",
        "            json.dump(final_summary_json, f, indent=2)\n",
        "\n",
        "        print(f\"\\nğŸ’¾ ì „ì²´ ê²°ê³¼ ìš”ì•½ ì €ì¥: {summary_path}\")\n",
        "\n",
        "        # ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        x = np.arange(len(metric_names))\n",
        "        width = 0.35\n",
        "\n",
        "        t_means = [np.mean(t_stage_results[m]) for m in metrics]\n",
        "        r_means = [np.mean(recurrence_results[m]) for m in metrics]\n",
        "\n",
        "        plt.bar(x - width/2, t_means, width, label='T-stage ë¶„ë¥˜', alpha=0.8)\n",
        "        plt.bar(x + width/2, r_means, width, label='ì¬ë°œ ì˜ˆì¸¡', alpha=0.8)\n",
        "\n",
        "        plt.xlabel('ë©”íŠ¸ë¦­')\n",
        "        plt.ylabel('ì ìˆ˜')\n",
        "        plt.title('FlexAttention MIL ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ')\n",
        "        plt.xticks(x, metric_names)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # ìˆ˜ì¹˜ í‘œì‹œ\n",
        "        for i, (t_val, r_val) in enumerate(zip(t_means, r_means)):\n",
        "            plt.text(i - width/2, t_val + 0.01, f'{t_val:.3f}', ha='center', fontsize=8)\n",
        "            plt.text(i + width/2, r_val + 0.01, f'{r_val:.3f}', ha='center', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        comparison_plot_path = os.path.join(work_dir, \"performance_comparison.png\")\n",
        "        plt.savefig(comparison_plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"ğŸ“Š ë¹„êµ ê·¸ë˜í”„ ì €ì¥: {comparison_plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "torch.cuda.empty_cache()\n",
        "log_gpu_memory(\"ì „ì²´ í›ˆë ¨ ì™„ë£Œ\")\n",
        "\n",
        "# ìµœì¢… ë©”ì‹œì§€\n",
        "print(f\"\\nğŸŠ ì¶•í•˜í•©ë‹ˆë‹¤! FlexAttention MIL ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "print(f\"ğŸ“ ëª¨ë“  ê²°ê³¼ëŠ” ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
        "print(f\"   {work_dir}\")\n",
        "print(f\"\\nğŸ“‹ ì €ì¥ëœ íŒŒì¼ë“¤:\")\n",
        "print(f\"   - T-stage ë¶„ë¥˜ ê²°ê³¼: results_t_label/\")\n",
        "print(f\"   - ì¬ë°œ ì˜ˆì¸¡ ê²°ê³¼: results_recur_label/\")\n",
        "print(f\"   - ì²´í¬í¬ì¸íŠ¸: */checkpoints/\")\n",
        "print(f\"   - ì „ì²´ ìš”ì•½: final_summary_all_tasks.json\")\n",
        "print(f\"   - ì„±ëŠ¥ ê·¸ë˜í”„: *.png\")\n",
        "\n",
        "if 'total_hours' in locals():\n",
        "    if total_hours < 48:  # 2ì¼ ì´ë‚´\n",
        "        print(f\"\\nâ° ëª©í‘œ ë‹¬ì„±! {total_hours}ì‹œê°„ {total_minutes}ë¶„ë§Œì— ì™„ë£Œ (2ì¼ ì´ë‚´)\")\n",
        "    else:\n",
        "        print(f\"\\nâ° ì´ ì†Œìš” ì‹œê°„: {total_hours}ì‹œê°„ {total_minutes}ë¶„\")\n",
        "\n",
        "print(f\"\\nâœ¨ FlexAttentionì„ ì´ìš©í•œ ë°©ê´‘ì•” ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Part 11 ì™„ë£Œ: ì „ì²´ í›ˆë ¨ ì™„ë£Œ ë° ê²°ê³¼ ìš”ì•½!\")\n",
        "print(\"ğŸ‰ ëª¨ë“  ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}